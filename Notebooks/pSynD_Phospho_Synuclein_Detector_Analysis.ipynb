{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8160eb4",
   "metadata": {},
   "source": [
    "# Analysis of Aiforia Phosphorylated $\\alpha$-Synuclein Raw Data\n",
    "\n",
    "## Part 0 - Outline\n",
    "This code handles the automatic processing of raw data from mouse brains analyzed using the Aiforia model “Lewy (PSYN) Pathology Detector”. The data are stored in a local folder on the computer, specified within the code. We typically start with CSV files. To automatically change the format of multiple files, please refer to the notebook Change_Name_Format_Input_Data.ipynb.\n",
    "This notebook is organized into three sections:\n",
    "\n",
    "**1) Define Functions for Part 2 & 3**\n",
    "\n",
    "**2) Automatic Analysis of X * N Slides Across N Brains**\n",
    "In this section, we automate the analysis of all X*N slides corresponding to N brains (X slides per brain, which is a parameter that the user can choose in the code) contained in the folder with raw data. The approach is as follows:\n",
    "\n",
    "1) All X*N filenames are collected from the folder and stored in a list.\n",
    "\n",
    "2) From this list, we extract the N filenames containing '_S1', corresponding to the first slide of each brain.\n",
    "\n",
    "3) We loop over these N '_S1' slides and perform the following steps for each brain:\n",
    "\n",
    "    a) We retrieve the second slide (with '_S2' in the filename) belonging to this brain. We do the same for the third ('_S3'), fourth ('_S4'), ..., X'th ('_SX')  slides of this brain.   \n",
    "    b) We perform the analysis steps on each slide individually (S1, S2, …, SX) and on the combined dataset (S1+S2+…+SX).\n",
    "    c) We export the results to an excel file for this specific brain.\n",
    "    \n",
    "After each iteration, the individual brain’s results are added to a summary table containing data for all brains. Once all brains are processed, this overview table is also exported to Excel.\n",
    "\n",
    "**3) Automatic Analysis of X * N Slides Across N Brains After Determining the (Un)Injected Areas**\n",
    "\n",
    "In this section, we extend the analysis by identifying which brain regions are on the injected versus non-injected side. The comparison between both sides follows the same analysis workflow as in Section 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf429a28",
   "metadata": {},
   "source": [
    "## Part 1 - Define the necessary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c2f9d",
   "metadata": {},
   "source": [
    "### Part 1.1 - Load all necessary Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84656b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Pandas display options\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd25711",
   "metadata": {},
   "source": [
    "### Part 1.2 - Data Locations\n",
    "\n",
    "**TO DO:**\n",
    "\n",
    "Specify the following paths before running the analysis:\n",
    "\n",
    "1) **Raw data format:** choose the file format of the raw data (e.g.: excel, csv).\n",
    "2) **Some experimental parameters:** spacing between sections and section thickness.\n",
    "3) **Raw data folder:** the folder containing the original data files exported from Aiforia.\n",
    "4) **Results folders:** the folders where the Excel files with processed results will be saved.\n",
    "5) **Region mapping files:** the location of the Excel files that specify which brain regions have to be replaced and were (un)injected.\n",
    "\n",
    "Use the following format to define each path: <font color='darkred'>r'file_location'</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5629fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify what data format you want to use for your raw data: excel, csv or feather. Do this by uncommenting the data_format that you want.\n",
    "data_format = 'csv'\n",
    "# data_format = 'excel'\n",
    "# data_format = 'feather'\n",
    "\n",
    "# Specify the maximum number of slides per brain. For example, if set to 4, filenames should include '_S1', '_S2', '_S3', and '_S4'. \n",
    "# If some brains have fewer slides, the code will generate empty data files for the missing ones to ensure proper execution.\n",
    "amount_of_slides = 2\n",
    "\n",
    "# Specify the experimental parameters (section_thickness in micrometers!!):\n",
    "spacing=12\n",
    "section_thickness = 40  \n",
    "\n",
    "# Specify folder locations\n",
    "folder_raw_data = r'C:\\Users\\Dieter\\...\\Raw_data_PSYN'\n",
    "folder_output_results = r'C:\\Users\\Dieter\\...\\Output_Results_PSYN'\n",
    "folder_output_results_injected = r'C:\\Users\\Dieter\\...\\Output_Results_Injected_PSYN'\n",
    "file_brainregions_to_replace =  r'C:\\Users\\Dieter\\...\\Brainregions_To_Replace_PSYN.xlsx'\n",
    "file_brainregions_injected =  r'C:\\Users\\Dieter\\...\\Brainregions_Hemisphere_PSYN.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e736cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folders if they did not exist yet\n",
    "if not os.path.isdir(folder_output_results):\n",
    "    os.mkdir(folder_output_results)\n",
    "if not os.path.isdir(folder_output_results_injected):\n",
    "    os.mkdir(folder_output_results_injected)\n",
    "\n",
    "# Create a list of expected slide suffixes. For example, if amount_of_slides = 4, then appendices_list = ['_S1', '_S2', '_S3', '_S4'].\n",
    "appendices_list = [f\"_S{i}\" for i in range(1, amount_of_slides + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12458138",
   "metadata": {},
   "source": [
    "### Part 1.3 – Function to Load All Image Files for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647f9c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_file_locations_S1(folder_raw_data: str, data_format: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Retrieve and list all file locations for S1 images in the specified raw data folder.\n",
    "\n",
    "    This function searches for all raw data files (based on the specified data format) \n",
    "    within the given folder and filters those containing '_S1' in their filename. \n",
    "    These represent the first slides (S1) of each brain. \n",
    "    If '_S1'/'_S2' naming is not used, '_S1' should be appended manually to filenames.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_raw_data : str\n",
    "        Path to the folder containing raw data files.\n",
    "    data_format : str\n",
    "        Format of the raw data files ('excel', 'csv', or 'feather').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    all_raw_data_file_locations_S1: list[str]\n",
    "        Sorted list of full file paths for S1 images.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the file pattern based on the data format\n",
    "    if data_format == 'excel':\n",
    "        pattern = \"*.xlsx\"\n",
    "    elif data_format == 'csv':\n",
    "        pattern = \"*.csv\"\n",
    "    elif data_format == 'feather':\n",
    "        pattern = \"*.feather\"\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid data format specified. Please set 'data_format' to 'excel', 'csv', or 'feather'.\"\n",
    "        )\n",
    "\n",
    "    # Retrieve and sort all matching raw data files\n",
    "    all_raw_data_file_locations = glob.glob(os.path.join(folder_raw_data, pattern))\n",
    "    all_raw_data_file_locations.sort()\n",
    "\n",
    "    print(\"All raw data file locations:\")\n",
    "    for file_location in all_raw_data_file_locations:\n",
    "        print(f\" - {file_location}\")\n",
    "\n",
    "    # Filter filenames that contain '_S1' (first slides of each brain)\n",
    "    all_raw_data_file_locations_S1 = [path for path in all_raw_data_file_locations if '_S1' in path]\n",
    "\n",
    "    print(\"\\nRaw data file locations for S1 images:\")\n",
    "    for file_location_S1 in all_raw_data_file_locations_S1:\n",
    "        print(f\" - {file_location_S1}\")\n",
    "\n",
    "    return all_raw_data_file_locations_S1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926f488e",
   "metadata": {},
   "source": [
    "### Part 1.4 – Function to Load the Brain Region Correction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db037f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_brainregions_to_replace(file_brainregions_to_replace: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and clean the file containing corrections for brain regions that need to be replaced for each image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_brainregions_to_replace : str\n",
    "        Path to the Excel file with columns: 'Image', 'Brainregion_Wrong', 'Brainregion_Correct'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Cleaned DataFrame with brain regions to replace for each image. \n",
    "        All brain region names are stripped of spaces and converted to uppercase.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    if not os.path.exists(file_brainregions_to_replace):\n",
    "        raise FileNotFoundError(f\"The specified file does not exist: {file_brainregions_to_replace}\")\n",
    "\n",
    "    # Load the relevant columns from the Excel file\n",
    "    df = pd.read_excel(\n",
    "        file_brainregions_to_replace,\n",
    "        usecols=['Image', 'Brainregion_Wrong', 'Brainregion_Correct'],\n",
    "        dtype={'Image': 'str', 'Brainregion_Wrong': 'str', 'Brainregion_Correct': 'str'}\n",
    "    )\n",
    "\n",
    "    # Clean the data in place\n",
    "    df['Image'] = df['Image'].str.strip()\n",
    "    df['Brainregion_Wrong'] = df['Brainregion_Wrong'].str.upper().str.strip()\n",
    "    df['Brainregion_Correct'] = df['Brainregion_Correct'].str.upper().str.strip()\n",
    "\n",
    "    print(\"The modified table of brain regions to replace for each image:\")\n",
    "    display(df)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524c828e",
   "metadata": {},
   "source": [
    "### Part 1.5 – Function to Load the File Indicating Which Brain Regions Were Injected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247f478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_brainregions_injected(file_brainregions_injected: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and clean the file specifying which brain regions were on the injected side for each specific image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_brainregions_injected : str\n",
    "        Path to the Excel file containing injected brain region information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Cleaned DataFrame with columns:\n",
    "        - 'Image': image identifier\n",
    "        - 'Brainregion': uppercase, stripped brain region name\n",
    "        - 'Daughter1_Injected': uppercase, stripped hemisphere \n",
    "\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_brainregions_injected):\n",
    "        raise FileNotFoundError(f\"The specified file does not exist: {file_brainregions_injected}\")\n",
    "\n",
    "    # Load relevant columns from the Excel file\n",
    "    df = pd.read_excel(\n",
    "        file_brainregions_injected,\n",
    "        usecols=['Image', 'Brainregion', 'Hemisphere'],\n",
    "        dtype={'Image': 'str', 'Brainregion': 'str', 'Hemisphere': 'str'}\n",
    "    )\n",
    "\n",
    "    # Clean the data in place\n",
    "    df['Image'] = df['Image'].str.strip()\n",
    "    df['Brainregion'] = df['Brainregion'].str.upper().str.strip()\n",
    "    df['Daughter1_Injected'] = df['Hemisphere'].str.upper().str.strip()\n",
    "\n",
    "    # Drop the original 'Hemisphere' column\n",
    "    df.drop(columns=['Hemisphere'], inplace=True)\n",
    "\n",
    "    print(\"The modified table of injected brain regions for each image:\")\n",
    "    display(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee6cee",
   "metadata": {},
   "source": [
    "### Part 1.6 – Function to Load a DataFrame and Clean It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_cleaning(file_location: str, df_brainregions_to_replace: pd.DataFrame, data_format: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a data file from the given location and clean it using a brain regions replacement table.\n",
    "    If the file does not exist, an empty file is created with the correct columns.\n",
    "    Replaces incorrect brain regions, merges names by removing numbers, filters based on area thresholds,\n",
    "    and calculates derived metrics like Area/Perimeter and Circularity.\n",
    "    Returns a cleaned dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_location : str\n",
    "        Path to the raw data file for a single image.\n",
    "    df_brainregions_to_replace : pd.DataFrame\n",
    "        DataFrame specifying which brain regions need to be replaced for each image.\n",
    "    data_format : str\n",
    "        Format of the raw data file: 'excel', 'csv', or 'feather'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Cleaned dataframe with replaced brain regions, merged name columns, and derived metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------\n",
    "    # Define expected columns and dtypes\n",
    "    # ------------------------\n",
    "    columns = ['Image', 'Parent area name', 'Area/object name', 'Class label', \n",
    "               'Class confidence (%)', 'Area (μm²)', 'Circumference (µm)']\n",
    "    dtypes = {\n",
    "        'Image': 'str',\n",
    "        'Parent area name': 'str',\n",
    "        'Area/object name': 'str',\n",
    "        'Class label': 'str',\n",
    "        'Class confidence (%)': 'float64',\n",
    "        'Area (μm²)': 'float64',\n",
    "        'Circumference (µm)': 'float64'\n",
    "    }\n",
    "\n",
    "    # ------------------------\n",
    "    # Load or create the data file\n",
    "    # ------------------------\n",
    "    try:\n",
    "        if data_format == 'csv':\n",
    "            df = pd.read_csv(file_location, sep='\\t', usecols=columns, dtype=dtypes, keep_default_na=True)\n",
    "        elif data_format == 'excel':\n",
    "            df = pd.read_excel(file_location, usecols=columns, dtype=dtypes, keep_default_na=True)\n",
    "        elif data_format == 'feather':\n",
    "            df = pd.read_feather(file_location).astype(dtypes)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid data format. Choose 'excel', 'csv', or 'feather'.\")\n",
    "    except FileNotFoundError:\n",
    "        # Create empty file if missing\n",
    "        df_empty = pd.DataFrame(columns=columns)\n",
    "        df_empty.reset_index(inplace=True)\n",
    "        if data_format == 'csv':\n",
    "            df_empty.to_csv(file_location, sep='\\t', index=False)\n",
    "            df = pd.read_csv(file_location, sep='\\t', usecols=columns, dtype=dtypes)\n",
    "        elif data_format == 'excel':\n",
    "            df_empty.to_excel(file_location, index=False)\n",
    "            df = pd.read_excel(file_location, usecols=columns, dtype=dtypes)\n",
    "        elif data_format == 'feather':\n",
    "            df_empty.to_feather(file_location)\n",
    "            df = pd.read_feather(file_location).astype(dtypes)\n",
    "        print(f\"\\nA dataframe at location {file_location} did not exist, so an empty dataframe was created.\")\n",
    "\n",
    "    # ------------------------\n",
    "    # Remove rows with missing essential values\n",
    "    # ------------------------\n",
    "    df.dropna(subset=['Area (μm²)', 'Area/object name'], inplace=True)\n",
    "\n",
    "    # ------------------------\n",
    "    # Standardize text columns\n",
    "    # ------------------------\n",
    "    df['Parent area name'] = df['Parent area name'].str.upper()\n",
    "    df['Area/object name'] = df['Area/object name'].str.upper()\n",
    "    df['Class label'] = df['Class label'].str.upper()\n",
    "\n",
    "    # ------------------------\n",
    "    # Extract image name from file path\n",
    "    # ------------------------\n",
    "    image_name = os.path.splitext(os.path.basename(file_location))[0]\n",
    "    print('The present image =', image_name)\n",
    "\n",
    "    # Make sure the image name across the whole first Image column is correct\n",
    "    df['Image'] = image_name\n",
    "\n",
    "    print('The full raw data =')\n",
    "    display(df)\n",
    "\n",
    "    # ------------------------\n",
    "    # Replace incorrect brain regions\n",
    "    # ------------------------\n",
    "    # Create the dictionary of brain regions that should be replaced for this specific image\n",
    "    df_replacements = df_brainregions_to_replace[df_brainregions_to_replace['Image'] == image_name]\n",
    "    dict_replace = pd.Series(df_replacements.Brainregion_Correct.values, index=df_replacements.Brainregion_Wrong).to_dict()\n",
    "    print(f\"The dictionary of brain regions to replace for {image_name} is:\", dict_replace)\n",
    "\n",
    "    # Apply replacements in both parent and Area/object name columns\n",
    "    df['Parent area name'] = df['Parent area name'].replace(dict_replace, regex=False)\n",
    "    df['Area/object name'] = df['Area/object name'].replace(dict_replace, regex=False)\n",
    "\n",
    "    # ------------------------\n",
    "    # Create a column 'Parent area name merged' and 'Area/object name merged' where the numbers are deleted from the original columns:\n",
    "    # ------------------------\n",
    "    df['Parent area name merged'] = df['Parent area name'].str.replace(r'\\d+$', '', regex=True).str.strip()\n",
    "    df['Area/object name merged'] = df['Area/object name'].str.replace(r'\\d+$', '', regex=True).str.strip()\n",
    "\n",
    "    # ------------------------\n",
    "    # Propagate EMPTY from parent to its descendants\n",
    "    # ------------------------\n",
    "    # Identify rows where the parent area was replaced with 'EMPTY'.\n",
    "    # Any area/object whose parent became EMPTY should also be considered EMPTY.\n",
    "    # For example, if a parent area is EMPTY, its child (and potentially further descendants) should also be marked for deletion.\n",
    "    df_empty_parent = df[df['Parent area name'] == 'EMPTY']\n",
    "    list_of_area_objects_that_should_be_empty = df_empty_parent['Area/object name'].to_list()\n",
    "    print('list_of_area_objects_that_should_be_empty =', list_of_area_objects_that_should_be_empty)\n",
    "\n",
    "    df.loc[df['Parent area name'].isin(list_of_area_objects_that_should_be_empty), \"Parent area name\"] = \"EMPTY\"\n",
    "    df = df[(df['Parent area name'] != 'EMPTY') & (df['Area/object name'] != 'EMPTY')]\n",
    "\n",
    "    # ------------------------\n",
    "    # Filter based on area thresholds for inclusions\n",
    "    # ------------------------\n",
    "    mask_exclude = (\n",
    "        ((df['Area (μm²)'] > 600) & df['Area/object name merged'].str.contains('CELLULAR DIFFUSE INCLUSION')) |\n",
    "        ((df['Area (μm²)'] < 25) & df['Area/object name merged'].str.contains('CELLULAR DIFFUSE INCLUSION')) |\n",
    "        ((df['Area (μm²)'] < 4) & df['Area/object name merged'].str.contains('A | NEURITIC SEEDED INCLUSION')) |\n",
    "        ((df['Area (μm²)'] < 15) & df['Area/object name merged'].str.contains('CELLULAR SEEDED INCLUSION'))\n",
    "    )\n",
    "    df = df[~mask_exclude]\n",
    "\n",
    "    # ------------------------\n",
    "    # Derived metrics\n",
    "    # ------------------------\n",
    "    df['Area/Perimeter (μm)'] = df['Area (μm²)'] / df['Circumference (µm)']\n",
    "    df['Circularity'] = (4 * math.pi * df['Area (μm²)']) / (df['Circumference (µm)'] ** 2)\n",
    "\n",
    "    print('The fully cleaned table with \"Area/Perimeter\", \"Circularity\" and so on:')\n",
    "    display(df)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a347ef9",
   "metadata": {},
   "source": [
    "### Part 1.7 - Function to Create Hierarchical Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467f8cf0",
   "metadata": {},
   "source": [
    "The hierarchy: \n",
    "\n",
    "One type of **Parent:** BRAIN TISSUE 1, 2, 3, … \\\n",
    "Many types of **Daughter 1:** AMYGDALA 1, 2, 3, …, STRIATUM 1, 2, 3, …, ...  \\\n",
    "Three types of **Daughter 2:** A | CELLULAR DIFFUSE INCLUSION X, A | CELLULAR SEEDED INCLUSION X, A | CELLULAR SEEDED INCLUSION \\\n",
    "Two types of **Daughter 3:** O | CELLULAR DIFFUSE INCLUSION X, O | CELLULAR SEEDED INCLUSION X \n",
    "\n",
    "Note: “X” denotes a number identifying the specific object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4965e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hierarchy(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Constructs hierarchical relationships in a dataframe.\n",
    "    The column 'Parent area name' is always the parent of the 'Area/object name' in the same row. \n",
    "    The Area (μm²) column in the row always belongs to the 'Area/object name'\n",
    "\n",
    "    The function builds four dataframes representing progressively deeper hierarchy levels:\n",
    "      1. Top-level parents (rows without their own parent)\n",
    "      2. Parent + first daughter\n",
    "      3. Parent + first + second daughter\n",
    "      4. Parent + first + second + third daughter\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input dataframe with columns \n",
    "            ['Image', 'Parent area name', 'Area/object name', 'Area/object name merged',\n",
    "             'Area (μm²)', 'Area/Perimeter (μm)', 'Circularity', 'Class label',\n",
    "             'Parent area name merged']\n",
    "\n",
    "    Returns:\n",
    "        tuple: (df_parent, df_parent_daughter1, df_parent_daughter2, df_parent_daughter3)\n",
    "            - df_parent: top-level parent areas\n",
    "            - df_parent_daughter1: parent + first daughter\n",
    "            - df_parent_daughter2: parent + first + second daughter\n",
    "            - df_parent_daughter3: parent + first + second + third daughter\n",
    "    \"\"\"\n",
    "\n",
    "    # Select top-level parents (rows without their own parent)\n",
    "    df_parent = df[df['Parent area name'].isna()].copy()\n",
    "    df_parent.rename(\n",
    "        columns={\n",
    "            'Area/object name': 'Parent name',\n",
    "            'Area/object name merged': 'Parent name merged',\n",
    "            'Area (μm²)': 'Area Parent (μm²)',\n",
    "            'Area/Perimeter (μm)': 'Area/Perimeter Parent (μm)',\n",
    "            'Circularity': 'Circularity Parent'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "    df_parent.drop(columns=['Parent area name', 'Class label', 'Parent area name merged',\n",
    "                            'Area/Perimeter Parent (μm)', 'Circularity Parent'], inplace=True)\n",
    "\n",
    "    # Merge to add first daughter (child of top-level parents)\n",
    "    df_parent_daughter1 = df_parent.merge(\n",
    "        df[['Parent area name', 'Area/object name', 'Area/object name merged', 'Area (μm²)']],\n",
    "        left_on='Parent name', right_on='Parent area name', how='inner'\n",
    "    )\n",
    "    df_parent_daughter1.rename(\n",
    "        columns={\n",
    "            'Parent area name': 'Parent name copy',\n",
    "            'Area/object name': 'Daughter1',\n",
    "            'Area/object name merged': 'Daughter1 merged',\n",
    "            'Area (μm²)': 'Area Daughter1 (μm²)'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    # Now there can be for instance 2 Striatum 4 rows in df_parent_daughter1. The first one is the original Striatum 4 row.\n",
    "    # The second one could originate from e.g. changing Amygdala 1 to Striatum 4 in the brainregion corrections replacement \n",
    "    # of section 1.6.\n",
    "    # We need to aggregate these 2 Striatum 4 rows into one unique row because otherwise \n",
    "    # we will double in the next join when making df_parent_daughter2.\n",
    "    df_parent_daughter1 = df_parent_daughter1.groupby('Daughter1', as_index=False).agg({\n",
    "        'Image': 'first',\n",
    "        'Parent name': 'first',\n",
    "        'Area Parent (μm²)': 'first',\n",
    "        'Parent name merged': 'first',\n",
    "        'Parent name copy': 'first',\n",
    "        'Daughter1': 'first',\n",
    "        'Daughter1 merged': 'first',\n",
    "        'Area Daughter1 (μm²)': 'sum'\n",
    "    })\n",
    "\n",
    "    # Merge to add second daughter (child of Daughter1)\n",
    "    df_parent_daughter2 = df_parent_daughter1.merge(\n",
    "        df[['Parent area name', 'Area/object name', 'Area/object name merged', 'Area (μm²)',\n",
    "            'Area/Perimeter (μm)', 'Circularity']],\n",
    "        left_on='Daughter1', right_on='Parent area name', how='inner'\n",
    "    )\n",
    "    df_parent_daughter2.rename(\n",
    "        columns={\n",
    "            'Parent area name': 'Daughter1 copy',\n",
    "            'Area/object name': 'Daughter2',\n",
    "            'Area/object name merged': 'Daughter2 merged',\n",
    "            'Area (μm²)': 'Area Daughter2 (μm²)',\n",
    "            'Area/Perimeter (μm)': 'Area/Perimeter Daughter2 (μm)',\n",
    "            'Circularity': 'Circularity Daughter2'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    # Merge to add third daughter (child of Daughter2)\n",
    "    df_parent_daughter3 = df_parent_daughter2.merge(\n",
    "        df[['Parent area name', 'Area/object name', 'Area/object name merged', 'Area (μm²)',\n",
    "            'Area/Perimeter (μm)', 'Circularity']],\n",
    "        left_on='Daughter2', right_on='Parent area name', how='inner'\n",
    "    )\n",
    "    df_parent_daughter3.rename(\n",
    "        columns={\n",
    "            'Parent area name': 'Daughter2 copy',\n",
    "            'Area/object name': 'Daughter3',\n",
    "            'Area/object name merged': 'Daughter3 merged',\n",
    "            'Area (μm²)': 'Area Daughter3 (μm²)',\n",
    "            'Area/Perimeter (μm)': 'Area/Perimeter Daughter3 (μm)',\n",
    "            'Circularity': 'Circularity Daughter3'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    return df_parent, df_parent_daughter1, df_parent_daughter2, df_parent_daughter3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649a8037",
   "metadata": {},
   "source": [
    "### Part 1.8 - Function to Calculate all Statistics Subdivided in the Three A Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128efad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_calculations_per_a_type(\n",
    "    df1: pd.DataFrame,\n",
    "    df2: pd.DataFrame,\n",
    "    groupby_column1: str = 'Area/object name merged',\n",
    "    groupby_column2: str = 'Daughter1 merged'\n",
    ") -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Compute summary statistics for all A-type inclusions across two hierarchical dataframes.\n",
    "\n",
    "    A-type inclusions include:\n",
    "        - 'A | CELLULAR DIFFUSE INCLUSION'\n",
    "        - 'A | CELLULAR SEEDED INCLUSION'\n",
    "        - 'A | NEURITIC SEEDED INCLUSION'\n",
    "\n",
    "    Parameters:\n",
    "        df1 : pd.DataFrame\n",
    "            DataFrame containing at least 'Area/object name merged and 'Area (μm²)' for region-level area aggregation.\n",
    "        df2 : pd.DataFrame\n",
    "            DataFrame containing at least 'Daughter1 merged, 'Area Daughter2 (μm²)', 'Area/Perimeter Daughter2 (μm)', \n",
    "            and 'Circularity Daughter2'.\n",
    "        groupby_column1 : str, optional\n",
    "            Column name used to group region areas (default 'Area/object name merged').\n",
    "        groupby_column2 : str, optional\n",
    "            Column name used to group inclusion-level features (default 'Daughter1 merged').\n",
    "\n",
    "    Returns:\n",
    "        dict: {A-type string: dataframe with calculated statistics per region}\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the total region area of each Daughter 1 merged by grouping over all Area/object name merged \n",
    "    # in the original (cleaned) dataframe.\n",
    "    # This returns e.g. the total area of Amygdala = Area Amygdala 1 + Area Amygdala 2 + ... Area Amygdala 7)\n",
    "    df_region_areas_merged = (\n",
    "        df1.groupby(groupby_column1, dropna=False, as_index=False)['Area (μm²)']\n",
    "        .sum()\n",
    "        .rename(columns={groupby_column1: 'Merged area name', 'Area (μm²)': 'Total Region Area (μm²)'})\n",
    "    )\n",
    "    \n",
    "    # List of A-types to calculate\n",
    "    A_type_list = [\n",
    "        'A | CELLULAR DIFFUSE INCLUSION',\n",
    "        'A | CELLULAR SEEDED INCLUSION',\n",
    "        'A | NEURITIC SEEDED INCLUSION'\n",
    "    ]\n",
    "    \n",
    "    A_type_dictionary = {}\n",
    "\n",
    "    for A_type in A_type_list:\n",
    "        # Filter df2 for the current A-type\n",
    "        df_A_type = df2[df2['Daughter2 merged'] == A_type]\n",
    "\n",
    "        # Calculate the total Area (μm²), average Area (μm²), average Area/Perimeter (μm), average Circularity  \n",
    "        # of the Inclusions belonging to each Daughter1 merged\n",
    "        agg_dict = {\n",
    "            'Area Daughter2 (μm²)': ['sum', 'mean'],\n",
    "            'Area/Perimeter Daughter2 (μm)': 'mean',\n",
    "            'Circularity Daughter2': 'mean'\n",
    "        }\n",
    "        df_stats = df_A_type.groupby(groupby_column2, as_index=False).agg(agg_dict)\n",
    "        df_stats.columns = ['Merged area name',\n",
    "                            A_type + ' Total Inclusion Area (μm²)',\n",
    "                            A_type + ' Average Inclusion Area (μm²)',\n",
    "                            A_type + ' Average Area/Perimeter (μm)',\n",
    "                            A_type + ' Average Circularity']\n",
    "\n",
    "        # Count the number of inclusions per region\n",
    "        df_counts = df_A_type[groupby_column2].value_counts(sort=True) \\\n",
    "                            .rename_axis('Merged area name').reset_index(name=A_type + ' Counts')\n",
    "\n",
    "        # Merge with region areas and counts\n",
    "        df_merged_A_type = functools.reduce(\n",
    "            lambda left, right: pd.merge(left, right, on='Merged area name', how='outer'),\n",
    "            [df_region_areas_merged, df_stats, df_counts]\n",
    "        )\n",
    "\n",
    "        # Derived calculations\n",
    "        df_merged_A_type[A_type + ' Percentage PSYN Positive Area'] = \\\n",
    "            100 * df_merged_A_type[A_type + ' Total Inclusion Area (μm²)'] / df_merged_A_type['Total Region Area (μm²)']\n",
    "        df_merged_A_type[A_type + ' Extrapolated Inclusion Count'] = \\\n",
    "            df_merged_A_type[A_type + ' Counts'] * spacing\n",
    "        df_merged_A_type[A_type + ' Inclusions/Region Area (per μm²)'] = \\\n",
    "            df_merged_A_type[A_type + ' Counts'] / df_merged_A_type['Total Region Area (μm²)']\n",
    "        df_merged_A_type[A_type + ' Inclusions/Region Volume (per μm³)'] = \\\n",
    "            df_merged_A_type[A_type + ' Inclusions/Region Area (per μm²)'] / section_thickness\n",
    "        df_merged_A_type[A_type + ' Inclusions/Region Area (mm²)'] = \\\n",
    "            df_merged_A_type[A_type + ' Inclusions/Region Area (per μm²)'] * 1e6\n",
    "        df_merged_A_type[A_type + ' Inclusions/Region Volume (mm³)'] = \\\n",
    "            df_merged_A_type[A_type + ' Inclusions/Region Volume (per μm³)'] * 1e9\n",
    "\n",
    "        # Drop intermediate per μm²/μm³ columns\n",
    "        df_merged_A_type.drop(columns=[A_type + ' Inclusions/Region Area (per μm²)',\n",
    "                                        A_type + ' Inclusions/Region Volume (per μm³)'], inplace=True)\n",
    "\n",
    "        # Define the column order dynamically for the current A_type\n",
    "        desired_order = [\n",
    "            \"Merged area name\",\n",
    "            \"Total Region Area (μm²)\",\n",
    "            f\"{A_type} Total Inclusion Area (μm²)\",\n",
    "            f\"{A_type} Average Inclusion Area (μm²)\",\n",
    "            f\"{A_type} Percentage PSYN Positive Area\",\n",
    "            f\"{A_type} Counts\",\n",
    "            f\"{A_type} Extrapolated Inclusion Count\",\n",
    "            f\"{A_type} Inclusions/Region Area (mm²)\",\n",
    "            f\"{A_type} Inclusions/Region Volume (mm³)\",\n",
    "            f\"{A_type} Average Area/Perimeter (μm)\",\n",
    "            f\"{A_type} Average Circularity\",\n",
    "        ]\n",
    "\n",
    "        # Reorder columns \n",
    "        df_merged_A_type = df_merged_A_type[desired_order]\n",
    "\n",
    "        # Display results\n",
    "        print(f'The total {A_type} calculations of each {groupby_column2}')\n",
    "        display(df_merged_A_type)\n",
    "\n",
    "        # Save in dictionary\n",
    "        A_type_dictionary[A_type] = df_merged_A_type\n",
    "\n",
    "    return A_type_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f1aca9",
   "metadata": {},
   "source": [
    "### Part 1.9 - Function to Calculate all Statistics Subdivided in the Two O Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0976ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_calculations_per_o_type(\n",
    "    df1: pd.DataFrame,\n",
    "    df2: pd.DataFrame,\n",
    "    groupby_column1: str = 'Area/object name merged',\n",
    "    groupby_column2: str = 'Daughter1 merged'\n",
    ") -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Compute summary statistics for all O-type inclusions across two hierarchical dataframes.\n",
    "\n",
    "    O-type inclusions include:\n",
    "        - 'O | CELLULAR DIFFUSE INCLUSION'\n",
    "        - 'O | CELLULAR SEEDED INCLUSIONS'\n",
    "\n",
    "    Parameters:\n",
    "        df1 : pd.DataFrame\n",
    "            DataFrame containing at least 'Area/object name merged and 'Area (μm²)' for region-level area aggregation.\n",
    "        df2 : pd.DataFrame\n",
    "            DataFrame containing at least 'Daughter1 merged, 'Area Daughter3 (μm²)', 'Area/Perimeter Daughter3 (μm)', \n",
    "            and 'Circularity Daughter3'.\n",
    "        groupby_column1 : str, optional\n",
    "            Column name used to group region areas (default 'Area/object name merged').\n",
    "        groupby_column2 : str, optional\n",
    "            Column name used to group inclusion-level features (default 'Daughter1 merged').\n",
    "\n",
    "    Returns:\n",
    "        dict: {O-type string: dataframe with calculated statistics per region}\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the total region area of each Daughter 1 merged by grouping over all Area/object name merged \n",
    "    # in the original (cleaned) dataframe.\n",
    "    # This returns e.g. the total area of Amygdala = Area Amygdala 1 + Area Amygdala 2 + ... Area Amygdala 7)\n",
    "    df_region_areas_merged = (\n",
    "        df1.groupby(groupby_column1, dropna=False, as_index=False)['Area (μm²)']\n",
    "        .sum()\n",
    "        .rename(columns={groupby_column1: 'Merged area name', 'Area (μm²)': 'Total Region Area (μm²)'})\n",
    "    )\n",
    "\n",
    "    # List of O-types to calculate\n",
    "    O_type_list = [\n",
    "        'O | CELLULAR DIFFUSE INCLUSION',\n",
    "        'O | CELLULAR SEEDED INCLUSIONS'\n",
    "    ]\n",
    "\n",
    "    O_type_dictionary = {}\n",
    "\n",
    "    for O_type in O_type_list:\n",
    "        # Filter df2 for the current O-type\n",
    "        df_O_type = df2[df2['Daughter3 merged'] == O_type]\n",
    "\n",
    "        # Calculate the total Area (μm²), average Area (μm²), average Area/Perimeter (μm), average Circularity\n",
    "        # of the Inclusions belonging to each Daughter1 merged\n",
    "        agg_dict = {\n",
    "            'Area Daughter3 (μm²)': ['sum', 'mean'],\n",
    "            'Area/Perimeter Daughter3 (μm)': 'mean',\n",
    "            'Circularity Daughter3': 'mean'\n",
    "        }\n",
    "        df_stats = df_O_type.groupby(groupby_column2, as_index=False).agg(agg_dict)\n",
    "        df_stats.columns = ['Merged area name',\n",
    "                            O_type + ' Total Inclusion Area (μm²)',\n",
    "                            O_type + ' Average Inclusion Area (μm²)',\n",
    "                            O_type + ' Average Area/Perimeter (μm)',\n",
    "                            O_type + ' Average Circularity']\n",
    "\n",
    "        # Count the number of inclusions per region\n",
    "        df_counts = df_O_type[groupby_column2].value_counts(sort=True) \\\n",
    "                        .rename_axis('Merged area name').reset_index(name=O_type + ' Counts')\n",
    "\n",
    "        # Merge with region areas and counts\n",
    "        df_merged_O_type = functools.reduce(\n",
    "            lambda left, right: pd.merge(left, right, on='Merged area name', how='outer'),\n",
    "            [df_region_areas_merged, df_stats, df_counts]\n",
    "        )\n",
    "\n",
    "        # Derived calculations\n",
    "        df_merged_O_type[O_type + ' Percentage PSYN Positive Area'] = \\\n",
    "            100 * df_merged_O_type[O_type + ' Total Inclusion Area (μm²)'] / df_merged_O_type['Total Region Area (μm²)']\n",
    "        df_merged_O_type[O_type + ' Extrapolated Inclusion Count'] = \\\n",
    "            df_merged_O_type[O_type + ' Counts'] * spacing\n",
    "        df_merged_O_type[O_type + ' Inclusions/Region Area (per μm²)'] = \\\n",
    "            df_merged_O_type[O_type + ' Counts'] / df_merged_O_type['Total Region Area (μm²)']\n",
    "        df_merged_O_type[O_type + ' Inclusions/Region Volume (per μm³)'] = \\\n",
    "            df_merged_O_type[O_type + ' Inclusions/Region Area (per μm²)'] / section_thickness\n",
    "        df_merged_O_type[O_type + ' Inclusions/Region Area (mm²)'] = \\\n",
    "            df_merged_O_type[O_type + ' Inclusions/Region Area (per μm²)'] * 1e6\n",
    "        df_merged_O_type[O_type + ' Inclusions/Region Volume (mm³)'] = \\\n",
    "            df_merged_O_type[O_type + ' Inclusions/Region Volume (per μm³)'] * 1e9\n",
    "\n",
    "        # Drop intermediate per μm²/μm³ columns\n",
    "        df_merged_O_type.drop(columns=[O_type + ' Inclusions/Region Area (per μm²)',\n",
    "                                       O_type + ' Inclusions/Region Volume (per μm³)'], inplace=True)\n",
    "        \n",
    "        # Define the column order dynamically for the current O_type\n",
    "        desired_order = [\n",
    "            \"Merged area name\",\n",
    "            \"Total Region Area (μm²)\",\n",
    "            f\"{O_type} Total Inclusion Area (μm²)\",\n",
    "            f\"{O_type} Average Inclusion Area (μm²)\",\n",
    "            f\"{O_type} Percentage PSYN Positive Area\",\n",
    "            f\"{O_type} Counts\",\n",
    "            f\"{O_type} Extrapolated Inclusion Count\",\n",
    "            f\"{O_type} Inclusions/Region Area (mm²)\",\n",
    "            f\"{O_type} Inclusions/Region Volume (mm³)\",\n",
    "            f\"{O_type} Average Area/Perimeter (μm)\",\n",
    "            f\"{O_type} Average Circularity\",\n",
    "        ]\n",
    "\n",
    "        # Reorder columns \n",
    "        df_merged_O_type = df_merged_O_type[desired_order]\n",
    "\n",
    "        # Display results\n",
    "        print(f'The total {O_type} calculations of each {groupby_column2}')\n",
    "        display(df_merged_O_type)\n",
    "\n",
    "        # Save in dictionary\n",
    "        O_type_dictionary[O_type] = df_merged_O_type\n",
    "\n",
    "    return O_type_dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9495c3f8",
   "metadata": {},
   "source": [
    "### Part 1.10 - Function to Merge the A and O Dataframes and Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_a_and_o_calculations(\n",
    "    dict_A: dict[str, pd.DataFrame],\n",
    "    dict_O: dict[str, pd.DataFrame]\n",
    ") -> tuple[dict[str, pd.DataFrame], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Merge dictionaries containing all A-type and O-type calculations.\n",
    "\n",
    "    This function performs the following steps:\n",
    "        1. Combines the two input dictionaries into a single dictionary.\n",
    "        2. Sorts the merged dictionary in a preferred order for Excel output.\n",
    "        3. Merges all dataframes in the dictionary into a single dataframe \n",
    "           using an outer join, which might be useful later.\n",
    "\n",
    "    Parameters:\n",
    "        dict1 (dict): Dictionary of A-type calculations {A-type string: dataframe}.\n",
    "        dict2 (dict): Dictionary of O-type calculations {O-type string: dataframe}.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - dict: Sorted dictionary of all A- and O-type calculations.\n",
    "            - pd.DataFrame: Outer-joined dataframe containing all merged calculations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Combine the dictionaries\n",
    "    A_and_O_type_dictionary = dict_A.copy()\n",
    "    A_and_O_type_dictionary.update(dict_O)\n",
    "\n",
    "    # Step 2: Sort the dictionary in a specific order for convenience\n",
    "    preferred_order = [\n",
    "        'A | NEURITIC SEEDED INCLUSION',\n",
    "        'A | CELLULAR SEEDED INCLUSION',\n",
    "        'O | CELLULAR SEEDED INCLUSIONS',\n",
    "        'A | CELLULAR DIFFUSE INCLUSION',\n",
    "        'O | CELLULAR DIFFUSE INCLUSION'\n",
    "    ]\n",
    "    A_and_O_type_dictionary_sorted = {key: A_and_O_type_dictionary[key] for key in preferred_order}\n",
    "\n",
    "    # Step 3: Merge all dataframes in the sorted dictionary using an outer join\n",
    "    dfs_to_merge = [A_and_O_type_dictionary_sorted[key] for key in A_and_O_type_dictionary_sorted.keys()]\n",
    "    df_all_calcs_merged = functools.reduce(\n",
    "        lambda left, right: pd.merge(\n",
    "            left, right, \n",
    "            on=['Merged area name', 'Total Region Area (μm²)'], \n",
    "            how='outer'\n",
    "        ),\n",
    "        dfs_to_merge\n",
    "    )\n",
    "\n",
    "    return A_and_O_type_dictionary_sorted, df_all_calcs_merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a38e24",
   "metadata": {},
   "source": [
    "## Part 2 - Automatic Analysis of all X*N Slides of all N Brains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b95b2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Measure execution time of this cell\n",
    "\n",
    "# Load the file specifying brain regions to replace/delete for each image\n",
    "df_brainregions_to_replace = load_data_brainregions_to_replace(file_brainregions_to_replace)\n",
    "\n",
    "# Get all file names containing '_S1' (first images of all N brains)\n",
    "all_raw_data_file_locations_S1 = load_all_file_locations_S1(folder_raw_data, data_format)\n",
    "\n",
    "# Initialize dictionary to store overview dataframes\n",
    "dictionary_overview_dataframes = {}\n",
    "\n",
    "# Loop over all S1 images in the raw_data folder\n",
    "for count, file_location_S1 in enumerate(all_raw_data_file_locations_S1):\n",
    "\n",
    "    print(f'\\nAnalysis of {file_location_S1}')\n",
    "\n",
    "    # Extract image name from file path\n",
    "    image_name_S1 = os.path.splitext(os.path.basename(file_location_S1))[0]\n",
    "\n",
    "    # Dictionaries to store cleaned and hierarchical dataframes for all appendices\n",
    "    dict_df_SX_final = {}              # {'_S1': df_S1_final, ..., '_SX': df_SX_final}\n",
    "    dict_df_SX_parent = {}             # {'_S1': df_S1_parent, ..., '_SX': df_SX_parent}\n",
    "    dict_df_SX_parent_daughter1 = {}   # {'_S1': df_S1_parent_daughter1, ..., '_SX': df_SX_parent_daughter1}\n",
    "    dict_df_SX_parent_daughter2 = {}   # {'_S1': df_S1_parent_daughter2, ..., '_SX': df_SX_parent_daughter2}\n",
    "    dict_df_SX_parent_daughter3 = {}   # {'_S1': df_S1_parent_daughter3, ..., '_SX': df_SX_parent_daughter3}\n",
    "    dict_df_A_and_O_type_dictionary = {}  # {'_S1': {...}, '_S2': {...}, ...}\n",
    "\n",
    "    # Loop over all appendices ('_S1', '_S2', ..., '_SX')\n",
    "    for appendix in appendices_list:\n",
    "        file_location = file_location_S1.replace('_S1', appendix)\n",
    "\n",
    "        # Clean data and generate hierarchical dataframes\n",
    "        dict_df_SX_final[appendix] = dataframe_cleaning(file_location, df_brainregions_to_replace, data_format)\n",
    "        (\n",
    "            dict_df_SX_parent[appendix],\n",
    "            dict_df_SX_parent_daughter1[appendix],\n",
    "            dict_df_SX_parent_daughter2[appendix],\n",
    "            dict_df_SX_parent_daughter3[appendix]\n",
    "        ) = make_hierarchy(dict_df_SX_final[appendix])\n",
    "\n",
    "        # Perform A-type and O-type calculations\n",
    "        # The except part is for when we have made an empty dataframe because no dataframe was available (will never be the case for appendix =_S1).\n",
    "        try:\n",
    "            A_type_dict_SX = all_calculations_per_a_type(dict_df_SX_final[appendix], dict_df_SX_parent_daughter2[appendix])\n",
    "            O_type_dict_SX = all_calculations_per_o_type(dict_df_SX_final[appendix], dict_df_SX_parent_daughter3[appendix])\n",
    "            dict_df_A_and_O_type_dictionary[appendix], dict_df_SX_all_calcs_merged = merge_all_a_and_o_calculations(A_type_dict_SX, O_type_dict_SX)\n",
    "            print(f'All A-type and O-type calculations merged for {appendix} of {file_location}')\n",
    "            display(dict_df_SX_all_calcs_merged)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Concatenate all cleaned and hierarchical dataframes (S1+S2+...+SX)\n",
    "    df_SX_final_concat = pd.concat(dict_df_SX_final.values(), axis=0)\n",
    "    df_SX_parent_daughter1_concat = pd.concat(dict_df_SX_parent_daughter1.values(), axis=0)\n",
    "    df_SX_parent_daughter2_concat = pd.concat(dict_df_SX_parent_daughter2.values(), axis=0)\n",
    "    df_SX_parent_daughter3_concat = pd.concat(dict_df_SX_parent_daughter3.values(), axis=0)\n",
    "\n",
    "    # Perform overall A-type and O-type calculations for concatenated SX data\n",
    "    try:\n",
    "        A_type_dict_concat = all_calculations_per_a_type(df_SX_final_concat, df_SX_parent_daughter2_concat)\n",
    "        O_type_dict_concat = all_calculations_per_o_type(df_SX_final_concat, df_SX_parent_daughter3_concat)\n",
    "        A_and_O_type_dict_SX, df_SX_all_calcs_concat = merge_all_a_and_o_calculations(A_type_dict_concat, O_type_dict_concat)\n",
    "        print(f'All A-type and O-type calculations merged for S1+S2+...+SX of {file_location_S1}')\n",
    "        display(df_SX_all_calcs_concat)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Save per-image SX results to Excel\n",
    "    output_file_SX = os.path.join(\n",
    "        folder_output_results,\n",
    "        image_name_S1.replace('_S1', '_SX') + '_Results.xlsx'\n",
    "    )\n",
    "\n",
    "    with pd.ExcelWriter(output_file_SX) as writer:\n",
    "        # Individual SX results\n",
    "        for appendix, results_dict in dict_df_A_and_O_type_dictionary.items():\n",
    "            start_row = 0\n",
    "            for df_key in results_dict:\n",
    "                results_dict[df_key].to_excel(\n",
    "                    writer, sheet_name=appendix[1:] + '_Results',\n",
    "                    index=False, float_format=\"%.3f\", startrow=start_row\n",
    "                )\n",
    "                start_row += results_dict[df_key].shape[0] + 2\n",
    "\n",
    "        # Concatenated results\n",
    "        start_row = 0\n",
    "        for df_key in A_and_O_type_dict_SX:\n",
    "            A_and_O_type_dict_SX[df_key].to_excel(\n",
    "                writer, sheet_name='SX_Results',\n",
    "                index=False, float_format=\"%.3f\", startrow=start_row\n",
    "            )\n",
    "            start_row += A_and_O_type_dict_SX[df_key].shape[0] + 2\n",
    "\n",
    "    # Add overview dataframes per a_o_type_name\n",
    "    # For the overview excel file, only the 5 dataframes for the 5 a_o_type_names in A_and_O_type_dictionary_SX are needed. \n",
    "    # We will make 5 overview excelfiles with 8 tabpages that we store in dictionary_overview_dataframes:\n",
    "    # dictionary_overview_dataframes = {'A | NEURITIC SEEDED INCLUSION' : {total_region_area: df, total_inclusion_area:df, extrapolated_inclusions:df, .... },\n",
    "    #                                   'A | CELLULAR SEEDED INCLUSION' : {total_region_area: df, total_inclusion_area:df, extrapolated_inclusions:df, .... },\n",
    "    #                                    ... }\n",
    "    for a_o_type_name in A_and_O_type_dict_SX:\n",
    "        if count == 0:\n",
    "            dictionary_overview_dataframes[a_o_type_name] = {}\n",
    "\n",
    "        # Define columns for each metric type\n",
    "        list_calculation_results = [\n",
    "            'Total Region Area (μm²)',\n",
    "            f'{a_o_type_name} Total Inclusion Area (μm²)',\n",
    "            f'{a_o_type_name} Average Inclusion Area (μm²)',\n",
    "            f'{a_o_type_name} Percentage PSYN Positive Area',\n",
    "            f'{a_o_type_name} Counts',\n",
    "            f'{a_o_type_name} Extrapolated Inclusion Count',\n",
    "            f'{a_o_type_name} Inclusions/Region Area (mm²)',\n",
    "            f'{a_o_type_name} Inclusions/Region Volume (mm³)',\n",
    "            f'{a_o_type_name} Average Area/Perimeter (μm)',\n",
    "            f'{a_o_type_name} Average Circularity'\n",
    "        ]\n",
    "        for calc in list_calculation_results:\n",
    "            df_calc = A_and_O_type_dict_SX[a_o_type_name][['Merged area name', calc]].copy()\n",
    "            df_calc.rename(columns={calc: image_name_S1.replace('_S1', '').replace('_PSYN', '')}, inplace=True)\n",
    "\n",
    "            if count == 0:\n",
    "                dictionary_overview_dataframes[a_o_type_name][calc] = df_calc.copy()\n",
    "            else:\n",
    "                dictionary_overview_dataframes[a_o_type_name][calc] = dictionary_overview_dataframes[a_o_type_name][calc].merge(\n",
    "                    df_calc, how='outer', on='Merged area name'\n",
    "                )\n",
    "\n",
    "    # Clean up memory for next iteration\n",
    "    del dict_df_SX_final, dict_df_SX_parent, dict_df_SX_parent_daughter1\n",
    "    del dict_df_SX_parent_daughter2, dict_df_SX_parent_daughter3\n",
    "    del df_SX_final_concat, df_SX_all_calcs_concat\n",
    "\n",
    "# After all loops, export overview results\n",
    "all_a_o_type_names = list(dictionary_overview_dataframes.keys()) # ['A | NEURITIC SEEDED INCLUSION','A | CELLULAR SEEDED INCLUSION', 'O | CELLULAR SEEDED INCLUSIONS', 'A | CELLULAR DIFFUSE INCLUSION', 'O | CELLULAR DIFFUSE INCLUSION']\n",
    "\n",
    "for a_o_type_name, calc_dict in dictionary_overview_dataframes.items():\n",
    "    a_o_type_name_clean = a_o_type_name.replace(' | ', '_').replace(' ', '_')\n",
    "    output_overview_file = os.path.join(\n",
    "        folder_output_results, f'Overview_PSYN_Results_{a_o_type_name_clean}.xlsx'\n",
    "    )\n",
    "\n",
    "    list_calculation_results = [\n",
    "        'Total Region Area (μm²)',\n",
    "        f'{a_o_type_name} Total Inclusion Area (μm²)',\n",
    "        f'{a_o_type_name} Average Inclusion Area (μm²)',\n",
    "        f'{a_o_type_name} Percentage PSYN Positive Area',\n",
    "        f'{a_o_type_name} Counts',\n",
    "        f'{a_o_type_name} Extrapolated Inclusion Count',\n",
    "        f'{a_o_type_name} Inclusions/Region Area (mm²)',\n",
    "        f'{a_o_type_name} Inclusions/Region Volume (mm³)',\n",
    "        f'{a_o_type_name} Average Area/Perimeter (μm)',\n",
    "        f'{a_o_type_name} Average Circularity'\n",
    "    ]\n",
    "    \n",
    "    with pd.ExcelWriter(output_overview_file) as writer:\n",
    "        for calc in list_calculation_results:\n",
    "            clean_name = (\n",
    "                calc.replace(f'{a_o_type_name} ', '')\n",
    "                .replace('Inclusions/', 'Incl/')\n",
    "                .replace('/', ' per ')\n",
    "                .replace('Volume', 'Vol')\n",
    "            )\n",
    "\n",
    "            if calc != 'Total Region Area (μm²)':\n",
    "                # Remove rows where 'Merged area name' equals any of the entries in all_a_o_type_names, because for these entries \n",
    "                # only the 'Total Region Area (μm²)' makes sense and has been calculated\n",
    "                calc_dict[calc] = calc_dict[calc][~calc_dict[calc]['Merged area name'].isin(all_a_o_type_names + ['TISSUE'])]\n",
    "       \n",
    "            print(f'Overview dataframe with all {clean_name} for {a_o_type_name} for all brains')\n",
    "            display(calc_dict[calc])\n",
    "            calc_dict[calc].to_excel(writer, sheet_name=clean_name, index=False, float_format=\"%.3f\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1001265",
   "metadata": {},
   "source": [
    "## Part 3 – Automatic Analysis of all X*N Slides of all N Brains (Including Injected and Uninjected Hemispheres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6488cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Measure execution time of this cell\n",
    "\n",
    "# Load the file specifying brain regions to replace/delete for each image\n",
    "df_brainregions_to_replace = load_data_brainregions_to_replace(file_brainregions_to_replace)\n",
    "\n",
    "# Load the file specifying hemisphere (injected/uninjected) classification for each image\n",
    "df_brainregions_injected = load_data_brainregions_injected(file_brainregions_injected)\n",
    "\n",
    "# Get all file names containing '_S1' (first images of all N brains)\n",
    "all_raw_data_file_locations_S1 = load_all_file_locations_S1(folder_raw_data, data_format)\n",
    "\n",
    "# Initialize dictionary to store overview dataframes\n",
    "dictionary_overview_dataframes_injected = {}\n",
    "\n",
    "# Loop over all S1 images in the raw_data folder\n",
    "for count, file_location_S1 in enumerate(all_raw_data_file_locations_S1):\n",
    "\n",
    "    print(f'\\nAnalysis of {file_location_S1}')\n",
    "\n",
    "    # Extract image name from file path\n",
    "    image_name_S1 = os.path.splitext(os.path.basename(file_location_S1))[0]\n",
    "\n",
    "    # Dictionaries to store cleaned and hierarchical dataframes for all appendices\n",
    "    dict_df_SX_final = {}\n",
    "    dict_df_SX_parent = {}\n",
    "    dict_df_SX_parent_daughter1 = {}\n",
    "    dict_df_SX_parent_daughter2 = {}\n",
    "    dict_df_SX_parent_daughter3 = {}\n",
    "\n",
    "    # Loop over all appendices ('_S1', '_S2', ..., '_SX')\n",
    "    for appendix in appendices_list:\n",
    "        file_location = file_location_S1.replace('_S1', appendix)\n",
    "        print(f'\\nAnalysis of {file_location}')\n",
    "\n",
    "        # Clean data and generate hierarchical dataframes\n",
    "        dict_df_SX_final[appendix] = dataframe_cleaning(file_location, df_brainregions_to_replace, data_format)\n",
    "        (\n",
    "            dict_df_SX_parent[appendix],\n",
    "            dict_df_SX_parent_daughter1[appendix],\n",
    "            dict_df_SX_parent_daughter2[appendix],\n",
    "            dict_df_SX_parent_daughter3[appendix]\n",
    "        ) = make_hierarchy(dict_df_SX_final[appendix])\n",
    "\n",
    "    # Concatenate all cleaned and hierarchical dataframes (S1+S2+...+SX)\n",
    "    print(f'\\nAnalysis of concatenated SX files of {image_name_S1}')\n",
    "    df_SX_final_concat = pd.concat(dict_df_SX_final.values(), axis=0)\n",
    "    df_SX_parent_daughter1_concat = pd.concat(dict_df_SX_parent_daughter1.values(), axis=0)\n",
    "    df_SX_parent_daughter2_concat = pd.concat(dict_df_SX_parent_daughter2.values(), axis=0)\n",
    "    df_SX_parent_daughter3_concat = pd.concat(dict_df_SX_parent_daughter3.values(), axis=0)\n",
    "\n",
    "    # Merge with hemisphere injection information\n",
    "    # For each dataframe, this determines whether the Daughter1 region was injected or uninjected\n",
    "    # Brain regions not relevant to the injected analysis are removed through the inner join\n",
    "    df_SX_final_concat_injected = df_SX_final_concat.merge(\n",
    "        df_brainregions_injected, left_on=['Image', 'Area/object name'], right_on=['Image', 'Brainregion'], how='inner'\n",
    "    )\n",
    "    df_SX_parent_daughter1_injected = df_SX_parent_daughter1_concat.merge(\n",
    "        df_brainregions_injected, left_on=['Image', 'Daughter1'], right_on=['Image', 'Brainregion'], how='inner'\n",
    "    )\n",
    "    df_SX_parent_daughter2_injected = df_SX_parent_daughter2_concat.merge(\n",
    "        df_brainregions_injected, left_on=['Image', 'Daughter1'], right_on=['Image', 'Brainregion'], how='inner'\n",
    "    )\n",
    "    df_SX_parent_daughter3_injected = df_SX_parent_daughter3_concat.merge(\n",
    "        df_brainregions_injected, left_on=['Image', 'Daughter1'], right_on=['Image', 'Brainregion'], how='inner'\n",
    "    )\n",
    "\n",
    "    # Perform A-type and O-type calculations for concatenated SX injected data\n",
    "    A_type_dict_SX_injected = all_calculations_per_a_type(\n",
    "        df_SX_final_concat_injected, df_SX_parent_daughter2_injected, 'Daughter1_Injected', 'Daughter1_Injected'\n",
    "    )\n",
    "    O_type_dict_SX_injected = all_calculations_per_o_type(\n",
    "        df_SX_final_concat_injected, df_SX_parent_daughter3_injected, 'Daughter1_Injected', 'Daughter1_Injected'\n",
    "    )\n",
    "\n",
    "    A_and_O_type_dict_SX_injected, df_SX_all_calcs_injected = merge_all_a_and_o_calculations(\n",
    "        A_type_dict_SX_injected, O_type_dict_SX_injected\n",
    "    )\n",
    "\n",
    "    print('All A-type and O-type calculations merged for concatenated SX injected')\n",
    "    display(df_SX_all_calcs_injected)\n",
    "\n",
    "  # Save individual SX hemisphere results to Excel\n",
    "    output_file_SX = os.path.join(\n",
    "        folder_output_results_injected,\n",
    "        image_name_S1.replace('_S1', '_SX') + '_Hemisphere_Results.xlsx'\n",
    "    )\n",
    "\n",
    "    with pd.ExcelWriter(output_file_SX) as writer:\n",
    "        start_row = 0\n",
    "        for df_key in A_and_O_type_dict_SX_injected:\n",
    "            A_and_O_type_dict_SX_injected[df_key].sort_values('Merged area name', ascending=False, inplace=True)\n",
    "            A_and_O_type_dict_SX_injected[df_key].to_excel(\n",
    "                writer, sheet_name='SX_Hemisphere_Results',\n",
    "                index=False, float_format=\"%.3f\", startrow=start_row\n",
    "            )\n",
    "            start_row += A_and_O_type_dict_SX_injected[df_key].shape[0] + 2\n",
    "\n",
    "    # Build overview dataframes per A/O type\n",
    "    for a_o_type_name in A_and_O_type_dict_SX_injected:\n",
    "        if count == 0:\n",
    "            dictionary_overview_dataframes_injected[a_o_type_name] = {}\n",
    "\n",
    "        list_calculation_results = [\n",
    "            'Total Region Area (μm²)',\n",
    "            f'{a_o_type_name} Total Inclusion Area (μm²)',\n",
    "            f'{a_o_type_name} Average Inclusion Area (μm²)',\n",
    "            f'{a_o_type_name} Percentage PSYN Positive Area',\n",
    "            f'{a_o_type_name} Counts',\n",
    "            f'{a_o_type_name} Extrapolated Inclusion Count',\n",
    "            f'{a_o_type_name} Inclusions/Region Area (mm²)',\n",
    "            f'{a_o_type_name} Inclusions/Region Volume (mm³)',\n",
    "            f'{a_o_type_name} Average Area/Perimeter (μm)',\n",
    "            f'{a_o_type_name} Average Circularity'\n",
    "        ]\n",
    "\n",
    "        for calc in list_calculation_results:\n",
    "            df_calc = A_and_O_type_dict_SX_injected[a_o_type_name][['Merged area name', calc]].copy()\n",
    "            df_calc.rename(columns={calc: image_name_S1.replace('_S1', '').replace('_PSYN', '')}, inplace=True)\n",
    "\n",
    "            if count == 0:\n",
    "                dictionary_overview_dataframes_injected[a_o_type_name][calc] = df_calc.copy()\n",
    "            else:\n",
    "                dictionary_overview_dataframes_injected[a_o_type_name][calc] = dictionary_overview_dataframes_injected[\n",
    "                    a_o_type_name\n",
    "                ][calc].merge(df_calc, how='outer', on='Merged area name')\n",
    "\n",
    "    # Clean up memory for next iteration\n",
    "    del dict_df_SX_final, dict_df_SX_parent, dict_df_SX_parent_daughter1\n",
    "    del dict_df_SX_parent_daughter2, dict_df_SX_parent_daughter3\n",
    "    del df_SX_final_concat, df_SX_all_calcs_injected\n",
    "\n",
    "# After all loops, export overview results\n",
    "for a_o_type_name, calc_dict in dictionary_overview_dataframes_injected.items():\n",
    "    a_o_type_name_clean = a_o_type_name.replace(' | ', '_').replace(' ', '_')\n",
    "    output_file_overview = os.path.join(\n",
    "        folder_output_results_injected,\n",
    "        f'Overview_PSYN_Hemisphere_Results_{a_o_type_name_clean}.xlsx'\n",
    "    )\n",
    "\n",
    "    list_calculation_results = [\n",
    "        'Total Region Area (μm²)',\n",
    "        f'{a_o_type_name} Total Inclusion Area (μm²)',\n",
    "        f'{a_o_type_name} Average Inclusion Area (μm²)',\n",
    "        f'{a_o_type_name} Percentage PSYN Positive Area',\n",
    "        f'{a_o_type_name} Counts',\n",
    "        f'{a_o_type_name} Extrapolated Inclusion Count',\n",
    "        f'{a_o_type_name} Inclusions/Region Area (mm²)',\n",
    "        f'{a_o_type_name} Inclusions/Region Volume (mm³)',\n",
    "        f'{a_o_type_name} Average Area/Perimeter (μm)',\n",
    "        f'{a_o_type_name} Average Circularity'\n",
    "    ]\n",
    "\n",
    "    with pd.ExcelWriter(output_file_overview) as writer:\n",
    "        for calc in list_calculation_results:\n",
    "            calc_clean = (\n",
    "                calc.replace(f'{a_o_type_name} ', '')\n",
    "                .replace('Inclusions/', 'Incl/')\n",
    "                .replace('/', ' per ')\n",
    "                .replace('Volume', 'Vol')\n",
    "            )\n",
    "            calc_dict[calc].sort_values('Merged area name', ascending=False, inplace=True)\n",
    "\n",
    "            print(f'Overview dataframe with all {calc_clean} for {a_o_type_name} for all brains')\n",
    "            display(calc_dict[calc])\n",
    "\n",
    "            calc_dict[calc].to_excel(\n",
    "                writer, sheet_name=calc_clean, index=False, float_format=\"%.3f\"\n",
    "            )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
