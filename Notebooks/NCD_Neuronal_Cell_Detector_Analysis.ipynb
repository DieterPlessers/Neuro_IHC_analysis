{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8160eb4",
   "metadata": {},
   "source": [
    "# Analysis of Aiforia Neuronal Cell Detector Ouput (NeuN)\n",
    "\n",
    "## Part 0 - Outline\n",
    "This code handles the automatic processing of raw data from mouse brains analyzed using the Aiforia model “Neuronal Cell Detector”. The data are stored in a local folder on the computer, specified within the code. The supported file formats are CSV, TSV, Excel and feather. To automatically change the format of multiple files, please refer to the notebook Change_Name_Format_Input_Data.ipynb.\n",
    "This notebook is organized into three sections:\n",
    "\n",
    "**1) Define Functions for Part 2 & 3**\n",
    "\n",
    "**2) Automatic Analysis of X * N Slides Across N Brains**\n",
    "In this section, we automate the analysis of all X*N slides corresponding to N brains (X slides per brain, which is a parameter that the user can choose in the code) contained in the folder with raw data. The approach is as follows:\n",
    "\n",
    "1) All X*N filenames are collected from the folder and stored in a list.\n",
    "\n",
    "2) From this list, we extract the N filenames containing '_S1', corresponding to the first slide of each brain.\n",
    "\n",
    "3) We loop over these N '_S1' slides and perform the following steps for each brain:\n",
    "\n",
    "    a) We retrieve the second slide (with '_S2' in the filename) belonging to this brain. We do the same for the third ('_S3'), fourth ('_S4'), ..., X'th ('_SX')  slides of this brain.   \n",
    "    b) We perform the analysis steps on each slide individually (S1, S2, …, SX) and on the combined dataset (S1+S2+…+SX).\n",
    "    c) We export the results to an excel file for this specific brain.\n",
    "    \n",
    "After each iteration, the individual brain’s results are added to a summary table containing data for all brains. Once all brains are processed, this overview table is also exported to Excel.\n",
    "\n",
    "**3) Automatic Analysis of X * N Slides Across N Brains After Determining the (Un)Injected Areas**\n",
    "\n",
    "In this section, we extend the analysis by identifying which brain regions are on the injected versus non-injected side. The comparison between both sides follows the same analysis workflow as in Section 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f008181a",
   "metadata": {},
   "source": [
    "## Part 1 - Define the necessary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b54e0a7",
   "metadata": {},
   "source": [
    "### Part 1.1 - Load all necessary Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f492eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Pandas display options\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f838015",
   "metadata": {},
   "source": [
    "### Part 1.2 - Data Locations\n",
    "\n",
    "**TO DO:**\n",
    "\n",
    "Specify the following paths before running the analysis:\n",
    "\n",
    "1) **Raw data format:** choose the file format of the raw data (csv, tsv, xlsx or feather).\n",
    "2) **Some experimental parameters:** spacing between sections and section thickness.\n",
    "3) **Raw data folder:** the folder containing the original data files exported from Aiforia.\n",
    "4) **Results folders:** the folders where the Excel files with processed results will be saved.\n",
    "5) **Region mapping files:** the location of the Excel files that specify which brain regions have to be replaced and were (un)injected.\n",
    "\n",
    "Use the following format to define each path: <font color='darkred'>r'file_location'</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db3aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify what data format you want to use for your raw data: csv, tsv, xlsx or feather. Do this by uncommenting the data_format that you want.\n",
    "data_format = 'csv'\n",
    "# data_format = 'tsv'\n",
    "# data_format = 'xlsx'\n",
    "# data_format = 'feather'\n",
    "\n",
    "# Specify the maximum number of slides per brain. For example, if set to 4, filenames should include '_S1', '_S2', '_S3', and '_S4'. \n",
    "# If some brains have fewer slides, the code will generate empty data files for the missing ones to ensure proper execution.\n",
    "amount_of_slides = 2\n",
    "\n",
    "# Specify the experimental parameters (section_thickness in micrometers!!):\n",
    "spacing=12\n",
    "section_thickness = 40  \n",
    "\n",
    "# Specify folder locations\n",
    "folder_raw_data = r'C:\\Users\\...\\Raw_data_NeuN'\n",
    "folder_output_results = r'C:\\Users\\...\\Output_Results_NeuN'\n",
    "folder_output_results_injected = r'C:\\Users\\...\\Output_Results_Injected_NeuN'\n",
    "file_brainregions_to_replace =  r'C:\\Users\\...\\Brainregions_To_Replace_NeuN.xlsx'\n",
    "file_brainregions_injected =  r'C:\\Users\\...\\Brainregions_Hemisphere_NeuN.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folders if they did not exist yet\n",
    "if not os.path.isdir(folder_output_results):\n",
    "    os.mkdir(folder_output_results)\n",
    "if not os.path.isdir(folder_output_results_injected):\n",
    "    os.mkdir(folder_output_results_injected)\n",
    "\n",
    "# Create a list of expected slide suffixes. For example, if amount_of_slides = 4, then appendices_list = ['_S1', '_S2', '_S3', '_S4'].\n",
    "appendices_list = [f\"_S{i}\" for i in range(1, amount_of_slides + 1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9522c6",
   "metadata": {},
   "source": [
    "### Part 1.3 – Function to Load All Image Files for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e65479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_file_locations_S1(folder_raw_data: str, data_format: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Retrieve and list all file locations for S1 images in the specified raw data folder.\n",
    "\n",
    "    This function searches for all raw data files (based on the specified data format) \n",
    "    within the given folder and filters those containing '_S1' in their filename. \n",
    "    These represent the first slides (S1) of each brain. \n",
    "    If '_S1'/'_S2' naming is not used, '_S1' should be appended manually to filenames.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_raw_data : str\n",
    "        Path to the folder containing raw data files.\n",
    "    data_format : str\n",
    "        Format of the raw data files ('csv', 'tsv', 'xlsx' or 'feather').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    all_raw_data_file_locations_S1: list[str]\n",
    "        Sorted list of full file paths for S1 images.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the file pattern based on the data format\n",
    "    if data_format == 'csv':\n",
    "        pattern = \"*.csv\"\n",
    "    elif data_format == 'tsv':\n",
    "        pattern = \"*.tsv\"\n",
    "    elif data_format == 'xlsx':\n",
    "        pattern = \"*.xlsx\"\n",
    "    elif data_format == 'feather':\n",
    "        pattern = \"*.feather\"\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid data format specified. Please set 'data_format' to 'csv', 'tsv', 'xlsx' or 'feather'.\"\n",
    "        )\n",
    "\n",
    "    # Retrieve and sort all matching raw data files\n",
    "    all_raw_data_file_locations = glob.glob(os.path.join(folder_raw_data, pattern))\n",
    "    all_raw_data_file_locations.sort()\n",
    "\n",
    "    print(\"All raw data file locations:\")\n",
    "    for file_location in all_raw_data_file_locations:\n",
    "        print(f\" - {file_location}\")\n",
    "\n",
    "    # Filter filenames that contain '_S1' (first slides of each brain)\n",
    "    all_raw_data_file_locations_S1 = [path for path in all_raw_data_file_locations if '_S1' in path]\n",
    "\n",
    "    print(\"\\nRaw data file locations for S1 images:\")\n",
    "    for file_location_S1 in all_raw_data_file_locations_S1:\n",
    "        print(f\" - {file_location_S1}\")\n",
    "\n",
    "    return all_raw_data_file_locations_S1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c5693",
   "metadata": {},
   "source": [
    "### Part 1.4 – Function to Load the Brain Region Correction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c618cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_brainregions_to_replace(file_brainregions_to_replace: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and clean the file containing corrections for brain regions that need to be replaced for each image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_brainregions_to_replace : str\n",
    "        Path to the Excel file with columns: 'Image', 'Brainregion_Wrong', 'Brainregion_Correct'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Cleaned DataFrame with brain regions to replace for each image. \n",
    "        All brain region names are stripped of spaces and converted to uppercase.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    if not os.path.exists(file_brainregions_to_replace):\n",
    "        raise FileNotFoundError(f\"The specified file does not exist: {file_brainregions_to_replace}\")\n",
    "\n",
    "    # Load the relevant columns from the Excel file\n",
    "    df = pd.read_excel(\n",
    "        file_brainregions_to_replace,\n",
    "        usecols=['Image', 'Brainregion_Wrong', 'Brainregion_Correct'],\n",
    "        dtype={'Image': 'str', 'Brainregion_Wrong': 'str', 'Brainregion_Correct': 'str'}\n",
    "    )\n",
    "\n",
    "    # Clean the data in place\n",
    "    df['Image'] = df['Image'].str.strip()\n",
    "    df['Brainregion_Wrong'] = df['Brainregion_Wrong'].str.upper().str.strip()\n",
    "    df['Brainregion_Correct'] = df['Brainregion_Correct'].str.upper().str.strip()\n",
    "\n",
    "    print(\"The modified table of brain regions to replace for each image:\")\n",
    "    display(df)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c26c5f4",
   "metadata": {},
   "source": [
    "### Part 1.5 - Function to load the file with which brainregions were injected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf098c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_brainregions_injected(file_brainregions_injected: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and clean the file specifying which brain regions were on the injected side for each specific image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_brainregions_injected : str\n",
    "        Path to the Excel file containing injected brain region information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Cleaned DataFrame with columns:\n",
    "        - 'Image': image identifier\n",
    "        - 'Brainregion': uppercase, stripped brain region name\n",
    "        - 'Daughter1_Injected': uppercase, stripped hemisphere \n",
    "\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_brainregions_injected):\n",
    "        raise FileNotFoundError(f\"The specified file does not exist: {file_brainregions_injected}\")\n",
    "\n",
    "    # Load relevant columns from the Excel file\n",
    "    df = pd.read_excel(\n",
    "        file_brainregions_injected,\n",
    "        usecols=['Image', 'Brainregion', 'Hemisphere'],\n",
    "        dtype={'Image': 'str', 'Brainregion': 'str', 'Hemisphere': 'str'}\n",
    "    )\n",
    "\n",
    "    # Clean the data in place\n",
    "    df['Image'] = df['Image'].str.strip()\n",
    "    df['Brainregion'] = df['Brainregion'].str.upper().str.strip()\n",
    "    df['Daughter1_Injected'] = df['Hemisphere'].str.upper().str.strip()\n",
    "\n",
    "    # Drop the original 'Hemisphere' column\n",
    "    df.drop(columns=['Hemisphere'], inplace=True)\n",
    "\n",
    "    print(\"The modified table of injected brain regions for each image:\")\n",
    "    display(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1d7805",
   "metadata": {},
   "source": [
    "### Part 1.6 – Function to Load a DataFrame and Clean It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b0bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_cleaning(file_location: str, df_brainregions_to_replace: pd.DataFrame, data_format: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a data file from the given location and clean it using a brain regions replacement table.\n",
    "    If the file does not exist, an empty file is created with the correct columns.\n",
    "    Replaces incorrect brain regions, merges names by removing numbers. Returns a cleaned dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_location : str\n",
    "        Path to the raw data file for a single image.\n",
    "    df_brainregions_to_replace : pd.DataFrame\n",
    "        DataFrame specifying which brain regions need to be replaced for each image.\n",
    "    data_format : str\n",
    "        Format of the raw data file: 'csv', 'tsv', 'xlsx' or 'feather'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Cleaned dataframe with replaced brain regions and merged name columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------\n",
    "    # Define expected columns and dtypes\n",
    "    # ------------------------\n",
    "    columns = ['Image', 'Parent area name', 'Area/object name', 'Class label', 'Area (μm²)', 'Circumference (µm)']\n",
    "    dtypes = {\n",
    "        'Image': 'str',\n",
    "        'Parent area name': 'str',\n",
    "        'Area/object name': 'str',\n",
    "        'Class label': 'str',\n",
    "        'Area (μm²)': 'float64',\n",
    "        'Circumference (µm)': 'float64'\n",
    "    }\n",
    "\n",
    "    # ------------------------\n",
    "    # Load or create the data file\n",
    "    # ------------------------\n",
    "    try:\n",
    "        if data_format in ('csv', 'tsv'):\n",
    "            df = pd.read_csv(file_location, sep='\\t', usecols=columns, dtype=dtypes, index_col=False, keep_default_na=True)\n",
    "        elif data_format == 'xlsx':\n",
    "            df = pd.read_excel(file_location, usecols=columns, dtype=dtypes, index_col=False, keep_default_na=True)\n",
    "        elif data_format == 'feather':\n",
    "            df = pd.read_feather(file_location).astype(dtypes)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid data format. Choose 'csv', 'tsv', 'xlsx',or 'feather'.\")\n",
    "    except FileNotFoundError:\n",
    "        # Create empty file if it doesn't exist\n",
    "        df_empty = pd.DataFrame(columns=columns)\n",
    "        df_empty.reset_index(inplace=True)\n",
    "        if data_format in ('csv', 'tsv'):\n",
    "            df_empty.to_csv(file_location, sep='\\t', index=False)\n",
    "            df = pd.read_csv(file_location, sep='\\t', usecols=columns, dtype=dtypes)\n",
    "        elif data_format == 'xlsx':\n",
    "            df_empty.to_excel(file_location, index=False)\n",
    "            df = pd.read_excel(file_location, usecols=columns, dtype=dtypes)\n",
    "        elif data_format == 'feather':\n",
    "            df_empty.to_feather(file_location)\n",
    "            df = pd.read_feather(file_location).astype(dtypes)\n",
    "        print(f\"\\nA dataframe at location {file_location} did not exist, so an empty dataframe was created.\")\n",
    "\n",
    "    # ------------------------\n",
    "    # Standardize text columns\n",
    "    # ------------------------\n",
    "    df['Parent area name'] = df['Parent area name'].str.upper()\n",
    "    df['Area/object name'] = df['Area/object name'].str.upper()\n",
    "    df['Class label'] = df['Class label'].str.upper()\n",
    "\n",
    "    # ------------------------\n",
    "    # Extract image name from file name\n",
    "    # ------------------------\n",
    "    image_name = os.path.splitext(os.path.basename(file_location))[0]\n",
    "    print('The present image =', image_name)\n",
    "\n",
    "    # Make sure the image name across the whole first Image column is correct\n",
    "    df['Image'] = image_name\n",
    "\n",
    "    print('The full raw data =')\n",
    "    display(df)\n",
    "\n",
    "    # ------------------------\n",
    "    # Replace incorrect brain regions\n",
    "    # ------------------------\n",
    "    # Create the dictionary of brain regions that should be replaced for this specific image\n",
    "    df_replacements = df_brainregions_to_replace[df_brainregions_to_replace['Image'] == image_name]\n",
    "    dict_replace = pd.Series(\n",
    "        df_replacements.Brainregion_Correct.values,\n",
    "        index=df_replacements.Brainregion_Wrong\n",
    "    ).to_dict()\n",
    "\n",
    "    print(f\"The dictionary of brain regions to replace for {image_name} is:\", dict_replace)\n",
    "\n",
    "    df['Parent area name'] = df['Parent area name'].replace(dict_replace, regex=False)\n",
    "    df['Area/object name'] = df['Area/object name'].replace(dict_replace, regex=False)\n",
    "\n",
    "    # ------------------------\n",
    "    # Create a column 'Parent area name merged' and 'Area/object name merged' where the numbers are deleted from the original columns:\n",
    "    # ------------------------\n",
    "    df['Parent area name merged'] = df['Parent area name'].str.replace(r'\\d+$', '', regex=True).str.strip()\n",
    "    df['Area/object name merged'] = df['Area/object name'].str.replace(r'\\d+$', '', regex=True).str.strip()\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # Propagate EMPTY from parent to its descendants\n",
    "    # ---------------------------------------------\n",
    "    # Identify rows where the parent area was replaced with 'EMPTY'.\n",
    "    # Any area/object whose parent became EMPTY should also be considered EMPTY.\n",
    "    # For example, if a parent area is EMPTY, its child (and potentially further descendants) should also be marked for deletion.\n",
    "    df_empty_parent = df[df['Parent area name'] == 'EMPTY']\n",
    "    list_of_area_objects_that_should_be_empty = df_empty_parent['Area/object name'].to_list()\n",
    "    print('list_of_area_objects_that_should_be_empty =', list_of_area_objects_that_should_be_empty)\n",
    "\n",
    "    df.loc[df['Parent area name'].isin(list_of_area_objects_that_should_be_empty), \"Parent area name\"] = \"EMPTY\"\n",
    "\n",
    "    # ------------------------\n",
    "    # Remove rows where Parent or Area/object name is EMPTY\n",
    "    # ------------------------\n",
    "    df_cleaned = df[(df['Parent area name'] != 'EMPTY') & (df['Area/object name'] != 'EMPTY')]\n",
    "\n",
    "    # ------------------------\n",
    "    # Show final cleaned dataframe\n",
    "    # ------------------------\n",
    "    print('The fully cleaned table with \"Parent area name merged\", \"Area/object name merged\" and replaced brain regions:')\n",
    "    display(df_cleaned)\n",
    "\n",
    "    return df_cleaned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb5f03c",
   "metadata": {},
   "source": [
    "### Part 1.7 - Function to Create Hierarchical Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4385ca",
   "metadata": {},
   "source": [
    "The hierarchy:\n",
    "\n",
    "One type of **Parent:** TISSUE 1, 2, 3, … \\\n",
    "Many types of **Daughter 1:** AMYGDALA 1, 2, 3, …, STRIATUM 1, 2, 3, …, ...  \\\n",
    "One type of **Daughter 2:** NEUN POSITIVE AREA 1010, NEUN POSITIVE AREA 1011, … \\\n",
    "One type of **Daughter 3:** NEUN POSITIVE CELL 5495, NEUN POSITIVE CELL 5711, …"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ceabdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hierarchy(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Constructs hierarchical relationships in a dataframe.\n",
    "    The column 'Parent area name' is always the parent of the 'Area/object name' in the same row. \n",
    "    The Area (μm²) column in the row always belongs to the 'Area/object name'\n",
    "\n",
    "    The function builds four dataframes representing progressively deeper hierarchy levels:\n",
    "      1. Top-level parents (rows without their own parent)\n",
    "      2. Parent + first daughter\n",
    "      3. Parent + first + second daughter\n",
    "      4. Parent + first + second + third daughter\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input dataframe with columns \n",
    "            ['Image', 'Parent area name', 'Area/object name', 'Area/object name merged', \n",
    "             'Area (μm²)', 'Class label', 'Parent area name merged']\n",
    "\n",
    "    Returns:\n",
    "        tuple: (df_parent, df_parent_daughter1, df_parent_daughter2, df_parent_daughter3)\n",
    "            - df_parent: top-level parent areas\n",
    "            - df_parent_daughter1: parent + first daughter\n",
    "            - df_parent_daughter2: parent + first + second daughter\n",
    "            - df_parent_daughter3: parent + first + second + third daughter\n",
    "    \"\"\"\n",
    "\n",
    "    # Select top-level parents (rows without their own parent)\n",
    "    df_parent = df[df['Parent area name'].isna()].copy()\n",
    "    df_parent.rename(\n",
    "        columns={\n",
    "            'Area/object name': 'Parent name',\n",
    "            'Area/object name merged': 'Parent name merged',\n",
    "            'Area (μm²)': 'Area Parent (μm²)'\n",
    "        }, inplace=True\n",
    "    )\n",
    "    df_parent.drop(columns=['Parent area name', 'Class label', 'Parent area name merged'], inplace=True)\n",
    "\n",
    "    # Merge to add first daughter (child of top-level parents)\n",
    "    df_parent_daughter1 = df_parent.merge(\n",
    "        df[['Parent area name', 'Area/object name', 'Area/object name merged', 'Area (μm²)']],\n",
    "        left_on='Parent name', right_on='Parent area name', how='inner'\n",
    "    )\n",
    "    df_parent_daughter1.rename(\n",
    "        columns={\n",
    "            'Parent area name': 'Parent name copy',\n",
    "            'Area/object name': 'Daughter1',\n",
    "            'Area/object name merged': 'Daughter1 merged',\n",
    "            'Area (μm²)': 'Area Daughter1 (μm²)'\n",
    "        }, inplace=True\n",
    "    )\n",
    "\n",
    "    # Now there can be for instance 2 Striatum 4 rows in df_parent_daughter1. The first one is the original Striatum 4 row.\n",
    "    # The second one could originate from e.g. changing Amygdala 1 to Striatum 4 in the brainregion corrections replacement \n",
    "    # of section 1.6.\n",
    "    # We need to aggregate these 2 Striatum 4 rows into one unique row because otherwise \n",
    "    # we will double in the next join when making df_parent_daughter2.\n",
    "    df_parent_daughter1 = df_parent_daughter1.groupby('Daughter1', as_index=False).agg({\n",
    "        'Image': 'first',\n",
    "        'Parent name': 'first',\n",
    "        'Area Parent (μm²)': 'first',\n",
    "        'Parent name merged': 'first',\n",
    "        'Parent name copy': 'first',\n",
    "        'Daughter1': 'first',\n",
    "        'Daughter1 merged': 'first',\n",
    "        'Area Daughter1 (μm²)': 'sum'\n",
    "    })\n",
    "\n",
    "    # Merge to add second daughter (child of Daughter1)\n",
    "    df_parent_daughter2 = df_parent_daughter1.merge(\n",
    "        df[['Parent area name', 'Area/object name', 'Area/object name merged', 'Area (μm²)']],\n",
    "        left_on='Daughter1', right_on='Parent area name', how='inner'\n",
    "    )\n",
    "    df_parent_daughter2.rename(\n",
    "        columns={\n",
    "            'Parent area name': 'Daughter1 copy',\n",
    "            'Area/object name': 'Daughter2',\n",
    "            'Area/object name merged': 'Daughter2 merged',\n",
    "            'Area (μm²)': 'Area Daughter2 (μm²)'\n",
    "        }, inplace=True\n",
    "    )\n",
    "\n",
    "    # Merge to add third daughter (child of Daughter2)\n",
    "    df_parent_daughter3 = df_parent_daughter2.merge(\n",
    "        df[['Parent area name', 'Area/object name', 'Area/object name merged', 'Area (μm²)']],\n",
    "        left_on='Daughter2', right_on='Parent area name', how='inner'\n",
    "    )\n",
    "    df_parent_daughter3.rename(\n",
    "        columns={\n",
    "            'Parent area name': 'Daughter2 copy',\n",
    "            'Area/object name': 'Daughter3',\n",
    "            'Area/object name merged': 'Daughter3 merged',\n",
    "            'Area (μm²)': 'Area Daughter3 (μm²)'\n",
    "        }, inplace=True\n",
    "    )\n",
    "\n",
    "    return df_parent, df_parent_daughter1, df_parent_daughter2, df_parent_daughter3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae65daa",
   "metadata": {},
   "source": [
    "### Part 1.8 - Function to Calculate all Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb67fd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_calculations(df1: pd.DataFrame, df2: pd.DataFrame, df3: pd.DataFrame, groupby_column: str = 'Daughter1 merged') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute key summary statistics for hierarchical regions across three dataframes.\n",
    "\n",
    "    Each dataframe represents a different level of hierarchy:\n",
    "        - df1: Total Region Area (Daughter1 level)\n",
    "        - df2: Total NeuN Positive Area (Daughter2 level)\n",
    "        - df3: Individual cell count (Daughter3 level)\n",
    "\n",
    "    All calculations are grouped by a chosen column (default: 'Daughter1 merged').\n",
    "\n",
    "    Parameters:\n",
    "        df1 (pd.DataFrame): Region-level dataframe containing 'Area Daughter1 (μm²)'.\n",
    "        df2 (pd.DataFrame): Sub-region-level dataframe containing 'Area Daughter2 (μm²)'.\n",
    "        df3 (pd.DataFrame): Cell-level dataframe where each row corresponds to a cell.\n",
    "        groupby_column (str): Column to group by (default: 'Daughter1 merged').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Merged dataframe with:\n",
    "            - Total Region Area\n",
    "            - Total NeuN Positive Area\n",
    "            - Cell counts\n",
    "            - Extrapolated Cell Count\n",
    "            - Percentage NeuN Positive Area\n",
    "            - Cells per region area and volume (mm² and mm³)\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the total region area of each Daughter 1 merged by doing a groupby over all 'Daughter1 merged' in df_parent_daughter1. \n",
    "    # This returns e.g. the total area of Amygdala = Area Amygdala 1 + Area Amygdala 2 + ... Area Amygdala 7)\n",
    "    df_region_areas_merged = df1.groupby(groupby_column, as_index=False)['Area Daughter1 (μm²)'] \\\n",
    "                                .sum().rename(columns={'Area Daughter1 (μm²)': 'Total Region Area (μm²)',\n",
    "                                                       groupby_column: 'Merged area name'})\n",
    "\n",
    "    # Count the NeuN Positive Area (layer 3 = Daughter2 area) of the cells belonging to each Daughter1 merged\n",
    "    df_positive_areas_merged = df2.groupby(groupby_column, as_index=False)['Area Daughter2 (μm²)'] \\\n",
    "                                  .sum().rename(columns={'Area Daughter2 (μm²)': 'Total NeuN Positive Area (μm²)',\n",
    "                                                         groupby_column: 'Merged area name'})\n",
    "\n",
    "    # Count the number of rows (each row has a cell name like NEUN POSITIVE CELL 29144 in Daughter 3, \n",
    "    # corresponding to layer 4) for each Daughter 1 merged\n",
    "    df_positive_counts = df3[groupby_column].value_counts(sort=True) \\\n",
    "                             .rename_axis('Merged area name').reset_index(name='Counts')\n",
    "\n",
    "    # Merge all intermediate results\n",
    "    dfs_to_merge = [df_region_areas_merged, df_positive_areas_merged, df_positive_counts]\n",
    "    df_all_calcs_merged = functools.reduce(\n",
    "        lambda left, right: pd.merge(left, right, on='Merged area name', how='outer'),\n",
    "        dfs_to_merge\n",
    "    )\n",
    "\n",
    "    # Replace NaN in numeric columns with 0\n",
    "    numeric_cols = df_all_calcs_merged.select_dtypes(include='number').columns\n",
    "    df_all_calcs_merged[numeric_cols] = df_all_calcs_merged[numeric_cols].fillna(0)\n",
    "\n",
    "    # Derived calculations\n",
    "    df_all_calcs_merged['Extrapolated Cell Count'] = df_all_calcs_merged['Counts'] * spacing\n",
    "    df_all_calcs_merged['Percentage NeuN Positive Area'] = \\\n",
    "        100 * df_all_calcs_merged['Total NeuN Positive Area (μm²)'] / df_all_calcs_merged['Total Region Area (μm²)']\n",
    "    df_all_calcs_merged['Cells/Region Area (per μm²)'] = \\\n",
    "        df_all_calcs_merged['Counts'] / df_all_calcs_merged['Total Region Area (μm²)']\n",
    "    df_all_calcs_merged['Cells/Region Volume (per μm³)'] = \\\n",
    "        df_all_calcs_merged['Cells/Region Area (per μm²)'] / section_thickness\n",
    "    df_all_calcs_merged['Cells/Region Area (mm²)'] = \\\n",
    "        df_all_calcs_merged['Cells/Region Area (per μm²)'] * 1e6\n",
    "    df_all_calcs_merged['Cells/Region Volume (mm³)'] = \\\n",
    "        df_all_calcs_merged['Cells/Region Volume (per μm³)'] * 1e9\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df_all_calcs_merged.drop(columns=['Cells/Region Area (per μm²)', 'Cells/Region Volume (per μm³)'], inplace=True)\n",
    "\n",
    "    # Sort for readability\n",
    "    df_all_calcs_merged.sort_values('Merged area name', inplace=True)\n",
    "\n",
    "    print(f'The total calculations of each {groupby_column}:')\n",
    "    display(df_all_calcs_merged)\n",
    "\n",
    "    return df_all_calcs_merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c6f554",
   "metadata": {},
   "source": [
    "## Part 2 - Automatic Analysis of all X*N Slides of all N Brains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3451b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Measure execution time of this cell\n",
    "\n",
    "# Load the file specifying brain regions to replace/delete for each image\n",
    "df_brainregions_to_replace = load_data_brainregions_to_replace(file_brainregions_to_replace)\n",
    "\n",
    "# Get all file names containing '_S1' (first images of all N brains)\n",
    "all_raw_data_file_locations_S1 = load_all_file_locations_S1(folder_raw_data, data_format)\n",
    "\n",
    "# Initialize dictionary to store overview dataframes\n",
    "dictionary_overview_dataframes = {}\n",
    "\n",
    "# Loop over all S1 images in the raw_data folder\n",
    "for count, file_location_S1 in enumerate(all_raw_data_file_locations_S1):\n",
    "\n",
    "    print(f'\\nAnalysis of {file_location_S1}')\n",
    "\n",
    "    # Extract image name from file path\n",
    "    image_name_S1 = os.path.splitext(os.path.basename(file_location_S1))[0]\n",
    "\n",
    "    # Dictionaries to store cleaned dataframes and hierarchical data for all appendices\n",
    "    dict_df_SX_final = {}              # {'_S1': df_S1_final, ..., '_SX': df_SX_final}\n",
    "    dict_df_SX_parent = {}             # {'_S1': df_S1_parent, ..., '_SX': df_SX_parent}\n",
    "    dict_df_SX_parent_daughter1 = {}   # {'_S1': df_S1_parent_daughter1, ..., '_SX': df_SX_parent_daughter1}\n",
    "    dict_df_SX_parent_daughter2 = {}   # {'_S1': df_S1_parent_daughter2, ..., '_SX': df_SX_parent_daughter2}\n",
    "    dict_df_SX_parent_daughter3 = {}   # {'_S1': df_S1_parent_daughter3, ..., '_SX': df_SX_parent_daughter3}\n",
    "    dict_df_SX_all_calcs_merged = {}   # {'_S1': df_S1_all_calcs_merged, ..., '_SX': df_SX_all_calcs_merged}\n",
    "\n",
    "    # Loop over all appendices ('_S1', '_S2', ..., '_SX')\n",
    "    for appendix in appendices_list:\n",
    "        # Replace '_S1' in the file path with the current appendix\n",
    "        file_location = file_location_S1.replace('_S1', appendix)\n",
    "\n",
    "        # Clean data and generate hierarchical dataframes\n",
    "        dict_df_SX_final[appendix] = dataframe_cleaning(file_location, df_brainregions_to_replace, data_format)\n",
    "        (\n",
    "            dict_df_SX_parent[appendix],\n",
    "            dict_df_SX_parent_daughter1[appendix],\n",
    "            dict_df_SX_parent_daughter2[appendix],\n",
    "            dict_df_SX_parent_daughter3[appendix]\n",
    "        ) = make_hierarchy(dict_df_SX_final[appendix])\n",
    "\n",
    "        # Perform all calculations for each appendix\n",
    "        # The except part is for when we have made an empty dataframe because no dataframe was available (will never be the case for appendix =_S1).\n",
    "        try:\n",
    "            dict_df_SX_all_calcs_merged[appendix] = all_calculations(\n",
    "                dict_df_SX_parent_daughter1[appendix],\n",
    "                dict_df_SX_parent_daughter2[appendix],\n",
    "                dict_df_SX_parent_daughter3[appendix]\n",
    "            )\n",
    "            print(f\"All calculations completed for {appendix} of {file_location}\")\n",
    "            display(dict_df_SX_all_calcs_merged[appendix])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Concatenate all cleaned and hierarchical dataframes (S1+S2+...+SX)\n",
    "    df_SX_final_concat = pd.concat(dict_df_SX_final.values(), axis=0)\n",
    "    df_SX_parent_daughter1_concat = pd.concat(dict_df_SX_parent_daughter1.values(), axis=0)\n",
    "    df_SX_parent_daughter2_concat = pd.concat(dict_df_SX_parent_daughter2.values(), axis=0)\n",
    "    df_SX_parent_daughter3_concat = pd.concat(dict_df_SX_parent_daughter3.values(), axis=0)\n",
    "\n",
    "    # Perform all calculations for the concatenated SX data\n",
    "    try:\n",
    "        df_SX_all_calcs_concat = all_calculations(\n",
    "            df_SX_parent_daughter1_concat,\n",
    "            df_SX_parent_daughter2_concat,\n",
    "            df_SX_parent_daughter3_concat\n",
    "        )\n",
    "        print(f'All calculations completed for concatenated S1+S2+...+SX of {file_location_S1}')\n",
    "        display(df_SX_all_calcs_concat)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Save individual and concatenated results to Excel\n",
    "    output_file_location_SX = os.path.join(\n",
    "        folder_output_results,\n",
    "        image_name_S1.replace('_S1', '_SX') + '_Results.xlsx'\n",
    "    )\n",
    "\n",
    "    with pd.ExcelWriter(output_file_location_SX) as writer:\n",
    "        for appendix in appendices_list:\n",
    "            try:\n",
    "                dict_df_SX_all_calcs_merged[appendix].to_excel(\n",
    "                    writer, sheet_name=appendix[1:] + '_Results', index=False, float_format=\"%.3f\"\n",
    "                )\n",
    "            except:\n",
    "                pass  # No SX dataframe was available, skipping empty entries\n",
    "\n",
    "        df_SX_all_calcs_concat.to_excel(\n",
    "            writer, sheet_name='SX_Combined_Results', index=False, float_format=\"%.3f\"\n",
    "        )\n",
    "\n",
    "    # Define calculation columns for overview\n",
    "    list_calculation_results = [\n",
    "        'Total Region Area (μm²)', 'Total NeuN Positive Area (μm²)', 'Counts',\n",
    "        'Extrapolated Cell Count', 'Cells/Region Area (mm²)',\n",
    "        'Cells/Region Volume (mm³)', 'Percentage NeuN Positive Area'\n",
    "    ]\n",
    "\n",
    "    # Prepare overview dataframes (for Overview_NeuN_Results.xlsx)\n",
    "    # We will make 1 overview excelfile with a few tabpages that we store in dictionary_overview_dataframes:\n",
    "    # dictionary_overview_dataframes = {Total Region Area: df, Total NeuN Positive Area: df, Extrapolated Cell Count:df, Cells/Region Area:df, .... }\n",
    "    for calculation_result in list_calculation_results:\n",
    "        df_calc = df_SX_all_calcs_concat[['Merged area name', calculation_result]].copy()\n",
    "        df_calc.rename(\n",
    "            columns={calculation_result: image_name_S1.replace('_NeuN', '').replace('_S1', '')}, inplace=True\n",
    "        )\n",
    "\n",
    "        if count == 0:\n",
    "            dictionary_overview_dataframes[calculation_result] = df_calc.copy()\n",
    "        else:\n",
    "            dictionary_overview_dataframes[calculation_result] = dictionary_overview_dataframes[\n",
    "                calculation_result\n",
    "            ].merge(df_calc, how='outer', on='Merged area name')\n",
    "\n",
    "    # Clean up memory for next iteration\n",
    "    del dict_df_SX_final, dict_df_SX_parent, dict_df_SX_parent_daughter1\n",
    "    del dict_df_SX_parent_daughter2, dict_df_SX_parent_daughter3\n",
    "    del df_SX_final_concat, df_SX_all_calcs_concat\n",
    "\n",
    "# Save overview Excel file\n",
    "output_file_name_overview = os.path.join(folder_output_results, 'Overview_NeuN_Results.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(output_file_name_overview) as writer:\n",
    "    for calculation_result in list_calculation_results:\n",
    "        sheet_name_clean = calculation_result.replace('/', ' per ').replace('Volume', 'Vol')\n",
    "\n",
    "        print(f'Overview dataframe with all {sheet_name_clean} for all brains')\n",
    "        display(dictionary_overview_dataframes[calculation_result])\n",
    "\n",
    "        dictionary_overview_dataframes[calculation_result].to_excel(\n",
    "            writer, sheet_name=sheet_name_clean, index=False, float_format=\"%.3f\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf99a802",
   "metadata": {},
   "source": [
    "## Part 3 – Automatic Analysis of all N S1 Slides of all N Brains (Including Injected and Uninjected Hemispheres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e710fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Measure execution time of this cell\n",
    "\n",
    "# Load the file specifying brain regions to replace/delete for each image\n",
    "df_brainregions_to_replace = load_data_brainregions_to_replace(file_brainregions_to_replace)\n",
    "\n",
    "# Load the file specifying which brain regions belong to each hemisphere\n",
    "df_brainregions_injected = load_data_brainregions_injected(file_brainregions_injected)\n",
    "\n",
    "# Get all file names containing '_S1' (first images of all N brains)\n",
    "all_raw_data_file_locations_S1 = load_all_file_locations_S1(folder_raw_data, data_format)\n",
    "\n",
    "# Initialize dictionary to store overview dataframes for injected analysis\n",
    "dictionary_overview_dataframes_injected = {}\n",
    "\n",
    "# Loop over all S1 images in the raw_data folder\n",
    "for count, file_location_S1 in enumerate(all_raw_data_file_locations_S1):\n",
    "\n",
    "    print(f'\\nAnalysis of {file_location_S1}')\n",
    "\n",
    "    # Extract image name from file path\n",
    "    image_name_S1 = os.path.splitext(os.path.basename(file_location_S1))[0]\n",
    "\n",
    "    # Dictionaries to store cleaned and hierarchical dataframes for all appendices\n",
    "    dict_df_SX_final = {}              # {'_S1': df_S1_final, ..., '_SX': df_SX_final}\n",
    "    dict_df_SX_parent = {}             # {'_S1': df_S1_parent, ..., '_SX': df_SX_parent}\n",
    "    dict_df_SX_parent_daughter1 = {}   # {'_S1': df_S1_parent_daughter1, ..., '_SX': df_SX_parent_daughter1}\n",
    "    dict_df_SX_parent_daughter2 = {}   # {'_S1': df_S1_parent_daughter2, ..., '_SX': df_SX_parent_daughter2}\n",
    "    dict_df_SX_parent_daughter3 = {}   # {'_S1': df_S1_parent_daughter3, ..., '_SX': df_SX_parent_daughter3}\n",
    "\n",
    "    # Loop over all appendices ('_S1', '_S2', ..., '_SX')\n",
    "    for appendix in appendices_list:\n",
    "        # Replace '_S1' in the file path with the current appendix\n",
    "        file_location = file_location_S1.replace('_S1', appendix)\n",
    "\n",
    "        # Clean data and generate hierarchical dataframes\n",
    "        dict_df_SX_final[appendix] = dataframe_cleaning(file_location, df_brainregions_to_replace, data_format)\n",
    "        (\n",
    "            dict_df_SX_parent[appendix],\n",
    "            dict_df_SX_parent_daughter1[appendix],\n",
    "            dict_df_SX_parent_daughter2[appendix],\n",
    "            dict_df_SX_parent_daughter3[appendix]\n",
    "        ) = make_hierarchy(dict_df_SX_final[appendix])\n",
    "\n",
    "    # Concatenate all cleaned and hierarchical dataframes (S1+S2+...+SX)\n",
    "    df_SX_final_concat = pd.concat(dict_df_SX_final.values(), axis=0)\n",
    "    df_SX_parent_daughter1_concat = pd.concat(dict_df_SX_parent_daughter1.values(), axis=0)\n",
    "    df_SX_parent_daughter2_concat = pd.concat(dict_df_SX_parent_daughter2.values(), axis=0)\n",
    "    df_SX_parent_daughter3_concat = pd.concat(dict_df_SX_parent_daughter3.values(), axis=0)\n",
    "\n",
    "    # Merge with hemisphere injection information\n",
    "    # For each dataframe, this determines whether the Daughter1 region was injected or uninjected\n",
    "    # Brain regions not relevant to the injected analysis are removed through the inner join\n",
    "    df_SX_final_injected = df_SX_final_concat.merge(\n",
    "        df_brainregions_injected, left_on=['Image', 'Area/object name'], right_on=['Image', 'Brainregion'], how='inner'\n",
    "    )\n",
    "    df_SX_parent_daughter1_injected = df_SX_parent_daughter1_concat.merge(\n",
    "        df_brainregions_injected, left_on=['Image', 'Daughter1'], right_on=['Image', 'Brainregion'], how='inner'\n",
    "    )\n",
    "    df_SX_parent_daughter2_injected = df_SX_parent_daughter2_concat.merge(\n",
    "        df_brainregions_injected, left_on=['Image', 'Daughter1'], right_on=['Image', 'Brainregion'], how='inner'\n",
    "    )\n",
    "    df_SX_parent_daughter3_injected = df_SX_parent_daughter3_concat.merge(\n",
    "        df_brainregions_injected, left_on=['Image', 'Daughter1'], right_on=['Image', 'Brainregion'], how='inner'\n",
    "    )\n",
    "\n",
    "    # Perform all calculations for concatenated SX injected data\n",
    "    try:\n",
    "        df_SX_all_calcs_injected = all_calculations(\n",
    "            df_SX_parent_daughter1_injected,\n",
    "            df_SX_parent_daughter2_injected,\n",
    "            df_SX_parent_daughter3_injected,\n",
    "            groupby_column='Daughter1_Injected'\n",
    "        )\n",
    "        df_SX_all_calcs_injected.sort_values('Merged area name', ascending=False, inplace=True)\n",
    "        print(f'All calculations completed for concatenated SX INJECTED of {file_location_S1}')\n",
    "        display(df_SX_all_calcs_injected)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Save individual results to Excel\n",
    "    output_file_location_SX = os.path.join(\n",
    "        folder_output_results_injected,\n",
    "        image_name_S1.replace('_S1', '_SX') + '_Hemisphere_Results.xlsx'\n",
    "    )\n",
    "\n",
    "    with pd.ExcelWriter(output_file_location_SX) as writer:\n",
    "        df_SX_all_calcs_injected.to_excel(\n",
    "            writer, sheet_name='SX_Hemisphere_Results', index=False, float_format=\"%.3f\"\n",
    "        )\n",
    "\n",
    "    # Define calculation columns for overview\n",
    "    list_calculation_results = [\n",
    "        'Total Region Area (μm²)', 'Total NeuN Positive Area (μm²)', 'Counts',\n",
    "        'Extrapolated Cell Count', 'Cells/Region Area (mm²)',\n",
    "        'Cells/Region Volume (mm³)', 'Percentage NeuN Positive Area'\n",
    "    ]\n",
    "\n",
    "    # Prepare overview dataframes (for Overview_NeuN_Hemisphere_Results.xlsx)\n",
    "    # We will make 1 overview excelfile with a few tabpages that we store in dictionary_overview_dataframes:\n",
    "    # dictionary_overview_dataframes = {Total Region Area: df, Total NeuN Positive Area: df, Extrapolated Cell Count:df, Cells/Region Area:df, .... }\n",
    "\n",
    "    for calculation_result in list_calculation_results:\n",
    "        df_calc = df_SX_all_calcs_injected[['Merged area name', calculation_result]].copy()\n",
    "        df_calc.rename(\n",
    "            columns={calculation_result: image_name_S1.replace('_NeuN', '').replace('_S1', '')}, inplace=True\n",
    "        )\n",
    "        \n",
    "        if count == 0:\n",
    "            dictionary_overview_dataframes_injected[calculation_result] = df_calc.copy()\n",
    "        else:\n",
    "            dictionary_overview_dataframes_injected[calculation_result] = dictionary_overview_dataframes_injected[\n",
    "                calculation_result\n",
    "            ].merge(df_calc, how='outer', on='Merged area name')\n",
    "\n",
    "    # Clean up memory for next iteration\n",
    "    del dict_df_SX_final, dict_df_SX_parent, dict_df_SX_parent_daughter1\n",
    "    del dict_df_SX_parent_daughter2, dict_df_SX_parent_daughter3\n",
    "    del df_SX_final_concat, df_SX_all_calcs_injected\n",
    "\n",
    "# Save overview Excel file\n",
    "output_file_name_overview = os.path.join(folder_output_results_injected, 'Overview_NeuN_Hemisphere_Results.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(output_file_name_overview) as writer:\n",
    "    for calculation_result in list_calculation_results:\n",
    "        sheet_name_clean = calculation_result.replace('/', ' per ').replace('Volume', 'Vol')\n",
    "        dictionary_overview_dataframes_injected[calculation_result].sort_values('Merged area name', ascending=False, inplace=True)\n",
    "\n",
    "        print(f'Overview dataframe with all {sheet_name_clean} for all brains')\n",
    "        display(dictionary_overview_dataframes_injected[calculation_result])\n",
    "\n",
    "        dictionary_overview_dataframes_injected[calculation_result].to_excel(\n",
    "            writer, sheet_name=sheet_name_clean, index=False, float_format=\"%.3f\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
