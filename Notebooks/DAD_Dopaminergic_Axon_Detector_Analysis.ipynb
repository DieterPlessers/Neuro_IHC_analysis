{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8160eb4",
   "metadata": {},
   "source": [
    "# Analysis of Aiforia Dopaminergic Axons \n",
    "\n",
    "## Part 0 - Outline\n",
    "This code handles the automatic processing of raw data from mouse brains analyzed using the Aiforia model “Dopaminergic Axon Detector”. The data are stored in a local folder on the computer, specified within the code. We typically start with Excel files. To automatically change the format of multiple files, please refer to the notebook Change_Name_Format_Input_Data.ipynb.\n",
    "This notebook is organized into three sections:\n",
    "\n",
    "**1) Define Functions for Part 2 & 3**\n",
    "\n",
    "**2) Automatic Analysis of N Slides (with Names Containing _S1) Across N Brains**\n",
    "\n",
    "In this section, we automate the analysis of all N S1 slides corresponding to N brains (one slide per brain) contained in the folder with raw data. The approach is as follows:\n",
    "\n",
    "1) All N filenames containing _S1 are collected from the folder and stored in a list.\n",
    "\n",
    "2) For each slide (one per brain), the following steps are performed:\n",
    "    a) Data analysis steps are executed.\n",
    "    b) The results are exported to an Excel file specific to that brain.\n",
    "    \n",
    "After each loop iteration, the results for the current brain are added to an overview table containing the combined results for all brains. After the final loop, this overview table is also exported to an Excel file.\n",
    "\n",
    "Note: In this section, we do not generate detailed “transposed” tables with information for each Striatum part.\n",
    "\n",
    "**3) Automatic Analysis of N Slides (with Names Containing _S1) After Determining the (Un)Injected Areas**\n",
    "\n",
    "In this section, we extend the analysis by identifying which brain regions are on the injected versus non-injected side. The comparison between both sides follows the same analysis workflow as in Section 2. Additionally, in this section we generate more detailed **transposed tables** containing information for each Striatum part for easier analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8949a9bf",
   "metadata": {},
   "source": [
    "## Part 1 - Define the necessary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f259ca",
   "metadata": {},
   "source": [
    "### Part 1.1 - Load all necessary Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f298f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Pandas display options\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a2fd6",
   "metadata": {},
   "source": [
    "### Part 1.2 - Data Locations\n",
    "\n",
    "**TO DO:**\n",
    "\n",
    "Specify the following paths before running the analysis:\n",
    "\n",
    "1) **Raw data format:** choose the file format of the raw data (e.g.: excel, csv).\n",
    "2) **Some experimental parameters:** spacing between sections and section thickness.\n",
    "3) **Raw data folder:** the folder containing the original data files exported from Aiforia.\n",
    "4) **Results folders:** the folders where the Excel files with processed results will be saved.\n",
    "5) **Region mapping files:** the location of the Excel files that specify which brain regions have to be replaced and were (un)injected.\n",
    "\n",
    "Use the following format to define each path: <font color='darkred'>r'file_location'</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae8930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify what data format you want to use for your raw data: excel, csv or feather. Do this by uncommenting the data_format that you want.\n",
    "# data_format = 'excel'\n",
    "data_format = 'csv'\n",
    "# data_format = 'feather'\n",
    "\n",
    "# Specify the experimental parameters (section_thickness in micrometers!!) \n",
    "spacing=12\n",
    "section_thickness = 40\n",
    "\n",
    "# Specify folder locations\n",
    "folder_raw_data = r'C:\\Users\\...\\Raw_data_TH_Axon'\n",
    "folder_output_results = r'C:\\Users\\...\\Output_Results_TH_Axon'\n",
    "folder_output_results_injected = r'C:\\Users\\...\\Output_Results_Injected_TH_Axon'\n",
    "file_brainregions_to_replace =  r'C:\\Users\\...\\Brainregions_To_Replace_TH_Axon.xlsx'\n",
    "file_brainregions_injected =  r'C:\\Users\\...\\Brainregions_Hemisphere_TH_Axon.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a443bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folders if they did not exist yet\n",
    "if not os.path.isdir(folder_output_results):\n",
    "    os.mkdir(folder_output_results)\n",
    "if not os.path.isdir(folder_output_results_injected):\n",
    "    os.mkdir(folder_output_results_injected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c8fe9d",
   "metadata": {},
   "source": [
    "### Part 1.3 – Function to Load All Image Files for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d03a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_file_locations_S1(folder_raw_data: str, data_format: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Create a list of all file locations for S1 images in the specified folder. \n",
    "    It is assumed that only S1 images are present in the folder, so '_S1' does not need to be in the filename here.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_raw_data : str\n",
    "        Path to the folder containing raw data files.\n",
    "    data_format : str\n",
    "        Format of the raw data files ('excel', 'csv', or 'feather').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    all_raw_data_file_locations_S1: list[str]\n",
    "        Sorted list of full file paths for S1 images.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Determine the file pattern based on the data format\n",
    "    if data_format == 'excel':\n",
    "        pattern = \"*.xlsx\"\n",
    "    elif data_format == 'csv':\n",
    "        pattern = \"*.csv\"\n",
    "    elif data_format == 'feather':\n",
    "        pattern = \"*.feather\"\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid data format specified. Please set 'data_format' to 'excel', 'csv', or 'feather'.\"\n",
    "        )\n",
    "    \n",
    "    # Get all matching files and sort them\n",
    "    all_raw_data_file_locations_S1 = glob.glob(os.path.join(folder_raw_data, pattern))\n",
    "    all_raw_data_file_locations_S1.sort()\n",
    "    \n",
    "    # Print the locations\n",
    "    print(\"The location of all raw data files:\")\n",
    "    for file_location in all_raw_data_file_locations_S1:\n",
    "        print(f\" - {file_location}\")\n",
    "    \n",
    "    return all_raw_data_file_locations_S1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f28be4e",
   "metadata": {},
   "source": [
    "### Part 1.4 – Function to Load the Brain Region Correction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f5974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_brainregions_to_replace(file_brainregions_to_replace: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and clean the file containing corrections for brain regions that need to be replaced for each image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_brainregions_to_replace : str\n",
    "        Path to the Excel file with columns: 'Image', 'Brainregion_Wrong', 'Brainregion_Correct'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Cleaned DataFrame with brain regions to replace for each image. \n",
    "        All brain region names are stripped of spaces and converted to uppercase.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    if not os.path.exists(file_brainregions_to_replace):\n",
    "        raise FileNotFoundError(f\"The specified file does not exist: {file_brainregions_to_replace}\")\n",
    "\n",
    "    # Load the relevant columns from the Excel file\n",
    "    df = pd.read_excel(\n",
    "        file_brainregions_to_replace,\n",
    "        usecols=['Image', 'Brainregion_Wrong', 'Brainregion_Correct'],\n",
    "        dtype={'Image': 'str', 'Brainregion_Wrong': 'str', 'Brainregion_Correct': 'str'}\n",
    "    )\n",
    "\n",
    "    # Clean the data in place\n",
    "    df['Image'] = df['Image'].str.strip()\n",
    "    df['Brainregion_Wrong'] = df['Brainregion_Wrong'].str.upper().str.strip()\n",
    "    df['Brainregion_Correct'] = df['Brainregion_Correct'].str.upper().str.strip()\n",
    "\n",
    "    print(\"The modified table of brain regions to replace for each image:\")\n",
    "    display(df)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ec28a",
   "metadata": {},
   "source": [
    "### Part 1.5 – Function to Load the File Indicating Which Brain Regions Were Injected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfb5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_brainregions_injected(file_brainregions_injected: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and clean the file specifying which brain regions were on the injected side for each specific image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_brainregions_injected : str\n",
    "        Path to the Excel file containing injected brain region information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Cleaned DataFrame with columns:\n",
    "        - 'Image': image identifier\n",
    "        - 'Brainregion': uppercase, stripped brain region name\n",
    "        - 'Region_Hemisphere': uppercase, stripped hemisphere (injected side)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_brainregions_injected):\n",
    "        raise FileNotFoundError(f\"The specified file does not exist: {file_brainregions_injected}\")\n",
    "\n",
    "    # Load relevant columns from the Excel file\n",
    "    df = pd.read_excel(\n",
    "        file_brainregions_injected,\n",
    "        usecols=['Image', 'Brainregion', 'Hemisphere'],\n",
    "        dtype={'Image': 'str', 'Brainregion': 'str', 'Hemisphere': 'str'}\n",
    "    )\n",
    "\n",
    "    # Clean the data in place\n",
    "    df['Image'] = df['Image'].str.strip()\n",
    "    df['Brainregion'] = df['Brainregion'].str.upper().str.strip()\n",
    "    df['Region_Hemisphere'] = df['Hemisphere'].str.upper().str.strip()\n",
    "    \n",
    "    # Drop the original 'Hemisphere' column\n",
    "    df.drop(columns=['Hemisphere'], inplace=True)\n",
    "\n",
    "    print(\"The modified table of injected brain regions for each image:\")\n",
    "    display(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67414c4e",
   "metadata": {},
   "source": [
    "### Part 1.6 – Function to Load a DataFrame and Clean It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68deb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_cleaning(file_location: str, df_brainregions_to_replace: pd.DataFrame, data_format: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a raw data file for a specific image and clean it using the brain regions replacement table.\n",
    "    Outputs a cleaned dataframe with additional calculated values like 'Lightness' and 'Intensity'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_location : str\n",
    "        Path to the raw data file for a single image.\n",
    "    df_brainregions_to_replace : pd.DataFrame\n",
    "        DataFrame specifying which brain regions need to be replaced for each image.\n",
    "    data_format : str\n",
    "        Format of the raw data file: 'excel', 'csv', or 'feather'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Cleaned dataframe with additional calculated columns.\n",
    "    \"\"\"\n",
    "    # ------------------------\n",
    "    # Load the raw data\n",
    "    # ------------------------\n",
    "    columns = ['Image', 'Area/object name', 'Area (μm²)', 'B', 'G', 'R']\n",
    "    \n",
    "    dtypes = {\n",
    "        'Image': 'str',\n",
    "        'Area/object name': 'str',\n",
    "        'Area (μm²)': 'float64',\n",
    "        'B': 'float64',\n",
    "        'G': 'float64',\n",
    "        'R': 'float64'\n",
    "    }\n",
    "    \n",
    "    if data_format == 'excel':\n",
    "        df = pd.read_excel(file_location, usecols=columns, dtype=dtypes, keep_default_na=True)\n",
    "    elif data_format == 'csv':\n",
    "        df = pd.read_csv(file_location, sep='\\t', usecols=columns, dtype=dtypes, keep_default_na=True)\n",
    "    elif data_format == 'feather':\n",
    "        df = pd.read_feather(file_location)\n",
    "        df = df.astype(dtypes)  # Ensure consistent column types\n",
    "    else:\n",
    "        raise ValueError(\"Invalid data format. Choose 'excel', 'csv', or 'feather'.\")\n",
    "\n",
    "\n",
    "    # ------------------------\n",
    "    # Get image name from file name\n",
    "    # ------------------------\n",
    "    image_name = os.path.splitext(os.path.basename(file_location))[0]\n",
    "    print('The present image =', image_name)\n",
    "    df['Image'] = image_name  # Make sure the image name across the whole first column is correct\n",
    "\n",
    "    # ------------------------\n",
    "    # Clean and standardize names\n",
    "    # ------------------------\n",
    "    # Capitalize to never make mistakes against capitalization\n",
    "    df['Area/object name'] = df['Area/object name'].str.upper()\n",
    "\n",
    "    # Brain tissue detector rows are not needed\n",
    "    df = df[~df['Area/object name'].str.contains(\"BRAIN TISSUE DETECTOR\")]\n",
    "\n",
    "    # ------------------------\n",
    "    # Replace incorrect brain regions\n",
    "    # ------------------------\n",
    "    # Create the dictionary of brain regions that should be replaced for this specific image\n",
    "    df_image_replacements = df_brainregions_to_replace[df_brainregions_to_replace['Image'] == image_name]\n",
    "    dict_replace = pd.Series(\n",
    "        df_image_replacements.Brainregion_Correct.values,\n",
    "        index=df_image_replacements.Brainregion_Wrong\n",
    "    ).to_dict()\n",
    "    print(f\"The dictionary of brain regions to replace for {image_name} is:\", dict_replace)\n",
    "\n",
    "    # Replace the value in the rows that have an Area/object name that is in dict_replace\n",
    "    df['Area/object name'] = df['Area/object name'].replace(dict_replace, regex=False)\n",
    "    \n",
    "    #Remove rows where 'Area/object name' was replaced with 'EMPTY'\n",
    "    df = df[df['Area/object name'] != 'EMPTY']\n",
    "    \n",
    "    # ------------------------\n",
    "    # Merge similar area names by removing numbers\n",
    "    # ------------------------\n",
    "    df['Area/object name merged'] = df['Area/object name'].str.replace(r'\\d+$', '', regex=True).str.strip()\n",
    "\n",
    "    # ------------------------\n",
    "    # Calculate Lightness and Intensity\n",
    "    # ------------------------\n",
    "    # Convert RGB values to grey scale intensity\n",
    "    # The higher the 'lightness' value, the lighter the image as white is RGB=(255,255,255) and black = RGB(0,0,0). \n",
    "    # We use a scale 0 to 100, but boils down to the same.\n",
    "    df['Lightness'] = 0.299*df['R'] + 0.587*df['G'] + 0.114*df['B']  # Standard grayscale conversion\n",
    "    df['Intensity'] = 100 - df['Lightness']  # Higher Intensity = darker/more intense\n",
    "\n",
    "    print('The full cleaned data =')\n",
    "    display(df)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924a1cb-9b58-4d5a-b16d-695ef7c4a39f",
   "metadata": {},
   "source": [
    "### Part 1.7 – Function to Calculate All Statistics (Disregarding Injected/Non-Injected Sides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056870c2-05b9-4c86-b60d-47a63083a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_calculations(df: pd.DataFrame, section_thickness: float, spacing: float, groupby_column: str = 'Area/object name merged') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate total area, weighted intensity, and volume for each Area/object name merged.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Cleaned dataframe for a single image containing at least:\n",
    "        'Area/object name merged', 'Area (μm²)', 'Intensity'.\n",
    "    groupby_column : str, optional\n",
    "        Column to group by for calculations (default is 'Area/object name merged').\n",
    "    section_thickness : float\n",
    "        Thickness of each section in μm.\n",
    "    spacing : float\n",
    "        Spacing between sections in μm.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with total area, weighted intensity, and calculated volume for each region.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import functools\n",
    "\n",
    "    # ------------------------\n",
    "    # Count number of objects per region\n",
    "    # ------------------------\n",
    "    df_counts = df.value_counts(groupby_column, sort=True).reset_index(name='Counts')\n",
    "\n",
    "    # ------------------------\n",
    "    # Calculate total area per region\n",
    "    # ------------------------\n",
    "    df_total_area = (\n",
    "        df.groupby(groupby_column)\n",
    "          .sum(numeric_only=True)['Area (μm²)']\n",
    "          .rename_axis(groupby_column)\n",
    "          .reset_index(name='Total Region Area (μm²)')\n",
    "    )\n",
    "\n",
    "    # ------------------------\n",
    "    # Calculate weighted intensity per region \n",
    "    # ------------------------\n",
    "    df_weighted_intensity = (\n",
    "        df.groupby(groupby_column)[['Intensity', 'Area (μm²)']]\n",
    "          .apply(lambda x: (x['Intensity'] * x['Area (μm²)']).sum() / x['Area (μm²)'].sum())\n",
    "          .rename_axis(groupby_column)\n",
    "          .reset_index(name='Weighted Intensity')\n",
    "    )\n",
    "\n",
    "    # ------------------------\n",
    "    # Merge all calculated results\n",
    "    # ------------------------\n",
    "    df_all_calcs = functools.reduce(\n",
    "        lambda left, right: pd.merge(left, right, on=groupby_column, how='outer'),\n",
    "        [df_counts, df_total_area, df_weighted_intensity]\n",
    "    )\n",
    "\n",
    "    # Convert units and calculate volume\n",
    "    df_all_calcs['Total Region Area (mm²)'] = df_all_calcs['Total Region Area (μm²)'] / 1_000_000\n",
    "    df_all_calcs['Total Region Volume (mm³)'] = df_all_calcs['Total Region Area (mm²)'] * (section_thickness / 1000) * spacing\n",
    "\n",
    "    # Drop original μm² column and sort by region name\n",
    "    df_all_calcs.drop(columns=['Total Region Area (μm²)'], inplace=True)\n",
    "    df_all_calcs.sort_values(by=[groupby_column], ascending=False, inplace=True)\n",
    "\n",
    "    print('Calculations for each Area/object name merged:')\n",
    "    display(df_all_calcs)\n",
    "\n",
    "    return df_all_calcs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca7d33",
   "metadata": {},
   "source": [
    "### Part 1.8 – Function to Calculate All Statistics for Injected/Uninjected Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ae8b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_calculations_injected(df: pd.DataFrame, section_thickness: float, spacing: float, groupby_column: str = 'Region_Hemisphere') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate total area, weighted intensity, and volume for each hemisphere region,\n",
    "    distinguishing injected vs. uninjected sides.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Cleaned dataframe containing at least 'Region_Hemisphere', 'Area (μm²)', and 'Intensity'.\n",
    "    groupby_column : str, optional\n",
    "        Column to group by for calculations (default 'Region_Hemisphere').\n",
    "    section_thickness : float\n",
    "        Thickness of each section in μm (must be provided).\n",
    "    spacing : float\n",
    "        Spacing between sections in μm (must be provided).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with total area, weighted intensity, and calculated volume per hemisphere.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import functools\n",
    "\n",
    "    # ------------------------\n",
    "    # Count number of objects per hemisphere\n",
    "    # ------------------------\n",
    "    df_counts = df.value_counts(groupby_column, sort=True).reset_index(name='Counts')\n",
    "\n",
    "    # ------------------------\n",
    "    # Calculate total area per hemisphere\n",
    "    # ------------------------\n",
    "    df_total_area = (\n",
    "        df.groupby(groupby_column)\n",
    "          .sum(numeric_only=True)['Area (μm²)']\n",
    "          .rename_axis(groupby_column)\n",
    "          .reset_index(name='Total Region Area (μm²)')\n",
    "    )\n",
    "\n",
    "    # ------------------------\n",
    "    # Calculate weighted intensity per hemisphere\n",
    "    # ------------------------\n",
    "    df_weighted_intensity = (\n",
    "        df.groupby(groupby_column)[['Intensity', 'Area (μm²)']]\n",
    "          .apply(lambda x: (x['Intensity'] * x['Area (μm²)']).sum() / x['Area (μm²)'].sum())\n",
    "          .rename_axis(groupby_column)\n",
    "          .reset_index(name='Weighted Intensity')\n",
    "    )\n",
    "\n",
    "    # ------------------------\n",
    "    # Merge all calculated results\n",
    "    # ------------------------\n",
    "    df_all_calcs = functools.reduce(\n",
    "        lambda left, right: pd.merge(left, right, on=groupby_column, how='outer'),\n",
    "        [df_counts, df_total_area, df_weighted_intensity]\n",
    "    )\n",
    "\n",
    "    # Convert units and calculate volume\n",
    "    df_all_calcs['Total Region Area (mm²)'] = df_all_calcs['Total Region Area (μm²)'] / 1_000_000\n",
    "    df_all_calcs['Total Region Volume (mm³)'] = df_all_calcs['Total Region Area (mm²)'] * (section_thickness / 1000) * spacing\n",
    "\n",
    "    # Sort by hemisphere name\n",
    "    df_all_calcs.sort_values(by=[groupby_column], ascending=False, inplace=True)\n",
    "\n",
    "    print('Calculations on injected/uninjected regions:')\n",
    "    display(df_all_calcs)\n",
    "\n",
    "    return df_all_calcs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b5624",
   "metadata": {},
   "source": [
    "### Part 1.9 – Transposed Summary of Striatum Regions and Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0803ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_calculations_transposed(df1: pd.DataFrame, df2: pd.DataFrame, filter_column: str = 'Region_Hemisphere') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Output a transposed dataframe showing area and intensity for each brain section (Striatum X),\n",
    "    as well as total area and weighted intensity for injected/uninjected hemispheres.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df1 : pd.DataFrame\n",
    "        Detailed data per brain section (columns: 'Region_Hemisphere', 'Area/object name', 'Intensity', 'Area (μm²)').\n",
    "    df2 : pd.DataFrame\n",
    "        Summary data per hemisphere (columns: 'Region_Hemisphere', 'Weighted Intensity', 'Total Region Area (μm²)').\n",
    "    filter_column : str, optional\n",
    "        Column specifying hemisphere regions (default 'Region_Hemisphere').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Transposed dataframe with all info, including calculated Loss.\n",
    "    \"\"\"\n",
    "    image_name = df1['Image'].iloc[0]\n",
    "    dictionary_inj_uninj = {}\n",
    "\n",
    "    for region in ['STRIATUM UNINJECTED', 'STRIATUM INJECTED']:\n",
    "        inj_uninj = region.split()[-1]  # This is either UNINJECTED or INJECTED\n",
    "\n",
    "        # Transpose detailed section data\n",
    "        df_detail = df1[df1[filter_column] == region][['Area/object name', 'Intensity', 'Area (μm²)']].transpose()\n",
    "        \n",
    "        # Change columns to UNINJECTED1', 'UNINJECTED2' ...  or 'INJECTED1', 'INJECTED2' ... \n",
    "        df_detail.columns = [f\"{inj_uninj}{i}\" for i in range(1, len(df_detail.columns) + 1)]\n",
    "\n",
    "        # Rename index\n",
    "        df_detail.index = [f\"{image_name} Area name\", f\"{image_name} Intensity\", f\"{image_name} Area (μm²)\"]\n",
    "\n",
    "        # Transpose summary hemisphere data\n",
    "        df_summary = df2[df2[filter_column] == region][['Weighted Intensity', 'Total Region Area (μm²)']].transpose()\n",
    "\n",
    "        # Change columns to 'TOTAL UNINJECTED' or 'TOTAL INJECTED'\n",
    "        df_summary.columns = [f\"TOTAL {inj_uninj}\"]\n",
    "\n",
    "        # Rename index\n",
    "        df_summary.index = [f\"{image_name} Intensity\", f\"{image_name} Area (μm²)\"]\n",
    "\n",
    "        # Concatenate detailed and summary horizontally\n",
    "        df_concatenated = pd.concat([df_detail, df_summary], axis=1)\n",
    "        print(f'Transposed {region} regions with all info:')\n",
    "        display(df_concatenated)\n",
    "\n",
    "        dictionary_inj_uninj[region] = df_concatenated\n",
    "\n",
    "    # Concatenate both hemispheres\n",
    "    df_combined = pd.concat(dictionary_inj_uninj.values(), axis=1)\n",
    "\n",
    "    # Calculate Loss (%)\n",
    "    df_combined['Loss'] = 100 * (1 - pd.to_numeric(df_combined['TOTAL INJECTED'], errors='coerce') /\n",
    "                                    pd.to_numeric(df_combined['TOTAL UNINJECTED'], errors='coerce'))\n",
    "\n",
    "    # Move Loss column to the front\n",
    "    cols = ['Loss'] + [col for col in df_combined.columns if col != 'Loss']\n",
    "    df_combined = df_combined[cols]\n",
    "\n",
    "    print('Dataframe combining uninjected and injected info:')\n",
    "    display(df_combined)\n",
    "\n",
    "    return df_combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd968b-e979-49f2-a4f6-3a3f68cf1574",
   "metadata": {},
   "source": [
    "## Part 2 - Automatic Analysis of all N S1 Slides of all N Brains \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8827edae-365f-4b79-974f-299415dceff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Measure the execution time of this cell\n",
    "\n",
    "# Load the file specifying brain regions to replace/delete for each image\n",
    "df_brainregions_to_replace = load_data_brainregions_to_replace(file_brainregions_to_replace)\n",
    "\n",
    "# Get all file names containing '_S1' \n",
    "all_raw_data_file_locations_S1 = load_all_file_locations_S1(folder_raw_data, data_format)\n",
    "\n",
    "# Initialize dictionary to store all overview dataframes\n",
    "dictionary_overview_dataframes = {}\n",
    "\n",
    "# Loop over all S1 images in the raw_data folder\n",
    "for count, file_location_S1 in enumerate(all_raw_data_file_locations_S1):\n",
    "\n",
    "    print(f'\\nAnalysis of {file_location_S1}')\n",
    "    \n",
    "    # Extract image name from file_path\n",
    "    image_name_S1 = os.path.splitext(os.path.basename(file_location_S1))[0]\n",
    "    \n",
    "    # Clean the S1 data\n",
    "    df_S1_final = dataframe_cleaning(file_location_S1, df_brainregions_to_replace, data_format)\n",
    "\n",
    "    # Perform calculations\n",
    "    df_S1_all_calcs = all_calculations(df_S1_final, section_thickness, spacing)\n",
    "\n",
    "    # Prepare overview dataframes. For the overview excel file, only the df_S1_all_calcs dataframe is needed. \n",
    "    # We will make 1 overview excelfile with a few tabpages that we store in dictionary_overview_dataframes:\n",
    "    # dictionary_overview_dataframes = {Total Intensity : df,  Total Region Area: df, .... }\n",
    "    list_calculation_results = ['Weighted Intensity', 'Total Region Area (mm²)', 'Total Region Volume (mm³)']\n",
    "\n",
    "    for calculation_result in list_calculation_results:\n",
    "        df_calc = df_S1_all_calcs[['Area/object name merged', calculation_result]].copy()\n",
    "        df_calc.rename(columns={calculation_result: image_name_S1}, inplace=True)\n",
    "\n",
    "        if count == 0:\n",
    "            # Initialize dictionary on first loop\n",
    "            dictionary_overview_dataframes[calculation_result] = df_calc\n",
    "        else:\n",
    "            # Merge subsequent results\n",
    "            dictionary_overview_dataframes[calculation_result] = dictionary_overview_dataframes[calculation_result].merge(\n",
    "                df_calc, how='outer', on='Area/object name merged'\n",
    "            )\n",
    "\n",
    "    # Clean up memory for next iteration\n",
    "    del df_S1_final, df_S1_all_calcs\n",
    "\n",
    "# Export overview tables to Excel\n",
    "output_file_name_overview = os.path.join(folder_output_results, 'Overview_TH_Axons_Results.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(output_file_name_overview) as writer:\n",
    "    for calculation_result in list_calculation_results:\n",
    "        sheet_name = calculation_result.replace('/', ' per ')\n",
    "        print(f'Overview dataframe with all {sheet_name} for all brains')\n",
    "        display(dictionary_overview_dataframes[calculation_result])\n",
    "        dictionary_overview_dataframes[calculation_result].to_excel(\n",
    "            writer, sheet_name=sheet_name, index=False, float_format=\"%.3f\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818bd6c2",
   "metadata": {},
   "source": [
    "## Part 3 – Automatic Analysis of all N S1 Slides of all N Brains (Including Injected and Uninjected Hemispheres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33258e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Measure the execution time of this cell\n",
    "\n",
    "# Load the file specifying brain regions to replace/delete for each image\n",
    "df_brainregions_to_replace = load_data_brainregions_to_replace(file_brainregions_to_replace)\n",
    "\n",
    "# Load the file specifying which brain regions belong to which hemisphere for each image\n",
    "df_brainregions_injected = load_data_brainregions_injected(file_brainregions_injected)\n",
    "\n",
    "# Get all file names containing '_S1'\n",
    "all_raw_data_file_locations_S1 = load_all_file_locations_S1(folder_raw_data, data_format)\n",
    "\n",
    "# Initialize dictionary to store all overview dataframes\n",
    "dictionary_overview_dataframes_injected = {}\n",
    "\n",
    "# Loop over all S1 images in the raw_data folder\n",
    "for count, file_location_S1 in enumerate(all_raw_data_file_locations_S1):\n",
    "\n",
    "    print(f'\\nAnalysis of {file_location_S1}')\n",
    "\n",
    "    # Extract image name from file_path\n",
    "    image_name_S1 = os.path.splitext(os.path.basename(file_location_S1))[0]\n",
    "\n",
    "    # Clean the S1 data\n",
    "    df_S1_final = dataframe_cleaning(file_location_S1, df_brainregions_to_replace, data_format)\n",
    "\n",
    "    # Match cleaned data with injected/uninjected hemisphere definitions\n",
    "    df_injected_object = df_brainregions_injected.merge(\n",
    "        df_S1_final,\n",
    "        left_on=['Image', 'Brainregion'],\n",
    "        right_on=['Image', 'Area/object name'],\n",
    "        how='inner'\n",
    "    ).drop(columns=['Brainregion'])\n",
    "\n",
    "    # Perform calculations\n",
    "    df_S1_all_calcs_injected = all_calculations_injected(df_injected_object, section_thickness, spacing)\n",
    "    df_uninjected_injected_info = all_calculations_transposed(df_injected_object, df_S1_all_calcs_injected)\n",
    "\n",
    "    # For the overview excel file, only the df_S1_all_calcs_injected and df_uninjected_injected_info dataframe is needed. \n",
    "    # We will make 1 overview excelfiles with a few tabpages that we store in dictionary_overview_dataframes_injected:\n",
    "    # dictionary_overview_dataframes_injected = {Intensities and Areas : df,  .... }\n",
    "    if count == 0:\n",
    "        dictionary_overview_dataframes_injected['Intensities and Areas'] = df_uninjected_injected_info\n",
    "    else:\n",
    "        dictionary_overview_dataframes_injected['Intensities and Areas'] = pd.concat(\n",
    "            [dictionary_overview_dataframes_injected['Intensities and Areas'], df_uninjected_injected_info]\n",
    "        )\n",
    "\n",
    "    # Prepare the dataframes that are needed for the overview excel file: choose the needed columns,\n",
    "    # and rename the header of the column with the values to the image_name \n",
    "    list_calculation_results = ['Total Region Area (mm²)', 'Total Region Volume (mm³)']\n",
    "\n",
    "    for calculation_result in list_calculation_results:\n",
    "        df_calc = df_S1_all_calcs_injected[['Region_Hemisphere', calculation_result]].copy()\n",
    "        df_calc.rename(columns={calculation_result: image_name_S1}, inplace=True)\n",
    "\n",
    "        if count == 0:\n",
    "            dictionary_overview_dataframes_injected[calculation_result] = df_calc\n",
    "        else:\n",
    "            dictionary_overview_dataframes_injected[calculation_result] = dictionary_overview_dataframes_injected[\n",
    "                calculation_result\n",
    "            ].merge(df_calc, how='outer', on='Region_Hemisphere')\n",
    "\n",
    "    # Clean up memory for next iteration\n",
    "    del df_S1_final, df_injected_object, df_S1_all_calcs_injected, df_uninjected_injected_info\n",
    "\n",
    "\n",
    "# After the for loops, we print the final overview tables\n",
    "# First we make sure that the first row is 'STRIATUM UNINJECTED' and the second row is 'STRIATUM INJECTED'\n",
    "dictionary_overview_dataframes_injected['Total Region Area (mm²)'].sort_values(\n",
    "    by='Region_Hemisphere', ascending=False, inplace=True\n",
    ")\n",
    "dictionary_overview_dataframes_injected['Total Region Volume (mm³)'].sort_values(\n",
    "    by='Region_Hemisphere', ascending=False, inplace=True\n",
    ")\n",
    "\n",
    "# Reorder the columns in the 'Intensities and Areas' overview\n",
    "cols = dictionary_overview_dataframes_injected['Intensities and Areas'].columns\n",
    "cols_loss = ['Loss']\n",
    "# Sort based on the number in it, and make sure that the order is U1, U2 ... U9, U10... instead of U1, U10, U2...\n",
    "cols_uninj = sorted([x for x in cols if 'UNINJECTED' in x and 'TOTAL' not in x],\n",
    "                    key=lambda x: float(x.replace('UNINJECTED', '').strip()))\n",
    "cols_total_uninj = ['TOTAL UNINJECTED']\n",
    "\n",
    "cols_inj = sorted([x for x in cols if 'INJECTED' in x and 'UN' not in x and 'TOTAL' not in x],\n",
    "                  key=lambda x: float(x.replace('INJECTED', '').strip()))\n",
    "cols_total_inj = ['TOTAL INJECTED']\n",
    "\n",
    "columns_ordered = cols_loss + cols_uninj + cols_total_uninj + cols_inj + cols_total_inj\n",
    "\n",
    "dictionary_overview_dataframes_injected['Intensities and Areas'] = \\\n",
    "    dictionary_overview_dataframes_injected['Intensities and Areas'][columns_ordered]\n",
    "\n",
    "# Extract loss values only for intensity rows\n",
    "df = dictionary_overview_dataframes_injected['Intensities and Areas']\n",
    "dictionary_overview_dataframes_injected['Intensity Loss'] = df.loc[df.index.str.contains('Intensity'), ['Loss']]\n",
    "\n",
    "# Export results to Excel\n",
    "output_file_name_overview = os.path.join(folder_output_results_injected, 'Overview_TH_Axons_Hemisphere_Results.xlsx')\n",
    "\n",
    "list_calculation_results = [\n",
    "    'Intensity Loss',\n",
    "    'Intensities and Areas',\n",
    "    'Total Region Area (mm²)',\n",
    "    'Total Region Volume (mm³)'\n",
    "]\n",
    "\n",
    "with pd.ExcelWriter(output_file_name_overview) as writer:\n",
    "    for calculation_result in list_calculation_results:\n",
    "        calculation_result_clean = calculation_result.replace('/', ' per ')\n",
    "        print(f'Overview dataframe: {calculation_result_clean}')\n",
    "        display(dictionary_overview_dataframes_injected[calculation_result])\n",
    "        dictionary_overview_dataframes_injected[calculation_result].to_excel(\n",
    "            writer,\n",
    "            sheet_name=calculation_result_clean,\n",
    "            index=calculation_result in ('Intensity Loss', 'Intensities and Areas'),\n",
    "            float_format=\"%.3f\"\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
