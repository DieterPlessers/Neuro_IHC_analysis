{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8160eb4",
   "metadata": {},
   "source": [
    "# Analysis of Dopaminergic Terminal Detector (DTD) model\n",
    "\n",
    "## 0. Outline\n",
    "This code deals with the automatic processing of raw data from mouse brains analysed with “Dopaminergic Terminal Detector” model developed in Aiforia® Create. We typically start from Excel/CSV files collected in a local folder on the computer that is specified in the code. To automatically change the format of a series of files, refer to the to the Change_Name_Format_Input_Data.ipynb notebook. The code is developed to take into account that a mouse brain can be mounted over several slides. Slides for each animal are named identically, except for a numeric postfix denoting the slide number: '_S1', '_S2', etc. For this code it is required that mouse brain sections containing the striatum from the same mouse are all mounted on the same '_S1' slide.\n",
    "\n",
    "The present notebook is divided into 3 sections:\n",
    "\n",
    "**1) Make the necessary functions for part 2**\n",
    "\n",
    "**2) Automatic Analysis of N Slides (of which the name contains '_S1') of N Brains**\n",
    "\n",
    "Here we automate the analysis of all N S1 slides of all N brains (1 slide per brain) in the folder with raw data. The approach is as follows:\n",
    "\n",
    "1) We collect all the N names of the S1 raw data files in the folder and store them in a list.\n",
    "\n",
    "2) We loop over these N slides belonging to the N brains and perform the following steps in each loop:\n",
    "\n",
    "    a) We perform the data analysis steps.  \n",
    "    b) We output the results to an excel file for this specific brain.\n",
    "    \n",
    "After each loop, we add the output of this specific brain to an overview table that will contain all results for all brains. After the last loop, this overview table is also exported to an excel file.\n",
    "\n",
    "In this part of the code, we **do not** make more detailed **'transposed'** tables with information on each Striatum part. \n",
    "\n",
    "**3) Automatic Analysis of N Slides (of which the name contains '_S1') of N Brains after determining to which hemisphere they belong**\n",
    "\n",
    "Here we add which Striatum regions are on each hemisphere, and compare the injected vs non-injected sides. Analysis occurs similar to section 2. In this part of the code, we also make more detailed **'transposed'** tables with information on each Striatum part for easier visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8949a9bf",
   "metadata": {},
   "source": [
    "## Part 1 - Make the necessary functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f259ca",
   "metadata": {},
   "source": [
    "### Part 1.1 - Load all necessary Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f298f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required Python packages\n",
    "import pandas as pd                                # For data analysis with dataframes\n",
    "import math                                        # To get the value for pi\n",
    "import functools                                   # For higher-order functions that work on other functions\n",
    "from IPython.display import display                # Enables the display of more than one dataframe per code cell\n",
    "import numpy as np                                 # For data analysis\n",
    "import glob                                        # To get all raw data file locations\n",
    "import os                                          # To get all raw data file locations\n",
    "pd.options.display.float_format = '{:.2f}'.format  # Display all numbers in dataframes with 2 decimals\n",
    "import re                                          # To do Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a2fd6",
   "metadata": {},
   "source": [
    "### Part 1.2 - Data locations\n",
    "\n",
    "**TO DO:** \n",
    "- Specify the format of the raw data and the raw data folder location, as well as some experimental parameters.\n",
    "- Specify the file paths of the excel file containing your quality control revisions and the excel file mapping each brain region to a hemisphere.\n",
    "- Specify the folder locations where you would like to collect the output excel files (for whole brain and hemisphere analysis).  \n",
    "\n",
    "The format is: <font color='darkred'>r'file_location'</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae8930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify what data format you want to use for your raw data: excel, csv or feather. Do this by uncommenting the data_format that you want.\n",
    "# data_format = 'excel'\n",
    "data_format = 'csv'\n",
    "# data_format = 'feather'\n",
    "\n",
    "# Specify the experimental parameters (section_thickness in micrometers) and locations:\n",
    "# The spacing parameter refers to the serial section spacing interval. It's the interval at which you sample the brain volume for analysis, not the physical distance between each section. For example, if you have a spacing parameter of 10, you would take every 10th section for your analysis.  \n",
    "spacing=12\n",
    "section_thickness = 40\n",
    "folder_raw_data = r'C:\\Users\\...\\Raw_Data_DTD'\n",
    "file_brainregions_to_replace =  r'C:\\Users\\...\\Brainregions_To_Replace_DTD.xlsx'\n",
    "file_brainregions_injected =  r'C:\\Users\\...\\Brainregions_Hemisphere_DTD.xlsx'\n",
    "folder_output_results = r'C:\\Users\\...\\Results_Wholebrain_DTD'\n",
    "folder_output_results_injected = r'C:\\Users\\...\\Results_Hemisphere_DTD'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a443bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the output folders if they did not exist yet\n",
    "if not os.path.isdir(folder_output_results):\n",
    "    os.mkdir(folder_output_results)\n",
    "if not os.path.isdir(folder_output_results_injected):\n",
    "    os.mkdir(folder_output_results_injected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c8fe9d",
   "metadata": {},
   "source": [
    "### Part 1.3 - Function to load all image files that need to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d03a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_file_locations_S1(folder_raw_data):\n",
    "    \"\"\"\n",
    "    Make a list of all file locations for S1 images present in the folder with all raw data files. There are only supposed to be S1 images in the folder, \n",
    "    so '_S1' does not have to be in the filename here.\n",
    "    Output: list of all file locations for S1 images.\n",
    "    \"\"\"\n",
    "\n",
    "    if data_format == 'excel':\n",
    "        all_raw_data_file_locations_S1 = glob.glob(os.path.join(folder_raw_data, \"*.xlsx\"))\n",
    "    elif data_format == 'csv':\n",
    "        all_raw_data_file_locations_S1 = glob.glob(os.path.join(folder_raw_data, \"*.csv\"))\n",
    "    elif data_format == 'feather':\n",
    "        all_raw_data_file_locations_S1 = glob.glob(os.path.join(folder_raw_data, \"*.feather\"))\n",
    "    else:\n",
    "        print('You did not specify a correct data-format in Part 1.2 and can expect some errors in the rest of the code')\n",
    "        \n",
    "    all_raw_data_file_locations_S1.sort()\n",
    "\n",
    "    print('The location of all the raw data files = ')\n",
    "    for file_location_S1 in all_raw_data_file_locations_S1:\n",
    "        print(file_location_S1)\n",
    "\n",
    "      \n",
    "    return all_raw_data_file_locations_S1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f28be4e",
   "metadata": {},
   "source": [
    "### Part 1.4 - Function to load the file with corrections for the brainregions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f5974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_brainregions_to_replace(file_brainregions_to_replace):\n",
    "    \"\"\"\n",
    "    Load the file containing the corrections for brain regions that need to be replaced for each specific image.\n",
    "    Output: cleaned dataframe with brain regions that need to be replaced for each image.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_brainregions_to_replace_raw=pd.read_excel(file_brainregions_to_replace,\n",
    "                                                 usecols=['Image', 'Brainregion_Wrong', 'Brainregion_Correct'],\n",
    "                                                 dtype={'Image': 'str', 'Brainregion_Wrong': 'str', 'Brainregion_Correct': 'str'}\n",
    "                                                )\n",
    "\n",
    "    # Modify the dataframe to delete spaces that are by accident there, and put the brainregions in upper case \n",
    "    df_brainregions_to_replace=df_brainregions_to_replace_raw.copy()\n",
    "    df_brainregions_to_replace['Image'] = df_brainregions_to_replace_raw['Image'].str.strip()\n",
    "    df_brainregions_to_replace['Brainregion_Wrong'] = df_brainregions_to_replace_raw['Brainregion_Wrong'].str.upper().str.strip()\n",
    "    df_brainregions_to_replace['Brainregion_Correct'] = df_brainregions_to_replace_raw['Brainregion_Correct'].str.upper().str.strip()\n",
    "\n",
    "    #     print('The raw table of the brain regions to replace for each image = ')\n",
    "    #     display(df_brainregions_to_replace_raw)\n",
    "\n",
    "    print('The modified table of the brain regions to replace for each image = ')\n",
    "    display(df_brainregions_to_replace)\n",
    "    \n",
    "    return df_brainregions_to_replace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ec28a",
   "metadata": {},
   "source": [
    "### Part 1.5 - Function to load the file with which brainregions were injected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfb5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_brainregions_injected(file_brainregions_injected):\n",
    "    \"\"\"\n",
    "    Load the file specifying which brainregions were on the injected side for each specific image.\n",
    "    Output: cleaned dataframe with brain regions that were injected for each image.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_brainregions_injected_raw=pd.read_excel(file_brainregions_injected,\n",
    "                                               usecols=['Image', 'Brainregion', 'Hemisphere'],\n",
    "                                               dtype={'Image': 'str', 'Brainregion': 'str', 'Hemisphere': 'str'}\n",
    "                                               )\n",
    "\n",
    "    # Modify the dataframe to delete spaces that are by accident there, and put the brainregions in upper case \n",
    "    df_brainregions_injected=df_brainregions_injected_raw.copy()\n",
    "    df_brainregions_injected['Image'] = df_brainregions_injected_raw['Image'].str.strip()\n",
    "    df_brainregions_injected['Brainregion'] = df_brainregions_injected_raw['Brainregion'].str.upper().str.strip()\n",
    "    df_brainregions_injected['Region_Hemisphere'] = df_brainregions_injected_raw['Hemisphere'].str.upper().str.strip()\n",
    "    df_brainregions_injected.drop(columns=['Hemisphere'], inplace=True)\n",
    "\n",
    "    #     print('The raw table of the brain regions injected for each image = ')\n",
    "    #     display(df_brainregions_injected_raw)\n",
    "\n",
    "    print('The modified table of the brain regions injected for each image = ')\n",
    "    display(df_brainregions_injected)\n",
    "    \n",
    "    return df_brainregions_injected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67414c4e",
   "metadata": {},
   "source": [
    "### Part 1.6 - Function to load dataframe and clean it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68deb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_cleaning(file_location, df_brainregions_to_replace):\n",
    "    \"\"\"\n",
    "    Load the specific file location in a dataframe and clean it with df_brainregions_to_replace.\n",
    "    Output: loaded and cleaned dataframe with some additional calculated values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load file with raw data for image S1 of this specific brain\n",
    "    if data_format == 'excel':\n",
    "        df_1=pd.read_excel(file_location,\n",
    "                           usecols=['Image', 'Area/object name', 'Area (μm²)', 'B', 'G', 'R'],\n",
    "                           dtype={'Image': 'str', 'Area/object name': 'str', 'Area (μm²)': 'float64', \n",
    "                                  'B': 'float64', 'G': 'float64', 'R': 'float64' },\n",
    "                           keep_default_na = True)\n",
    "    elif data_format == 'csv':\n",
    "        df_1=pd.read_csv(file_location, sep='\\t',\n",
    "                         usecols=['Image', 'Area/object name', 'Area (μm²)', 'B', 'G', 'R'],\n",
    "                           dtype={'Image': 'str', 'Area/object name': 'str', 'Area (μm²)': 'float64', \n",
    "                                  'B': 'float64', 'G': 'float64', 'R': 'float64' },\n",
    "                         keep_default_na = True)\n",
    "    elif data_format == 'feather':\n",
    "        df_1=pd.read_feather(file_location) \n",
    "        dtype_dictionary = {'Image': 'object', 'Area/object name': 'object', 'Area (μm²)': 'float64', \n",
    "                            'B': 'float64', 'G': 'float64', 'R': 'float64' }\n",
    "        df_1=df_1.astype(dtype_dictionary)\n",
    "    else:\n",
    "        print('You did not specify a correct data format in Part 1.2 and can expect some errors in the rest of the code')\n",
    "   \n",
    "    \n",
    "        \n",
    "    # Get the image name out of the file_path (getting image name from dataframe first column is hard because some are empty, \n",
    "    # and getting from filename makes more sense anyway) \n",
    "    full_name = os.path.basename(file_location)\n",
    "    file_name = os.path.splitext(full_name)\n",
    "    image_name = file_name[0]\n",
    "    print('The present image=', image_name)\n",
    "\n",
    "    # Make sure the image name across the whole first column is correct\n",
    "    df_1['Image']=image_name\n",
    "    \n",
    "    # Delete the rows with an empty  Area (μm²) or Area/object name \n",
    "    # df_1.dropna(subset =['Area (μm²)', 'Area/object name'] , how='any', inplace=True)\n",
    "    \n",
    "    # Put all columns in capitals to never make mistakes against capitalization\n",
    "    df_1['Area/object name'] = df_1['Area/object name'].str.upper()\n",
    "\n",
    "    # Brain tissue detector rows are not needed\n",
    "    df_2 = df_1[ ~(df_1['Area/object name'].str.contains(\"BRAIN TISSUE DETECTOR\")) ]\n",
    "\n",
    "    # Determine the dictionary of brain regions that should be replaced for this specific image\n",
    "    df_brainregions_to_replace = df_brainregions_to_replace[df_brainregions_to_replace['Image']==image_name]\n",
    "    dict_brainregions_to_replace= pd.Series(df_brainregions_to_replace.Brainregion_Correct.values, index=df_brainregions_to_replace.Brainregion_Wrong).to_dict()\n",
    "\n",
    "    print('The dictionary of brain regions to replace for this specific image', image_name, 'is', dict_brainregions_to_replace)\n",
    "\n",
    "    # Replace the value in the rows that have an Area/object name that is in list_brainregions_replace\n",
    "    df_3 = df_2.copy()\n",
    "    df_3['Area/object name'] = df_3['Area/object name'].replace(dict_brainregions_to_replace, regex=False)\n",
    "\n",
    "    # Create a column 'Area/object name merged' where the numbers are deleted from these columns:\n",
    "    df_3['Area/object name merged'] = df_3['Area/object name'].str.replace('\\\\d+', '', regex=True).str.strip()\n",
    "\n",
    "    # Convert RGB values to grey scale intensity\n",
    "    df_4 = df_3.copy() \n",
    "    # The higher the 'lightness' value, the lighter the image as white is RGB=(255,255,255) and black = RGB(0,0,0). We use a scale 0 to 100, but boils down to the same\n",
    "    df_4['Lightness'] = 0.299*df_3['R'] + 0.587*df_3['G'] + 0.114*df_3['B'] \n",
    "    # df_4['Lightness'] = 1/3*df_3['R'] + 1/3*df_3['G'] + 1/3*df_3['B'] \n",
    "    # The higher the 'intensity' value, the darker / more intense the image.\n",
    "    df_4['Intensity'] = 100 - df_4['Lightness']\n",
    "\n",
    "    print('The full data=')\n",
    "    display(df_4)\n",
    " \n",
    "    return df_4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924a1cb-9b58-4d5a-b16d-695ef7c4a39f",
   "metadata": {},
   "source": [
    "### Part 1.7 - Function to calculate all information (disregarding injected/uninjected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056870c2-05b9-4c86-b60d-47a63083a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_calculations(df1, groupby_column1='Area/object name merged'):\n",
    "    \"\"\"\n",
    "    Make the main calculations of total area and weighted intensities for each Area/object name merged\n",
    "    Output: dataframe with all calculations for each Area/object name merged.\n",
    "    \"\"\"\n",
    "\n",
    "    # Count the number of rows for each Area/object name merged\n",
    "    df_counts = df1.value_counts(groupby_column1, sort=True).reset_index(name='Counts')\n",
    "\n",
    "    # Calculate the total area of each Area/object name merged\n",
    "    df_total_area = df1.groupby(groupby_column1).sum(numeric_only=True)['Area (μm²)'].rename_axis(groupby_column1).reset_index(name='Total Region Area (μm²)')\n",
    "\n",
    "    # Calculate the weighted intensity of each Area/object name merged\n",
    "    f = lambda x: sum(x['Intensity'] * x['Area (μm²)']) / sum(x['Area (μm²)'])\n",
    "    df_weighted_intensity= df1.groupby(groupby_column1).apply(f).rename_axis(groupby_column1).reset_index(name='Weighted Intensity')\n",
    "    \n",
    "    # Put all calculated results together\n",
    "    dfs_to_merge = [df_counts, df_total_area, df_weighted_intensity]\n",
    "    df_all_calcs  = functools.reduce(lambda left, right: pd.merge(left,right,on=groupby_column1, how='outer'), dfs_to_merge)\n",
    "\n",
    "    df_all_calcs['Total Region Area (mm²)'] = df_all_calcs['Total Region Area (μm²)'] / 1000000\n",
    "    df_all_calcs['Total Region Volume (mm³)'] =  df_all_calcs['Total Region Area (mm²)']*(section_thickness/1000)*spacing\n",
    "    \n",
    "    df_all_calcs.drop(columns=['Total Region Area (μm²)'], inplace=True)\n",
    "    df_all_calcs.sort_values(by=[groupby_column1], ascending=False, inplace=True)\n",
    "    \n",
    "    print('Calculations for each Area/object name merged')\n",
    "    display(df_all_calcs)\n",
    "\n",
    "    return df_all_calcs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca7d33",
   "metadata": {},
   "source": [
    "### Part 1.8 - Function to calculate all information for the injected/uninjected hemispheres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ae8b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_calculations_injected(df_injected_object, groupby_column1='Region_Hemisphere'):\n",
    "    \"\"\"\n",
    "    Make the main calculations of total area and weighted intensities for each hemisphere region \n",
    "    Output: dataframe with all calculations with the specification injected/uninjected side.\n",
    "    \"\"\"\n",
    "\n",
    "    # Count the number of rows for each Region_Hemisphere\n",
    "    df_counts_injected = df_injected_object.value_counts(groupby_column1, sort=True).reset_index(name='Counts')\n",
    "\n",
    "    # Calculate the total area of each Region_Hemisphere\n",
    "    df_total_area_injected = df_injected_object.groupby(groupby_column1).sum(numeric_only=True)['Area (μm²)'].rename_axis(groupby_column1).reset_index(name='Total Region Area (μm²)')\n",
    "\n",
    "    # Calculate the weighted intensity of each Region_Hemisphere\n",
    "    f = lambda x: sum(x['Intensity'] * x['Area (μm²)']) / sum(x['Area (μm²)'])\n",
    "    df_weighted_intensity_injected= df_injected_object.groupby(groupby_column1).apply(f).rename_axis(groupby_column1).reset_index(name='Weighted Intensity')\n",
    "    \n",
    "    # Put all calculated results together\n",
    "    dfs_to_merge = [df_counts_injected, df_total_area_injected, df_weighted_intensity_injected]\n",
    "    df_all_calcs_injected  = functools.reduce(lambda left, right: pd.merge(left,right,on=groupby_column1, how='outer'), dfs_to_merge)\n",
    "\n",
    "    df_all_calcs_injected['Total Region Area (mm²)'] = df_all_calcs_injected['Total Region Area (μm²)'] / 1000000\n",
    "    df_all_calcs_injected['Total Region Volume (mm³)'] =  df_all_calcs_injected['Total Region Area (mm²)']*(section_thickness/1000)*spacing\n",
    "    \n",
    "    df_all_calcs_injected.sort_values(by=[groupby_column1], ascending=False, inplace=True)\n",
    "    \n",
    "    print('Calculations on injected/uninjected regions')\n",
    "    display(df_all_calcs_injected)\n",
    "\n",
    "    return df_all_calcs_injected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b5624",
   "metadata": {},
   "source": [
    "### Part 1.9 - Function to display all information of the different Striatums and hemispheres (transposed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0803ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_calculations_transposed(df1, df2, filter_column1='Region_Hemisphere'):\n",
    "    \"\"\"\n",
    "    Output:  the area and intensity for each brain section (Striatum X), as well as the total area and weighted intensity \n",
    "    for the two hemispheres (injected/uninjected) that we calculated in section 1.7. \n",
    "    \"\"\"\n",
    "\n",
    "    df_short = df1[['Region_Hemisphere', 'Area/object name', 'Intensity', 'Area (μm²)']]\n",
    "    df_short2= df2[['Region_Hemisphere', 'Weighted Intensity', 'Total Region Area (μm²)']]\n",
    "    image_name=df1['Image'][0]\n",
    "\n",
    "    dictionary_inj_uninj={}\n",
    "    for region in ['STRIATUM UNINJECTED', 'STRIATUM INJECTED']:\n",
    "        inj_uninj=region.split()[-1]   # This is either UNINJECTED or INJECTED\n",
    "        \n",
    "        df_short_transp = df_short[df_short[filter_column1] == region][['Area/object name', 'Intensity', 'Area (μm²)']].transpose()\n",
    "        \n",
    "        # Change columns to UNINJECTED1', 'UNINJECTED2' ...  or 'INJECTED1', 'INJECTED2' ... \n",
    "        df_short_transp.columns = [inj_uninj+ str(x) for x in range(1, len(df_short_transp.columns)+1)]    \n",
    "        # Rename index\n",
    "        df_short_transp = df_short_transp.rename(index={'Area/object name': image_name + ' Area name',\n",
    "                                                        'Intensity': image_name + ' Intensity',\n",
    "                                                        'Area (μm²)': image_name + ' Area (μm²)' })\n",
    "        # display(df_short_transp)\n",
    "        \n",
    "        df_short2_transp = df_short2[df_short2[filter_column1]==region].transpose()\n",
    "        # Change columns to 'TOTAL UNINJECTED'   or 'TOTAL INJECTED'\n",
    "        df_short2_transp.columns = ['TOTAL ' + inj_uninj]\n",
    "        # Rename index\n",
    "        df_short2_transp = df_short2_transp.rename(index={'Region_Hemisphere': image_name + ' Area name',\n",
    "                                                          'Weighted Intensity': image_name + ' Intensity',\n",
    "                                                          'Total Region Area (μm²)': image_name + ' Area (μm²)' })\n",
    "        # display(df_short2_transp)\n",
    "    \n",
    "        # Concatenate the dataframes together horizontally:\n",
    "        df_concatenated = pd.concat([df_short_transp,df_short2_transp], axis=1)\n",
    "        \n",
    "        print(f'Transposed {region} regions with all info')\n",
    "        display(df_concatenated)\n",
    "        dictionary_inj_uninj[region]=df_concatenated\n",
    "    \n",
    "    # Concatenate the dataframe with the uninjected info and the injected info together horizontally:\n",
    "    df_uninjected_injected_info = pd.concat(dictionary_inj_uninj.values(), axis=1)\n",
    "\n",
    "    a = pd.to_numeric(df_uninjected_injected_info['TOTAL INJECTED'], errors='coerce')\n",
    "    b = pd.to_numeric(df_uninjected_injected_info['TOTAL UNINJECTED'], errors='coerce')\n",
    "    df_uninjected_injected_info['Loss'] = 100*(1-a/b)\n",
    "\n",
    "    # Bring the Loss column to the front\n",
    "    df_uninjected_injected_info = df_uninjected_injected_info[ ['Loss'] + [ col for col in df_uninjected_injected_info.columns if col != 'Loss' ] ]\n",
    "    \n",
    "    print('Dataframe with the uninjected info and the injected info together')\n",
    "    display(df_uninjected_injected_info)\n",
    "    \n",
    "    return df_uninjected_injected_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd968b-e979-49f2-a4f6-3a3f68cf1574",
   "metadata": {},
   "source": [
    "## Part 2 - Automatic Wholebrain Analysis of all N S1 Slides of all N Brains \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8827edae-365f-4b79-974f-299415dceff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time   \n",
    "# For curiosity we measure the time the code in this cell takes to run\n",
    "\n",
    "# Load the modified file with brain regions to replace/delete for each specific image \n",
    "df_brainregions_to_replace=load_data_brainregions_to_replace(file_brainregions_to_replace)\n",
    "\n",
    "# Extract the file names that contain '_S1' in the file name. These are the N first images of the N unique brains.\n",
    "all_raw_data_file_locations_S1= load_all_file_locations_S1(folder_raw_data)\n",
    "\n",
    "# We initiate a counter to keep track in which loop we are below:\n",
    "count = 0\n",
    "\n",
    "# Loop over all the S1 pictures in the raw_data folder\n",
    "for file_location_S1 in all_raw_data_file_locations_S1:\n",
    "    count = count +1 # Counts the loop; first loop: counter = 1\n",
    "\n",
    "    # Get the image name out of the file_path \n",
    "    full_name = os.path.basename(file_location_S1)\n",
    "    file_name = os.path.splitext(full_name)\n",
    "    image_name_S1 = file_name[0]\n",
    "    \n",
    "    # Do the S1 data cleaning, making use of the functions defined above\n",
    "    print('\\n Analysis of ', file_location_S1)\n",
    "    df_S1_final = dataframe_cleaning(file_location_S1, df_brainregions_to_replace)\n",
    "\n",
    "    # Do all the calculations, making use of the functions defined above. \n",
    "    df_S1_all_calcs = all_calculations(df_S1_final)\n",
    "\n",
    "    \n",
    "    ############################\n",
    "    #   Prepare overview file  #\n",
    "    ############################\n",
    "    \n",
    "\n",
    "    # For the overview excel file, only the df_S1_all_calcs dataframe is needed. \n",
    "    # We will make 1 overview excelfiles with a few tabpages that we store in dictionary_overview_dataframes:\n",
    "    # dictionary_overview_dataframes = {Total Intensity : df,  Total Region Area: df, .... }\n",
    "    \n",
    "    # In the first loop we initiate an empty overview dictionary that will be filled with dataframes. \n",
    "    if count==1:\n",
    "        dictionary_overview_dataframes={}\n",
    "     \n",
    "    # Prepare the dataframes that are needed for the overview excel file: choose the needed columns,\n",
    "    # and rename the header of the column with the values to the image_name \n",
    "    list_calculation_results=['Weighted Intensity', 'Total Region Area (mm²)', 'Total Region Volume (mm³)']\n",
    "\n",
    "    for calculation_result in list_calculation_results:\n",
    "        df_S1_all_calcs_calculation= df_S1_all_calcs[['Area/object name merged', calculation_result]].copy()\n",
    "        df_S1_all_calcs_calculation.rename(columns={calculation_result: image_name_S1}, inplace=True)\n",
    "        \n",
    "        if count==1:\n",
    "            # In the first loop we fill the empty overview dictionary with a dataframe with the values calculated in loop 1  \n",
    "            dictionary_overview_dataframes[calculation_result]  = df_S1_all_calcs_calculation.copy()\n",
    "            \n",
    "        elif count > 1 :\n",
    "            # In the subsequent loops we will add the values of those loops to the dataframes in the overview dictionary\n",
    "            dictionary_overview_dataframes[calculation_result] = dictionary_overview_dataframes[calculation_result].merge(df_S1_all_calcs_calculation, how='outer', on='Area/object name merged')\n",
    "\n",
    "    # At the end, we delete some of the dataframes, to ensure they cannot be used in the next loop\n",
    "    del(df_S1_final)\n",
    "    del(df_S1_all_calcs)\n",
    "                \n",
    "# After the for loops, we print the final overview tables\n",
    "\n",
    "# Output the final overview tables to an excel file Overview_THTerminals_Results.xlsx that is created in the output folder specified at the beginning of this notebook\n",
    "output_file_name_overview = os.path.join(folder_output_results, 'Overview_THTerminals_Results.xlsx')\n",
    "\n",
    "list_calculation_results=['Weighted Intensity', 'Total Region Area (mm²)', 'Total Region Volume (mm³)']\n",
    "    \n",
    "with pd.ExcelWriter(output_file_name_overview) as writer: \n",
    "    for calculation_result in list_calculation_results:\n",
    "        calculation_result_clean = calculation_result.replace('/', ' per ')\n",
    "        \n",
    "        print(f'Overview dataframe with all {calculation_result_clean} for all brains')\n",
    "        display(dictionary_overview_dataframes[calculation_result])\n",
    "        dictionary_overview_dataframes[calculation_result].to_excel(writer, sheet_name=calculation_result_clean, index=False, float_format = \"%.3f\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818bd6c2",
   "metadata": {},
   "source": [
    "## Part 3 - Automatic Hemisphere Analysis of all N S1 Slides of all N Brains (injected vs uninjected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33258e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time   \n",
    "# For curiosity we measure the time the code in this cell takes to run\n",
    "\n",
    "# Load the modified file with brain regions to replace/delete for each specific image \n",
    "df_brainregions_to_replace=load_data_brainregions_to_replace(file_brainregions_to_replace)\n",
    "\n",
    "# Load the modified file with hemisphere analysis for each specific image \n",
    "df_brainregions_injected=load_data_brainregions_injected(file_brainregions_injected)\n",
    "\n",
    "# Extract the file names that contain '_S1' in the file name. These are the N first images of the N unique brains.\n",
    "all_raw_data_file_locations_S1= load_all_file_locations_S1(folder_raw_data)\n",
    "\n",
    "# We initiate a counter to keep track in which loop we are below:\n",
    "count = 0\n",
    "\n",
    "# Loop over all the S1 pictures in the raw_data folder\n",
    "for file_location_S1 in all_raw_data_file_locations_S1:\n",
    "    count = count +1 # Counts the loop; first loop: counter = 1\n",
    "\n",
    "    # Get the image name out of the file_path \n",
    "    full_name = os.path.basename(file_location_S1)\n",
    "    file_name = os.path.splitext(full_name)\n",
    "    image_name_S1 = file_name[0]\n",
    "    \n",
    "    # Do the S1 data cleaning, making use of the functions defined above\n",
    "    print('\\n Analysis of ', file_location_S1)\n",
    "    df_S1_final = dataframe_cleaning(file_location_S1, df_brainregions_to_replace)\n",
    "\n",
    "    # Inner join with the injected/uninjected areas that are in the Brainregions_Hemisphere_DTD.xlsx file. \n",
    "    df_injected_object= df_brainregions_injected.merge(df_S1_final, left_on=['Image', 'Brainregion'], right_on=['Image', 'Area/object name'], how='inner')\n",
    "    df_injected_object.drop(columns=['Brainregion'], inplace=True)\n",
    "\n",
    "    # Do all the calculations, making use of the functions defined above. \n",
    "    df_S1_all_calcs_injected = all_calculations_injected(df_injected_object)\n",
    "    df_uninjected_injected_info = all_calculations_transposed(df_injected_object, df_S1_all_calcs_injected)\n",
    "\n",
    "    \n",
    "    ############################\n",
    "    #   Prepare overview file  #\n",
    "    ############################\n",
    "    \n",
    "\n",
    "    # For the overview excel file, only the df_S1_all_calcs_injected and df_uninjected_injected_info dataframe is needed. \n",
    "    # We will make 1 overview excelfiles with a few tabpages that we store in dictionary_overview_dataframes:\n",
    "    # dictionary_overview_dataframes = {Intensities and Areas : df,  .... }\n",
    "    \n",
    "    # In the first loop we initiate an empty overview dictionary that will be filled with dataframes. \n",
    "    if count==1:\n",
    "        dictionary_overview_dataframes={}\n",
    "        dictionary_overview_dataframes['Intensities and Areas']= df_uninjected_injected_info\n",
    "    elif count > 1 : \n",
    "        dictionary_overview_dataframes['Intensities and Areas']  = pd.concat([dictionary_overview_dataframes['Intensities and Areas'], df_uninjected_injected_info])   \n",
    "\n",
    "     \n",
    "    # Prepare the dataframes that are needed for the overview excel file: choose the needed columns,\n",
    "    # and rename the header of the column with the values to the image_name \n",
    "    list_calculation_results=['Total Region Area (mm²)', 'Total Region Volume (mm³)']\n",
    "\n",
    "    for calculation_result in list_calculation_results:\n",
    "        df_S1_all_calcs_injected_calculation= df_S1_all_calcs_injected[['Region_Hemisphere', calculation_result]].copy()\n",
    "        df_S1_all_calcs_injected_calculation.rename(columns={calculation_result: image_name_S1}, inplace=True)\n",
    "        \n",
    "        if count==1:\n",
    "            # In the first loop we fill the empty overview dictionary with a dataframe with the values calculated in loop 1  \n",
    "            dictionary_overview_dataframes[calculation_result]  = df_S1_all_calcs_injected_calculation.copy()\n",
    "            \n",
    "        elif count > 1 :\n",
    "            # In the subsequent loops we will add the values of those loops to the dataframes in the overview dictionary\n",
    "            dictionary_overview_dataframes[calculation_result] = dictionary_overview_dataframes[calculation_result].merge(df_S1_all_calcs_injected_calculation, how='outer', on='Region_Hemisphere')\n",
    "\n",
    "    # At the end, we delete some of the dataframes, to ensure they cannot be used in the next loop\n",
    "    del(df_S1_final)\n",
    "    del(df_injected_object)\n",
    "    del(df_S1_all_calcs_injected)\n",
    "    del(df_uninjected_injected_info)\n",
    "                \n",
    "# After the for loops, we print the final overview tables\n",
    "\n",
    "# Start by rearranging the columns of the dataframe dictionary_overview_dataframes['Intensities and Areas']: \n",
    "# first the Loss %, then the Uninjected columns, then the Injected columns\n",
    "columns_to_order = dictionary_overview_dataframes['Intensities and Areas'].columns\n",
    "columns_0 = ['Loss']\n",
    "columns_1 = [x for x in columns_to_order if 'UNINJECTED' in x and 'TOTAL' not in x]\n",
    "columns_1.sort(key= lambda x: float(x[10:]))  # to sort based on the number in it, and make sure that the order is U1, U2 ... U9, U10... instead of U1, U10, U2...\n",
    "columns_2 = ['TOTAL UNINJECTED']\n",
    "columns_3 = [x for x in columns_to_order if 'INJECTED' in x and 'UN' not in x and 'TOTAL' not in x]\n",
    "columns_3.sort(key= lambda x: float(x[8:])) \n",
    "columns_4 = ['TOTAL INJECTED']\n",
    "columns_ordered = columns_0 + columns_1 + columns_2 + columns_3 + columns_4\n",
    "print(columns_ordered)\n",
    "# Now reorder the columns of the dataframe:\n",
    "dictionary_overview_dataframes['Intensities and Areas'] = dictionary_overview_dataframes['Intensities and Areas'][columns_ordered]\n",
    "\n",
    "# Output the final overview tables to an excel file Overview_THTerminals_Hemisphere_Results.xlsx that is created in the output folder specified at the beginning of this notebook\n",
    "output_file_name_overview = os.path.join(folder_output_results_injected, 'Overview_THTerminals_Hemisphere_Results.xlsx')\n",
    "\n",
    "df=dictionary_overview_dataframes['Intensities and Areas']\n",
    "df_loss_intensities=df[df.index.str.contains('Intensity')]\n",
    "dictionary_overview_dataframes['Intensity Loss'] = df_loss_intensities['Loss']\n",
    "\n",
    "\n",
    "list_calculation_results=['Intensity Loss', 'Intensities and Areas', 'Total Region Area (mm²)', 'Total Region Volume (mm³)']\n",
    "    \n",
    "with pd.ExcelWriter(output_file_name_overview) as writer: \n",
    "    for calculation_result in list_calculation_results:\n",
    "        calculation_result_clean = calculation_result.replace('/', ' per ')\n",
    "        \n",
    "        print(f'Overview dataframe with all {calculation_result_clean} for all brains')\n",
    "        display(dictionary_overview_dataframes[calculation_result])\n",
    "        if calculation_result in ('Intensity Loss', 'Intensities and Areas'):\n",
    "            dictionary_overview_dataframes[calculation_result].to_excel(writer, sheet_name=calculation_result_clean, index=True, float_format = \"%.3f\")\n",
    "        else:\n",
    "            dictionary_overview_dataframes[calculation_result].to_excel(writer, sheet_name=calculation_result_clean, index=False, float_format = \"%.3f\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
