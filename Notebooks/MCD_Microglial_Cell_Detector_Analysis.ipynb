{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8160eb4",
   "metadata": {},
   "source": [
    "# Analysis of Aiforia Microglia Cell Detector Output (IBA1)\n",
    "\n",
    "## Part 0 - Outline\n",
    "This code handles the automatic processing of raw data from mouse brains analyzed using the Aiforia model “Microglial (IBA1) Cell Detector”. The data are stored in a local folder on the computer, specified within the code. The supported file formats are CSV, TSV, Excel and feather. To automatically change the format of multiple files, please refer to the notebook Change_Name_Format_Input_Data.ipynb.\n",
    "This notebook is organized into three sections:\n",
    "\n",
    "**1) Define Functions for Part 2 & 3**\n",
    "\n",
    "**2) Automatic Analysis of X * N Slides Across N Brains**\n",
    "In this section, we automate the analysis of all X*N slides corresponding to N brains (X slides per brain, which is a parameter that the user can choose in the code) contained in the folder with raw data. The approach is as follows:\n",
    "\n",
    "1) All X*N filenames are collected from the folder and stored in a list.\n",
    "\n",
    "2) From this list, we extract the N filenames containing '_S1', corresponding to the first slide of each brain.\n",
    "\n",
    "3) We loop over these N '_S1' slides and perform the following steps for each brain:\n",
    "\n",
    "    a) We retrieve the second slide (with '_S2' in the filename) belonging to this brain. We do the same for the third ('_S3'), fourth ('_S4'), ..., X'th ('_SX')  slides of this brain.   \n",
    "    b) We perform the analysis steps on each slide individually (S1, S2, …, SX) and on the combined dataset (S1+S2+…+SX).\n",
    "    c) We export the results to an excel file for this specific brain.\n",
    "    \n",
    "After each iteration, the individual brain’s results are added to a summary table containing data for all brains. Once all brains are processed, this overview table is also exported to Excel.\n",
    "\n",
    "**3) Automatic Analysis of X * N Slides Across N Brains After Determining the (Un)Injected Areas**\n",
    "\n",
    "In this section, we extend the analysis by identifying which brain regions are on the injected versus non-injected side. The comparison between both sides follows the same analysis workflow as in Section 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5b4c22",
   "metadata": {},
   "source": [
    "## Part 1 - Define the necessary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0ede8e",
   "metadata": {},
   "source": [
    "### Part 1.1 - Load all necessary Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Pandas display options\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aafba6",
   "metadata": {},
   "source": [
    "### Part 1.2 - Data Locations\n",
    "\n",
    "**TO DO:**\n",
    "\n",
    "Specify the following paths before running the analysis:\n",
    "\n",
    "1) **Raw data format:** choose the file format of the raw data (csv, tsv, xlsx or feather).\n",
    "2) **Some experimental parameters:** spacing between sections and section thickness.\n",
    "3) **Raw data folder:** the folder containing the original data files exported from Aiforia.\n",
    "4) **Results folders:** the folders where the Excel files with processed results will be saved.\n",
    "5) **Region mapping files:** the location of the Excel files that specify which brain regions have to be replaced and were (un)injected.\n",
    "\n",
    "Use the following format to define each path: <font color='darkred'>r'file_location'</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify what data format you want to use for your raw data: csv, tsv, xlsx or feather. Do this by uncommenting the data_format that you want.\n",
    "data_format = 'csv'\n",
    "# data_format = 'tsv'\n",
    "# data_format = 'xlsx'\n",
    "# data_format = 'feather'\n",
    "\n",
    "# Specify the maximum number of slides per brain. For example, if set to 4, filenames should include '_S1', '_S2', '_S3', and '_S4'. \n",
    "# If some brains have fewer slides, the code will generate empty data files for the missing ones to ensure proper execution.\n",
    "amount_of_slides = 2\n",
    "\n",
    "# Specify the experimental parameters (section_thickness in micrometers!!):\n",
    "spacing=12\n",
    "section_thickness = 40  \n",
    "\n",
    "# Specify folder locations\n",
    "folder_raw_data = r'C:\\Users\\...\\Raw_data_IBA1'\n",
    "folder_output_results = r'C:\\Users\\...\\Output_Results_IBA1'\n",
    "folder_output_results_injected = r'C:\\Users\\...\\Output_Results_Injected_IBA1'\n",
    "file_brainregions_to_replace =  r'C:\\Users\\...\\Brainregions_To_Replace_IBA1.xlsx'\n",
    "file_brainregions_injected =  r'C:\\Users\\...\\Brainregions_Hemisphere_IBA1.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eedbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folders if they did not exist yet\n",
    "if not os.path.isdir(folder_output_results):\n",
    "    os.mkdir(folder_output_results)\n",
    "if not os.path.isdir(folder_output_results_injected):\n",
    "    os.mkdir(folder_output_results_injected)\n",
    "\n",
    "# Create a list of expected slide suffixes. For example, if amount_of_slides = 4, then appendices_list = ['_S1', '_S2', '_S3', '_S4'].\n",
    "appendices_list = [f\"_S{i}\" for i in range(1, amount_of_slides + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559665cf",
   "metadata": {},
   "source": [
    "### Part 1.3 – Function to Load All Image Files for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf54a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_file_locations_S1(folder_raw_data: str, data_format: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Retrieve and list all file locations for S1 images in the specified raw data folder.\n",
    "\n",
    "    This function searches for all raw data files (based on the specified data format) \n",
    "    within the given folder and filters those containing '_S1' in their filename. \n",
    "    These represent the first slides (S1) of each brain. \n",
    "    If '_S1'/'_S2' naming is not used, '_S1' should be appended manually to filenames.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_raw_data : str\n",
    "        Path to the folder containing raw data files.\n",
    "    data_format : str\n",
    "        Format of the raw data files ('csv', 'tsv', 'xlsx' or 'feather').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    all_raw_data_file_locations_S1: list[str]\n",
    "        Sorted list of full file paths for S1 images.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the file pattern based on the data format\n",
    "    if data_format == 'csv':\n",
    "        pattern = \"*.csv\"\n",
    "    elif data_format == 'tsv':\n",
    "        pattern = \"*.tsv\"\n",
    "    elif data_format == 'xlsx':\n",
    "        pattern = \"*.xlsx\"\n",
    "    elif data_format == 'feather':\n",
    "        pattern = \"*.feather\"\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid data format specified. Please set 'data_format' to 'csv', 'tsv', 'xlsx' or 'feather'.\"\n",
    "        )\n",
    "\n",
    "    # Retrieve and sort all matching raw data files\n",
    "    all_raw_data_file_locations = glob.glob(os.path.join(folder_raw_data, pattern))\n",
    "    all_raw_data_file_locations.sort()\n",
    "\n",
    "    print(\"All raw data file locations:\")\n",
    "    for file_location in all_raw_data_file_locations:\n",
    "        print(f\" - {file_location}\")\n",
    "\n",
    "    # Filter filenames that contain '_S1' (first slides of each brain)\n",
    "    all_raw_data_file_locations_S1 = [path for path in all_raw_data_file_locations if '_S1' in path]\n",
    "\n",
    "    print(\"\\nRaw data file locations for S1 images:\")\n",
    "    for file_location_S1 in all_raw_data_file_locations_S1:\n",
    "        print(f\" - {file_location_S1}\")\n",
    "\n",
    "    return all_raw_data_file_locations_S1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60972e7e",
   "metadata": {},
   "source": [
    "### Part 1.4 – Function to Load the Brain Region Correction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf72538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_brainregions_to_replace(file_brainregions_to_replace: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and clean the file containing corrections for brain regions that need to be replaced for each image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_brainregions_to_replace : str\n",
    "        Path to the Excel file with columns: 'Image', 'Brainregion_Wrong', 'Brainregion_Correct'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Cleaned DataFrame with brain regions to replace for each image. \n",
    "        All brain region names are stripped of spaces and converted to uppercase.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    if not os.path.exists(file_brainregions_to_replace):\n",
    "        raise FileNotFoundError(f\"The specified file does not exist: {file_brainregions_to_replace}\")\n",
    "\n",
    "    # Load the relevant columns from the Excel file\n",
    "    df = pd.read_excel(\n",
    "        file_brainregions_to_replace,\n",
    "        usecols=['Image', 'Brainregion_Wrong', 'Brainregion_Correct'],\n",
    "        dtype={'Image': 'str', 'Brainregion_Wrong': 'str', 'Brainregion_Correct': 'str'}\n",
    "    )\n",
    "\n",
    "    # Clean the data in place\n",
    "    df['Image'] = df['Image'].str.strip()\n",
    "    df['Brainregion_Wrong'] = df['Brainregion_Wrong'].str.upper().str.strip()\n",
    "    df['Brainregion_Correct'] = df['Brainregion_Correct'].str.upper().str.strip()\n",
    "\n",
    "    print(\"The modified table of brain regions to replace for each image:\")\n",
    "    display(df)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2ce6b7",
   "metadata": {},
   "source": [
    "### Part 1.5 – Function to Load the File Indicating Which Brain Regions Were Injected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e812ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_brainregions_injected(file_brainregions_injected: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and clean the file specifying which brain regions were on the injected side for each specific image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_brainregions_injected : str\n",
    "        Path to the Excel file containing injected brain region information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Cleaned DataFrame with columns:\n",
    "        - 'Image': image identifier\n",
    "        - 'Brainregion': uppercase, stripped brain region name\n",
    "        - 'Parent_Injected': uppercase, stripped hemisphere \n",
    "        - 'Daughter1_Injected': uppercase, stripped hemisphere \n",
    "\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_brainregions_injected):\n",
    "        raise FileNotFoundError(f\"The specified file does not exist: {file_brainregions_injected}\")\n",
    "\n",
    "    # Load relevant columns from the Excel file\n",
    "    df = pd.read_excel(\n",
    "        file_brainregions_injected,\n",
    "        usecols=['Image', 'Brainregion', 'Hemisphere'],\n",
    "        dtype={'Image': 'str', 'Brainregion': 'str', 'Hemisphere': 'str'}\n",
    "    )\n",
    "\n",
    "    # Clean the data in place\n",
    "    df['Image'] = df['Image'].str.strip()\n",
    "    df['Brainregion'] = df['Brainregion'].str.upper().str.strip()\n",
    "    df['Parent_Injected'] = df['Hemisphere'].str.upper().str.strip()\n",
    "    df['Daughter1_Injected'] = df['Hemisphere'].str.upper().str.strip()\n",
    "\n",
    "    # Drop the original 'Hemisphere' column\n",
    "    df.drop(columns=['Hemisphere'], inplace=True)\n",
    "\n",
    "    print(\"The modified table of injected brain regions for each image:\")\n",
    "    display(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d81821b",
   "metadata": {},
   "source": [
    "### Part 1.6 – Function to Load a DataFrame and Clean It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c380e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_cleaning(file_location: str, df_brainregions_to_replace: pd.DataFrame, data_format: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a data file from the given location and clean it using a brain regions replacement table.\n",
    "    If the file does not exist, an empty file is created with the correct columns.\n",
    "    Replaces incorrect brain regions, merges names by removing numbers, filters based on area thresholds,\n",
    "    and calculates derived metrics like Area/Perimeter and Circularity.\n",
    "    Returns a cleaned dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_location : str\n",
    "        Path to the raw data file for a single image.\n",
    "    df_brainregions_to_replace : pd.DataFrame\n",
    "        DataFrame specifying which brain regions need to be replaced for each image.\n",
    "    data_format : str\n",
    "        Format of the raw data file: 'csv', 'tsv', 'xlsx' or 'feather'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Cleaned dataframe with additional calculated columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------\n",
    "    # Define expected columns and dtypes\n",
    "    # ------------------------\n",
    "    columns = [\n",
    "        'Image', 'Parent area name', 'Area/object name',\n",
    "        'Class label', 'Area (μm²)', 'Circumference (µm)'\n",
    "    ]\n",
    "    dtypes = {\n",
    "        'Image': 'str',\n",
    "        'Parent area name': 'str',\n",
    "        'Area/object name': 'str',\n",
    "        'Class label': 'str',\n",
    "        'Area (μm²)': 'float64',\n",
    "        'Circumference (µm)': 'float64'\n",
    "    }\n",
    "\n",
    "    # ------------------------\n",
    "    # Load or create the data file\n",
    "    # ------------------------\n",
    "    try:\n",
    "        if data_format in ('csv', 'tsv'):\n",
    "            df = pd.read_csv(file_location, sep='\\t', usecols=columns, dtype=dtypes, index_col=False, keep_default_na=True)\n",
    "        elif data_format == 'xlsx':\n",
    "            df = pd.read_excel(file_location, usecols=columns, dtype=dtypes, index_col=False, keep_default_na=True)\n",
    "        elif data_format == 'feather':\n",
    "            df = pd.read_feather(file_location).astype(dtypes)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid data format. Choose 'csv', 'tsv', 'xlsx' or 'feather'.\")\n",
    "    except FileNotFoundError:\n",
    "        # If file doesn't exist, create an empty one and reload\n",
    "        df_empty = pd.DataFrame(columns=columns)\n",
    "        df_empty.reset_index(inplace=True)\n",
    "        if data_format in ('csv', 'tsv'):\n",
    "            df_empty.to_csv(file_location, sep='\\t', index=False)\n",
    "            df = pd.read_csv(file_location, sep='\\t', usecols=columns, dtype=dtypes)\n",
    "        elif data_format == 'xlsx':\n",
    "            df_empty.to_excel(file_location, index=False)\n",
    "            df = pd.read_excel(file_location, usecols=columns, dtype=dtypes)\n",
    "        elif data_format == 'feather':\n",
    "            df_empty.to_feather(file_location)\n",
    "            df = pd.read_feather(file_location).astype(dtypes)\n",
    "        print(f\"\\nA dataframe at location {file_location} did not exist, so an empty dataframe was created.\")\n",
    "\n",
    "    # ------------------------\n",
    "    # Clean up and standardize column values\n",
    "    # ------------------------\n",
    "    # Remove rows with missing essential data\n",
    "    df.dropna(subset=['Parent area name', 'Area (μm²)', 'Area/object name', 'Class label'], inplace=True)\n",
    "\n",
    "    # Standardize text capitalization\n",
    "    df['Parent area name'] = df['Parent area name'].str.upper()\n",
    "    df['Area/object name'] = df['Area/object name'].str.upper()\n",
    "    df['Class label'] = df['Class label'].str.upper()\n",
    "\n",
    "    # ------------------------\n",
    "    # Extract image name from file name\n",
    "    # ------------------------\n",
    "    image_name = os.path.splitext(os.path.basename(file_location))[0]\n",
    "    print('The present image =', image_name)\n",
    "    \n",
    "    # Make sure the image name across the whole first Image column is correct\n",
    "    df['Image'] = image_name\n",
    "\n",
    "    print('The full raw data =')\n",
    "    display(df)\n",
    "\n",
    "    # ------------------------\n",
    "    # Replace incorrect brain regions\n",
    "    # ------------------------\n",
    "    # Create the dictionary of brain regions that should be replaced for this specific image\n",
    "    df_replacements = df_brainregions_to_replace[df_brainregions_to_replace['Image'] == image_name]\n",
    "    dict_replace = pd.Series(\n",
    "        df_replacements.Brainregion_Correct.values,\n",
    "        index=df_replacements.Brainregion_Wrong\n",
    "    ).to_dict()\n",
    "\n",
    "    print(f\"The dictionary of brain regions to replace for {image_name} is:\", dict_replace)\n",
    "\n",
    "    # Apply replacements in both parent and Area/object name columns\n",
    "    df['Parent area name'] = df['Parent area name'].replace(dict_replace, regex=False)\n",
    "    df['Area/object name'] = df['Area/object name'].replace(dict_replace, regex=False)\n",
    "\n",
    "    # ------------------------\n",
    "    # Create a column 'Parent area name merged' and 'Area/object name merged' where the ending numbers are deleted from the original columns:\n",
    "    # ------------------------\n",
    "    df['Parent area name merged'] = df['Parent area name'].str.replace(r'\\d+$', '', regex=True).str.strip()\n",
    "    df['Area/object name merged'] = df['Area/object name'].str.replace(r'\\d+$', '', regex=True).str.strip()\n",
    "\n",
    "    # ------------------------\n",
    "    # Filter unwanted rows\n",
    "    # ------------------------\n",
    "    # Remove rows with area < 45 for class label \"IBA1 POSITIVE CELL\"\n",
    "    mask_exclude = (df['Area (μm²)'] < 45) & (df['Class label'] == 'IBA1 POSITIVE CELL')\n",
    "    df = df[~mask_exclude]\n",
    "\n",
    "    # Remove rows with placeholder EMPTY labels (if created during replacements)\n",
    "    df = df[(df['Parent area name'] != 'EMPTY') & (df['Area/object name'] != 'EMPTY')]\n",
    "\n",
    "    # ------------------------\n",
    "    # Derived metrics\n",
    "    # ------------------------\n",
    "    df['Area/Perimeter (μm)'] = df['Area (μm²)'] / df['Circumference (µm)']\n",
    "    df['Circularity'] = (4 * math.pi * df['Area (μm²)']) / (df['Circumference (µm)'] ** 2)\n",
    "\n",
    "    print('The fully cleaned table with \"Area/Perimeter (μm)\" and \"Circularity\" =')\n",
    "    display(df)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8d2b73",
   "metadata": {},
   "source": [
    "### Part 1.7 - Function to Create Hierarchical Dataframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6433e",
   "metadata": {},
   "source": [
    "Note: This function is not used for the IBA-1 code, as the hierarchy does not extend to Daughter 3.\n",
    "\n",
    "Hierarchy:\n",
    "\n",
    "One type of **Parent:** TISSUE 1, 2, 3 ... \\\n",
    "Many types of **Daughter 1:** AMYGDALA 1, 2, 3, …, STRIATUM 1, 2, 3, …, ...  \\\n",
    "One type of **Daughter 2:** IBA1 POSITIVE CELL 60451, IBA1 POSITIVE CELL 354269, …"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abb410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hierarchy() -> None:\n",
    "    \"\"\"Note: This function is not used for the IBA-1 code, as the hierarchy does not extend to Daughter 3.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1013829b",
   "metadata": {},
   "source": [
    "### Part 1.8 - Function to Calculate all Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2000e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_calculations(df1: pd.DataFrame, df2: pd.DataFrame, groupby_column1: str = 'Parent area name merged', groupby_column2: str = 'Area/object name merged') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute key summary statistics (counts, areas, averages) for hierarchical regions\n",
    "    based on two dataframes, with optional grouping columns.\n",
    "\n",
    "    Parameters:\n",
    "        df1 (pd.DataFrame): dataframe for calculations.\n",
    "        df2 (pd.DataFrame): dataframe for calculations (can be same as df1 when injected/uninjected is disregarded).\n",
    "        groupby_column1 (str): Column in df1 to group by.\n",
    "        groupby_column2 (str): Column in df2 to group by.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Merged dataframe containing:\n",
    "            - Counts\n",
    "            - Total region area\n",
    "            - Total cell area\n",
    "            - Average cell area\n",
    "            - Average Area/Perimeter\n",
    "            - Average circularity\n",
    "            - Extrapolated cell count\n",
    "            - Percentage of IBA1 positive area\n",
    "            - Cells per region area and volume (mm² and mm³)\n",
    "    \"\"\"\n",
    "\n",
    "    # Count the number of rows for each parent area name merged \n",
    "    df_counts_merged = df1[groupby_column1].value_counts().rename_axis('Merged area name') \\\n",
    "                       .reset_index(name='Counts')\n",
    "\n",
    "    # Count the total area of each Area/object name merged (e.g. Amygdala 1 + Amygdala 7 + ... area)\n",
    "    df_total_region_area_merged = df2.groupby(groupby_column2, as_index=False)['Area (μm²)'] \\\n",
    "                                     .sum().rename(columns={'Area (μm²)': 'Total Region Area (μm²)',\n",
    "                                                            groupby_column2: 'Merged area name'})\n",
    "\n",
    "    # Calculate the total Area (μm²), average Area (μm²), average Area/Perimeter (μm), average Circularity  \n",
    "    # of the cells belonging to each Parent area name merged\n",
    "    agg_dict = {\n",
    "        'Area (μm²)': ['sum', 'mean'],\n",
    "        'Area/Perimeter (μm)': 'mean',\n",
    "        'Circularity': 'mean'\n",
    "    }\n",
    "    df_stats = df1.groupby(groupby_column1, as_index=False).agg(agg_dict)\n",
    "    df_stats.columns = ['Merged area name', 'Total Cell Area (μm²)', 'Average Cell Area (μm²)',\n",
    "                        'Average Area/Perimeter (μm)', 'Average Circularity']\n",
    "\n",
    "    # Merge all intermediate results\n",
    "    dfs_to_merge = [df_counts_merged, df_total_region_area_merged, df_stats]\n",
    "    df_all_calcs_merged = functools.reduce(\n",
    "        lambda left, right: pd.merge(left, right, on='Merged area name', how='outer'),\n",
    "        dfs_to_merge\n",
    "    )\n",
    "\n",
    "    # Additional derived calculations\n",
    "    df_all_calcs_merged['Extrapolated Cell Count'] = df_all_calcs_merged['Counts'] * spacing\n",
    "    df_all_calcs_merged['Percentage IBA1 Positive Area'] = 100 * df_all_calcs_merged['Total Cell Area (μm²)'] / \\\n",
    "                                                          df_all_calcs_merged['Total Region Area (μm²)']\n",
    "    df_all_calcs_merged['Cells/Region Area (per μm²)'] = df_all_calcs_merged['Counts'] / \\\n",
    "                                                          df_all_calcs_merged['Total Region Area (μm²)']\n",
    "    df_all_calcs_merged['Cells/Region Volume (per μm³)'] = df_all_calcs_merged['Cells/Region Area (per μm²)'] / section_thickness\n",
    "    df_all_calcs_merged['Cells/Region Area (mm²)'] = df_all_calcs_merged['Cells/Region Area (per μm²)'] * 1e6\n",
    "    df_all_calcs_merged['Cells/Region Volume (mm³)'] = df_all_calcs_merged['Cells/Region Volume (per μm³)'] * 1e9\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df_all_calcs_merged.drop(columns=['Cells/Region Area (per μm²)', 'Cells/Region Volume (per μm³)'], inplace=True)\n",
    "\n",
    "    # Sort for readability\n",
    "    df_all_calcs_merged.sort_values('Merged area name', inplace=True)\n",
    "\n",
    "    print('The total Calculations of each group:')\n",
    "    display(df_all_calcs_merged)\n",
    "\n",
    "    return df_all_calcs_merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8cfed3",
   "metadata": {},
   "source": [
    "## Part 2 - Automatic Analysis of all X*N Slides of all N Brains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec97f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Measure execution time of this cell\n",
    "\n",
    "# Load the file specifying brain regions to replace/delete for each image\n",
    "df_brainregions_to_replace = load_data_brainregions_to_replace(file_brainregions_to_replace)\n",
    "\n",
    "# Get all file names containing '_S1' (first images of all N brains)\n",
    "all_raw_data_file_locations_S1 = load_all_file_locations_S1(folder_raw_data, data_format)\n",
    "\n",
    "# Initialize dictionary to store all overview dataframes\n",
    "dictionary_overview_dataframes = {}\n",
    "\n",
    "\n",
    "# Loop over all S1 images in the raw_data folder\n",
    "for count, file_location_S1 in enumerate(all_raw_data_file_locations_S1):\n",
    "\n",
    "    print(f'\\nAnalysis of {file_location_S1}')\n",
    "\n",
    "    # Extract image name from file path\n",
    "    image_name_S1 = os.path.splitext(os.path.basename(file_location_S1))[0]\n",
    "\n",
    "    # Dictionaries to store cleaned dataframes and calculated results for all appendices\n",
    "    dict_df_SX_final = {}              # e.g., {'_S1' : df_S1_final, '_S2' : df_S2_final, ..., '_SX' : df_SX_final}\n",
    "    dict_df_SX_all_calcs_merged = {}   # e.g., {'_S1' : df_S1_all_calcs_merged, '_S2' : df_S2_all_calcs_merged, ..., '_SX' : df_SX_all_calcs_merged}\n",
    "\n",
    "    # Loop over all appendices ('_S1', '_S2', ..., '_SX')\n",
    "    for appendix in appendices_list:\n",
    "        # Replace '_S1' in the file path with the current appendix\n",
    "        file_location = file_location_S1.replace('_S1', appendix)\n",
    "\n",
    "        # Clean the data using pre-defined function\n",
    "        dict_df_SX_final[appendix] = dataframe_cleaning(file_location, df_brainregions_to_replace, data_format)\n",
    "\n",
    "        # Perform all calculations on the cleaned dataframe\n",
    "        # The except part is for when we have made an empty dataframe because no file was available (will never be the case for appendix =_S1).\n",
    "        try:\n",
    "            dict_df_SX_all_calcs_merged[appendix] = all_calculations(dict_df_SX_final[appendix],\n",
    "                                                                     dict_df_SX_final[appendix])\n",
    "            print(f\"All calculations completed for {appendix} of {file_location}\")\n",
    "            display(dict_df_SX_all_calcs_merged[appendix])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Concatenate all cleaned dataframes (S1+S2+...+SX)\n",
    "    df_SX_final_concat = pd.concat(dict_df_SX_final.values(), axis=0)\n",
    "\n",
    "    # Perform calculations on the concatenated  S1 + S2 + ... + SX dataframe\n",
    "    try:\n",
    "        df_SX_all_calcs_concat = all_calculations(df_SX_final_concat, df_SX_final_concat)\n",
    "        print(f'All calculations completed for concatenated S1+S2+...+SX of {file_location_S1}')\n",
    "        display(df_SX_all_calcs_concat)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Save individual and concatenated results to Excel\n",
    "    output_file_location_SX = os.path.join(\n",
    "        folder_output_results,\n",
    "        image_name_S1.replace('_S1', '_SX') + '_Results.xlsx'\n",
    "    )\n",
    "\n",
    "    with pd.ExcelWriter(output_file_location_SX) as writer:\n",
    "        for appendix in appendices_list:\n",
    "            try:\n",
    "                dict_df_SX_all_calcs_merged[appendix].to_excel(\n",
    "                    writer, sheet_name=appendix[1:] + '_Results', index=False, float_format=\"%.3f\"\n",
    "                )\n",
    "            except:\n",
    "                pass  # No SX dataframe was available, and the empty one would lead to errors in the try clause\n",
    "\n",
    "        df_SX_all_calcs_concat.to_excel(writer, sheet_name='SX_Combined_Results', index=False, float_format=\"%.3f\")\n",
    "\n",
    "\n",
    "    # Prepare overview Excel file, for which only the df_SX_all_calcs_concat dataframe is needed. \n",
    "    # Define calculation columns for overview\n",
    "    list_calculation_results = [\n",
    "        'Total Region Area (μm²)', 'Counts', 'Extrapolated Cell Count',\n",
    "        'Total Cell Area (μm²)', 'Average Cell Area (μm²)', 'Percentage IBA1 Positive Area',\n",
    "        'Average Area/Perimeter (μm)', 'Average Circularity',\n",
    "        'Cells/Region Area (mm²)', 'Cells/Region Volume (mm³)',\n",
    "    ]\n",
    "\n",
    "    # Exclude unnecessary brain regions\n",
    "    brainregions_not_needed = ['IBA1 POSITIVE CELL', 'TISSUE']\n",
    "\n",
    "    # Prepare overview dataframes\n",
    "    # We will make 1 overview excelfile with a few tabpages that we store in dictionary_overview_dataframes:\n",
    "    # dictionary_overview_dataframes = {Total Region area: df, Extrapolated Cell Count:df, Cells/Region Area:df, .... }\n",
    "    for calculation_result in list_calculation_results:\n",
    "        df_calc = df_SX_all_calcs_concat[['Merged area name', calculation_result]].copy()\n",
    "        df_calc = df_calc[~df_calc['Merged area name'].isin(brainregions_not_needed)]\n",
    "        df_calc.rename(columns={calculation_result: image_name_S1.replace('_S1', '').replace('_IBA1', '')}, inplace=True)\n",
    "\n",
    "        # Merge data into overview dictionary\n",
    "        if count == 0:\n",
    "            dictionary_overview_dataframes[calculation_result] = df_calc.copy()\n",
    "        else:\n",
    "            dictionary_overview_dataframes[calculation_result] = dictionary_overview_dataframes[calculation_result].merge(\n",
    "                df_calc, how='outer', on='Merged area name'\n",
    "            )\n",
    "\n",
    "    # Clean up memory for next iteration\n",
    "    del dict_df_SX_final, df_SX_final_concat, df_SX_all_calcs_concat\n",
    "\n",
    "# Save overview Excel file\n",
    "output_file_name_overview = os.path.join(folder_output_results, 'Overview_IBA1_Results.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(output_file_name_overview) as writer:\n",
    "    for calculation_result in list_calculation_results:\n",
    "        sheet_name_clean = calculation_result.replace('/', ' per ').replace('Volume', 'Vol')\n",
    "\n",
    "        print(f'Overview dataframe with all {sheet_name_clean} for all brains')\n",
    "        display(dictionary_overview_dataframes[calculation_result])\n",
    "        \n",
    "        dictionary_overview_dataframes[calculation_result].to_excel(\n",
    "            writer, sheet_name=sheet_name_clean, index=False, float_format=\"%.3f\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b43d4",
   "metadata": {},
   "source": [
    "## Part 3 – Automatic Analysis of all N S1 Slides of all N Brains (Including Injected and Uninjected Hemispheres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b18f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Measure the execution time of this cell\n",
    "\n",
    "# Load the file specifying brain regions to replace/delete for each image\n",
    "df_brainregions_to_replace = load_data_brainregions_to_replace(file_brainregions_to_replace)\n",
    "\n",
    "# Load the file specifying which brain regions belong to which hemisphere for each image\n",
    "df_brainregions_injected = load_data_brainregions_injected(file_brainregions_injected)\n",
    "\n",
    "# Get all file names containing '_S1'\n",
    "all_raw_data_file_locations_S1 = load_all_file_locations_S1(folder_raw_data, data_format)\n",
    "\n",
    "# Initialize dictionary to store all overview dataframes for injected analysis\n",
    "dictionary_overview_dataframes_injected = {}\n",
    "\n",
    "# Loop over all S1 images in the raw_data folder\n",
    "for count, file_location_S1 in enumerate(all_raw_data_file_locations_S1):\n",
    "\n",
    "    print(f'\\nAnalysis of {file_location_S1}')\n",
    "\n",
    "    # Extract image name from file path\n",
    "    image_name_S1 = os.path.splitext(os.path.basename(file_location_S1))[0]\n",
    "\n",
    "    # Dictionaries to store cleaned dataframes for all appendices\n",
    "    dict_df_SX_final = {}  # e.g., {'_S1': df_S1_final, '_S2': df_S2_final, ..., '_SX': df_SX_final}\n",
    "\n",
    "    # Loop over all appendices ('_S1', '_S2', ..., '_SX')\n",
    "    for appendix in appendices_list:\n",
    "        file_location = file_location_S1.replace('_S1', appendix)\n",
    "        # Clean the data using pre-defined function\n",
    "        dict_df_SX_final[appendix] = dataframe_cleaning(file_location, df_brainregions_to_replace, data_format)\n",
    "\n",
    "    # Concatenate all cleaned dataframes (S1+S2+...+SX)\n",
    "    df_SX_final_concat = pd.concat(dict_df_SX_final.values(), axis=0)\n",
    "\n",
    "    # Merge with hemisphere injected information. \n",
    "    # For each row, determine whether the Parent area name and Area/object name were injected or uninjected\n",
    "    # Brain regions not relevant to the injected analysis are removed through the inner join\n",
    "    df_SX_injected_parent = df_SX_final_concat.merge(\n",
    "        df_brainregions_injected, left_on=['Image', 'Parent area name'], right_on=['Image', 'Brainregion'], how='inner'\n",
    "    )\n",
    "    df_SX_injected_object = df_SX_final_concat.merge(\n",
    "        df_brainregions_injected, left_on=['Image', 'Area/object name'], right_on=['Image', 'Brainregion'], how='inner'\n",
    "    )\n",
    "\n",
    "    # Perform all calculations for injected data.\n",
    "    # The except part is for when we have made an empty dataframe because no dataframe was available (will never be the case for S1+S2 +...SX).\n",
    "    try:\n",
    "        df_SX_all_calcs_injected = all_calculations(\n",
    "            df_SX_injected_parent, df_SX_injected_object,\n",
    "            groupby_column1='Parent_Injected', groupby_column2='Daughter1_Injected'\n",
    "        )\n",
    "        df_SX_all_calcs_injected.sort_values('Merged area name', ascending=False, inplace=True)\n",
    "        print(f'All calculations completed for concatenated SX INJECTED of {file_location_S1}')\n",
    "        display(df_SX_all_calcs_injected)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Save individual results to Excel\n",
    "    output_file_location_SX = os.path.join(\n",
    "        folder_output_results_injected,\n",
    "        image_name_S1.replace('_S1', '_SX') + '_Hemisphere_Results.xlsx'\n",
    "    )\n",
    "\n",
    "    with pd.ExcelWriter(output_file_location_SX) as writer:\n",
    "        df_SX_all_calcs_injected.to_excel(writer, sheet_name='SX_Hemisphere_Results', index=False, float_format=\"%.3f\")\n",
    "\n",
    "    # Define calculation columns for overview\n",
    "    list_calculation_results = [\n",
    "        'Total Region Area (μm²)', 'Counts', 'Extrapolated Cell Count',\n",
    "        'Total Cell Area (μm²)', 'Average Cell Area (μm²)', 'Percentage IBA1 Positive Area',\n",
    "        'Average Area/Perimeter (μm)', 'Average Circularity',\n",
    "        'Cells/Region Area (mm²)', 'Cells/Region Volume (mm³)',\n",
    "    ]\n",
    "\n",
    "    # Exclude unnecessary brain regions\n",
    "    brainregions_not_needed = ['IBA1 POSITIVE CELL', 'TISSUE']\n",
    "\n",
    "    # Prepare overview dataframes\n",
    "    # We will make 1 overview excelfile with a few tabpages that we store in dictionary_overview_dataframes_injected:\n",
    "    # dictionary_overview_dataframes_injected = {Total Region area: df, Extrapolated Cell Count:df, Cells/Region Area:df, .... }\n",
    "    for calculation_result in list_calculation_results:\n",
    "        df_calc = df_SX_all_calcs_injected[['Merged area name', calculation_result]].copy()\n",
    "        df_calc = df_calc[~df_calc['Merged area name'].isin(brainregions_not_needed)]\n",
    "        df_calc.rename(columns={calculation_result: image_name_S1.replace('_S1', '').replace('_IBA1', '')}, inplace=True)\n",
    "\n",
    "        # Merge data into overview dictionary\n",
    "        if count == 0:\n",
    "            dictionary_overview_dataframes_injected[calculation_result] = df_calc.copy()\n",
    "        else:\n",
    "            dictionary_overview_dataframes_injected[calculation_result] = dictionary_overview_dataframes_injected[calculation_result].merge(\n",
    "                df_calc, how='outer', on='Merged area name'\n",
    "            )\n",
    "\n",
    "    # Clean up memory for next iteration\n",
    "    del dict_df_SX_final, df_SX_final_concat, df_SX_all_calcs_injected\n",
    "\n",
    "# Save overview Excel file\n",
    "output_file_name_overview = os.path.join(folder_output_results_injected, 'Overview_IBA1_Hemisphere_Results.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(output_file_name_overview) as writer:\n",
    "    for calculation_result in list_calculation_results:\n",
    "        sheet_name_clean = calculation_result.replace('/', ' per ').replace('Volume', 'Vol')\n",
    "        dictionary_overview_dataframes_injected[calculation_result].sort_values('Merged area name', ascending=False, inplace=True)\n",
    "        \n",
    "        print(f'Overview dataframe with all {sheet_name_clean} for all brains')\n",
    "        display(dictionary_overview_dataframes_injected[calculation_result])\n",
    "        \n",
    "        dictionary_overview_dataframes_injected[calculation_result].to_excel(writer, sheet_name=sheet_name_clean, index=False, float_format=\"%.3f\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
